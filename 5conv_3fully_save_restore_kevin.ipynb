{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 100, 100, 3)\n",
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "file_locate='/home/seongjung/바탕화면/Numpy_ASAN/Mal_vs_Benign/100_100/0/0/'\n",
    "sess = tf.InteractiveSession()\n",
    "test_img=np.load(file_locate+'test_img.npy');\n",
    "try:\n",
    "    print np.shape(test_img)\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "except:\n",
    "    np.shape(test_img)\n",
    "    test_img=np.reshape(test_img , newshape = [np.shape(test_img)[0] , 32, 32 ,3] )\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "\n",
    "save_flag  = False\n",
    "divide_flag= False\n",
    "restore_flag =True\n",
    "#odel_save_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/3_0/'\n",
    "model_save_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/0_0'\n",
    "if restore_flag ==True:\n",
    "#   restore_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/3_0/'\n",
    "    restore_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/0_0'\n",
    "batch_size=30\n",
    "print img_row ,img_col\n",
    "n_classes =2\n",
    "in_ch =3\n",
    "out_ch1=200\n",
    "out_ch2=200\n",
    "out_ch3=200\n",
    "out_ch4=200\n",
    "out_ch5=200\n",
    "\n",
    "\n",
    "fully_ch1=1024\n",
    "fully_ch2 =1024\n",
    "fully_ch3 =1024\n",
    "\n",
    "\n",
    "\n",
    "strides_1=[1,2,2,1]\n",
    "strides_2=[1,1,1,1]\n",
    "strides_3=[1,1,1,1]\n",
    "strides_4=[1,1,1,1]\n",
    "strides_5=[1,1,1,1]\n",
    "\n",
    "\n",
    "x= tf.placeholder(\"float\",shape=[None,img_col , img_row , 3],  name = 'x-input')\n",
    "y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,3])\n",
    "\n",
    "iterate=1\n",
    "\n",
    "\n",
    "\n",
    "weight_row =3 ; weight_col=3\n",
    "\n",
    "\n",
    "pooling_row_size1=int(img_row/2)\n",
    "pooling_row_size2=int(pooling_row_size1/2)\n",
    "pooling_row_size3=int(pooling_row_size2/2)\n",
    "pooling_row_size4=int(pooling_row_size3/2)\n",
    "pooling_row_size5=int(pooling_row_size4/2)\n",
    "pooling_col_size1=int(img_col/2)\n",
    "pooling_col_size2=int(pooling_col_size1/2)\n",
    "pooling_col_size3=int(pooling_col_size2/2)\n",
    "pooling_col_size4=int(pooling_col_size3/2)\n",
    "pooling_col_size5=int(pooling_col_size4/2)\n",
    "\n",
    "print img_col , img_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Weight and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/seongjung/jupyter'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (306, 100, 100, 3)\n",
      "Training Data Label (306, 2)\n",
      "Test Data Label (39, 2)\n",
      "val Data Label (38, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#with tf.device('/gpu:0'):\n",
    "\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "        validation_img = np.load('/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/cancer_non_classification_Numpy/test_set.npy')\n",
    "        validation_lab = np.zeros( [np.shape(validation_img)[0], 2 ])\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img_1.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab_1.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "        validation_img = np.load('/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/cancer_non_classification_Numpy/test_set.npy')\n",
    "        validation_lab = np.zeros( [np.shape(validation_img)[0], 2 ])\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "with tf.device('/gpu:0'):\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1 , shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    def conv2d(x,w,strides_):\n",
    "        return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            b_conv1 = bias_variable([out_ch1])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv1 = bias_variable([out_ch1])\n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        try:\n",
    "            w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        try:\n",
    "            b_conv2= bias_variable([out_ch2])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv2= bias_variable([out_ch2])\n",
    "\n",
    "    with tf.variable_scope('layer3') as scope:\n",
    "        try:\n",
    "            w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer3') as scope:\n",
    "        try:\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "\n",
    "    with tf.variable_scope('layer4') as scope:\n",
    "        try:\n",
    "            w_conv4 =tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer4') as scope:\n",
    "        try:\n",
    "            b_conv4 = bias_variable([out_ch4])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch4])\n",
    "\n",
    "    with tf.variable_scope('layer5') as scope:\n",
    "        try:\n",
    "            w_conv5 = tf.get_variable(\"W5\",[weight_row,weight_col,out_ch4,out_ch5] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W5\" ,[weight_row,weight_col,out_ch4,out_ch5] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer5') as scope:\n",
    "        try:\n",
    "            b_conv5 = bias_variable([out_ch5])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==True:\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            b_conv1 = tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv1 =tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "    with tf.variable_scope(\"layer2\") as scope:\n",
    "        try:\n",
    "            w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "    with tf.variable_scope(\"layer2\") as scope:\n",
    "        try:\n",
    "            b_conv2 = tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv2 =tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "    with tf.variable_scope(\"layer3\") as scope:\n",
    "        try:\n",
    "            w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "    with tf.variable_scope(\"layer3\") as scope:\n",
    "        try:\n",
    "            b_conv3 = tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 =tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "    with tf.variable_scope(\"layer4\") as scope:\n",
    "        try:\n",
    "            w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "    with tf.variable_scope(\"layer4\") as scope:\n",
    "        try:\n",
    "            b_conv4 = tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv4 =tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "    with tf.variable_scope(\"layer5\") as scope:\n",
    "        try:\n",
    "            w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "    with tf.variable_scope(\"layer5\") as scope:\n",
    "        try:\n",
    "            b_conv5 = tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv5 =tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_16:0\", shape=(?, 50, 50, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool_6:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_18:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_19:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool_8:0\", shape=(?, 13, 13, 200), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "#conncect hidden layer \n",
    "with tf.device('/gpu:0'):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image , w_conv1 ,strides_1)+b_conv1)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1 , w_conv2 ,strides_2)+b_conv2)\n",
    "    h_conv2 = max_pool_2x2(h_conv2)#pooling\n",
    "    \n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2 , w_conv3,strides_3)+b_conv3)\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3 , w_conv4,strides_4)+b_conv4)\n",
    "    h_pool4 = max_pool_2x2(h_conv4) #pooling \n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, w_conv5,strides_5)+b_conv5)\n",
    "    h_conv5= max_pool_2x2(h_conv5) #pooling \n",
    "\n",
    "    print h_conv1\n",
    "    print h_conv2\n",
    "    print h_conv3\n",
    "    print h_conv4\n",
    "    print h_conv5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_conv = h_conv5\n",
    "#print conv2d(h_pool1 , w_conv2).get_shape()\n",
    "end_conv_row=int(h_conv5.get_shape()[1])\n",
    "end_conv_col=int(h_conv5.get_shape()[2])\n",
    "end_conv_ch=int(h_conv5.get_shape()[3])\n",
    "#connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            try:\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "\n",
    "        \n",
    "with tf.device('/gpu:0'): # flat conv layer \n",
    "    end_flat_conv =tf.reshape(end_conv, [-1,end_conv_col*end_conv_row*end_conv_ch])\n",
    "   \n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc1 = tf.nn.relu(tf.matmul(end_flat_conv , w_fc1)+ b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 1024)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.load('/home/seongjung/variable_save/w_fc1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            try:\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "\n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1 , w_fc2)+ b_fc2)\n",
    "    h_fc2 = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            try:\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy'),name=\"fc3_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy',name=\"fc3_B\"))\n",
    "\n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2 , w_fc3)+ b_fc3)\n",
    "    h_fc3 = tf.nn.dropout(h_fc3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_fc=h_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope('fc3') as scope:\n",
    "            try:\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes ],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_end = bias_variable([n_classes])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end = bias_variable([n_classes])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            try:\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "\n",
    "with tf.device('/gpu:0'):  # join flat layer with fully  connnected layer \n",
    "    y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recorded at :27\n"
     ]
    }
   ],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "\n",
    "dirname='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/result/'\n",
    "dirname='/home/seongjung/바탕화면/result_temp/'    \n",
    "count=0\n",
    "while(True):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    elif not os.path.isdir(dirname + str(count)):\n",
    "        dirname=dirname+str(count)\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    else:\n",
    "        count+=1\n",
    "print 'it is recorded at :'+str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open(dirname+\"/log.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    print list_files\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_lab.npy', 'test_lab.npy', 'train_lab.npy', 'val_img.npy', 'test_img.npy', 'train_img.npy']\n"
     ]
    }
   ],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img.npy']\n",
      "['train_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_numpy_weight( model_save_path ):\n",
    "    \n",
    "    np_w_conv1,np_w_conv2,np_w_conv3,np_w_conv4,np_w_conv5=sess.run([w_conv1,w_conv2,w_conv3,w_conv4,w_conv5])\n",
    "    np_b_conv1,np_b_conv2,np_b_conv3,np_b_conv4,np_b_conv5=sess.run([b_conv1,b_conv2,b_conv3,b_conv4,b_conv5])\n",
    "    np_w_fc1 , np_w_fc2,np_w_fc3,np_w_end=sess.run([w_fc1 , w_fc2,w_fc3 ,w_end])\n",
    "    np_b_fc1 , np_b_fc2,np_b_fc3,np_b_end=sess.run([b_fc1 , b_fc2,b_fc3,b_end])\n",
    "    \n",
    "    np_w_conv1=np.asarray(np_w_conv1)\n",
    "    np_w_conv2=np.asarray(np_w_conv2)\n",
    "    np_w_conv3=np.asarray(np_w_conv3)\n",
    "    np_w_conv4=np.asarray(np_w_conv4)\n",
    "    np_w_conv5=np.asarray(np_w_conv5)\n",
    "    \n",
    "    np_b_conv1=np.asarray(np_b_conv1)\n",
    "    np_b_conv2=np.asarray(np_b_conv2)\n",
    "    np_b_conv3=np.asarray(np_b_conv3)\n",
    "    np_b_conv4=np.asarray(np_b_conv4)\n",
    "    np_b_conv5=np.asarray(np_b_conv5)\n",
    "    \n",
    "    np_w_fc1=np.asarray(np_w_fc1)\n",
    "    np_w_fc2=np.asarray(np_w_fc2)\n",
    "    np_w_fc3=np.asarray(np_w_fc3)\n",
    "    np_w_end=np.asarray(np_w_end)\n",
    "    \n",
    "    np_b_fc1=np.asarray(np_b_fc1)\n",
    "    np_b_fc2=np.asarray(np_b_fc2)\n",
    "    np_b_fc3=np.asarray(np_b_fc3)\n",
    "    np_b_end=np.asarray(np_b_end)\n",
    "    \n",
    "    \n",
    "    np.save(model_save_path +'w_conv1' , np_w_conv1)\n",
    "    np.save(model_save_path +'w_conv2' , np_w_conv2)\n",
    "    np.save(model_save_path +'w_conv3' , np_w_conv3)\n",
    "    np.save(model_save_path +'w_conv4' , np_w_conv4)\n",
    "    np.save(model_save_path +'w_conv5' , np_w_conv5)\n",
    "    \n",
    "    np.save(model_save_path +'b_conv1' , np_b_conv1)\n",
    "    np.save(model_save_path +'b_conv2' , np_b_conv2)\n",
    "    np.save(model_save_path +'b_conv3' , np_b_conv3)\n",
    "    np.save(model_save_path +'b_conv4' , np_b_conv4)\n",
    "    np.save(model_save_path +'b_conv5' , np_b_conv5)\n",
    "\n",
    "    np.save(model_save_path +'w_fc1' , np_w_fc1)\n",
    "    np.save(model_save_path +'w_fc2' , np_w_fc2)\n",
    "    np.save(model_save_path +'w_fc3' , np_w_fc3)\n",
    "    np.save(model_save_path +'w_end' , np_w_end)\n",
    "    \n",
    "    np.save(model_save_path +'b_fc1' , np_b_fc1)\n",
    "    np.save(model_save_path +'b_fc2' , np_b_fc2)\n",
    "    np.save(model_save_path +'b_fc3' , np_b_fc3)\n",
    "    np.save(model_save_path +'b_end' , np_b_end)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-175-40d100c5e8b7>:19 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "model was saved\n",
      "step 0 , training  accuracy 1\n",
      "step 0 , loss : 0.462306\n",
      "step 0 , validation  accuracy 0.973684\n",
      "step 0 , validation loss : 0.527849\n",
      "step 0 , test  accuracy 0.692308\n",
      "step 0 , test loss : 0.743099\n",
      "--- Training Time : 56.8585119247 ---\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#sm_conv= tf.nn.softmax(y_conv)\n",
    "    #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    start_time = time.time()\n",
    "\n",
    "    regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "    pred=tf.nn.softmax(y_conv)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "with tf.device('/gpu:0'):\n",
    "    cost = cost+regular\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "batch_count=0\n",
    "max_acc=0\n",
    "if divide_flag ==True:\n",
    "    n_batch =len(train_images)\n",
    "    batch_count=0\n",
    "show_Exception_flag=True\n",
    "val_acc_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "train_loss_list=[]\n",
    "for i in range(iterate):    \n",
    "    if divide_flag ==True:\n",
    "        if batch_count >= n_batch:\n",
    "            batch_count =0\n",
    "        train_img =np.load(file_locate+train_images[batch_count])\n",
    "        train_lab =np.load(file_locate+train_labels[batch_count])\n",
    "    batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)\n",
    "   # batch_val_xs  , batch_val_ys = next_batch(20 , val_img , val_lab)\n",
    "\n",
    "    if i%100 ==0: # in here add to validation \n",
    "        try:\n",
    "            val_accuracy = sess.run( accuracy , feed_dict={x:val_img , y_:val_lab , keep_prob: 1.0})        \n",
    "            val_loss = sess.run(cost , feed_dict = {x:val_img , y_: val_lab , keep_prob: 1.0})\n",
    "            train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "            train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "            test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})\n",
    "            \n",
    "            val_acc_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "            train_acc_list.append(train_accuracy)\n",
    "            train_loss_list.append(train_loss)\n",
    "            \n",
    "            if (val_accuracy+test_accuracy)/2 > max_acc:\n",
    "                print 'model was saved'\n",
    "                if save_flag == True:\n",
    "                    save_numpy_weight(model_save_path)\n",
    "                max_acc=(val_accuracy+test_accuracy)/2\n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "            print(\"step %d , test  accuracy %g\" %(i,test_accuracy))\n",
    "            print(\"step %d , test loss : %g\" %(i,test_loss))\n",
    "            \n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            if divide_flag ==True:\n",
    "                batch_count+=1\n",
    "        except Exception as e:\n",
    "            if show_Exception_flag:\n",
    "                print str(e)\n",
    "                show_Exception_flag=False\n",
    "            \n",
    "            list_acc=[]\n",
    "            list_loss=[]\n",
    "            n_divide=len(val_img)/batch_size\n",
    "            j=0\n",
    "            for j in range(n_divide):\n",
    "                # j*batch_size :(j+1)*batch_size\n",
    "                val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :(j+1)*batch_size] , y_:val_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                list_acc.append(float(val_accuracy))\n",
    "                list_loss.append(float(val_loss))\n",
    "            val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "            list_acc=np.asarray(list_acc)\n",
    "            list_loss= np.asarray(list_loss)\n",
    "            val_accuracy=np.mean(list_acc)\n",
    "            val_loss = np.mean(list_loss)\n",
    "            \n",
    "            val_acc_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "\n",
    "                        \n",
    "            list_acc=[]\n",
    "            list_loss=[]                \n",
    "            for j in range(n_divide):    \n",
    "                # j*batch_size :(j+1)*batch_size\n",
    "                test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                list_acc.append(float(test_accuracy))\n",
    "                list_loss.append(float(test_loss))\n",
    "            #right above code have to modify\n",
    "            test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "            list_acc.append(test_accuracy)\n",
    "            list_loss.append(test_loss)\n",
    "            \n",
    "\n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            \n",
    "            train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "            train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "            train_acc_list.append(train_accuracy)\n",
    "            train_loss_list.append(train_loss)\n",
    "            \n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "            \n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "            print(\"step %d , test  accuracy %g\" %(i,test_accuracy))\n",
    "            print(\"step %d , test loss : %g\" %(i,test_loss))           \n",
    "            \n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            batch_count+=1\n",
    "            \n",
    "            val_acc_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "            train_acc_list.append(train_accuracy)\n",
    "            train_loss_list.append(train_loss)    \n",
    "\n",
    "        sess.run(train_step ,feed_dict={x:batch_xs , y_:batch_ys , keep_prob : 0.7})\n",
    "\n",
    "np.save(model_save_path+'val_acc',np.asarray(val_acc_list))\n",
    "np.save(model_save_path+'val_loss',np.asarray(val_loss_list))\n",
    "np.save(model_save_path+'train_acc',np.asarray(train_acc_list))\n",
    "np.save(model_save_path+'train_loss',np.asarray(train_loss_list))\n",
    "\n",
    "softmax_val=sess.run( pred , feed_dict={x:val_img  ,y_:val_lab, keep_prob: 1.0})\n",
    "softmax_test=sess.run( pred , feed_dict={x:test_img  ,y_:test_lab, keep_prob: 1.0})\n",
    "softmax_validation=sess.run( pred , feed_dict={x:validation_img  ,y_:validation_lab, keep_prob: 1.0})\n",
    "test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})\n",
    "print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "f.write(train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_pred_np=np.asarray(softmax_test)\n",
    "softmax_pred_cls_np=np.zeros( [len(softmax_pred_np) , 2])\n",
    "for i in range(len(softmax_pred_np)):\n",
    "    if softmax_pred_np[i , 0] >softmax_pred_np[i , 1]:\n",
    "        softmax_pred_cls_np[i , 0:1] =1\n",
    "    elif softmax_pred_np[i , 0] <softmax_pred_np[i , 1]:\n",
    "        \n",
    "        softmax_pred_cls_np[i , 1:2] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "28\n",
      "0.717948717949\n"
     ]
    }
   ],
   "source": [
    "accuracy_np = np.equal(softmax_pred_cls_np , test_lab)\n",
    "count=0\n",
    "print len(accuracy_np)\n",
    "for i in range(len(accuracy_np)):\n",
    "    if accuracy_np[i,0]==True:\n",
    "        count+=1\n",
    "print count\n",
    "print float(count)/float(len(test_lab))\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_pred=softmax_pred_np[:,0]\n",
    "roc_true=test_lab[:,0]          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278436 0.72178\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFdCAYAAACNYC65AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15cf22ca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "score = roc_pred\n",
    "y = roc_true\n",
    "\n",
    "roc_x = []\n",
    "roc_y = []\n",
    "min_score = min(score)\n",
    "max_score = max(score)\n",
    "print min_score , max_score\n",
    "thr = np.linspace(min_score, max_score, 30)\n",
    "FP=0\n",
    "TP=0\n",
    "N = sum(y)\n",
    "P = len(y) - N\n",
    "\n",
    "for (i, T) in enumerate(thr):\n",
    "    for i in range(0, len(score)):\n",
    "        if (score[i] > T):\n",
    "            if (y[i]==1):\n",
    "                TP = TP + 1\n",
    "            if (y[i]==0):\n",
    "                FP = FP + 1\n",
    "    roc_x.append(FP/float(N))\n",
    "    roc_y.append(TP/float(P))\n",
    "    FP=0\n",
    "    TP=0\n",
    "plt.scatter(roc_x, roc_y)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "test_img=np.load('/home/seongjung/save_numpy/1.npy')\n",
    "print np.shape(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_pred_cls_np[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  7]\n",
      " [ 4 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "roc_pred_list =list(softmax_pred_cls_np[:,0])\n",
    "roc_true_list =list(roc_true)\n",
    "cm=confusion_matrix(roc_true_list, roc_pred_list)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_pred_np=np.asarray(softmax_val)\n",
    "softmax_pred_cls_np=np.zeros( [len(softmax_pred_np) , 2])\n",
    "for i in range(len(softmax_pred_np)):\n",
    "    if softmax_pred_np[i , 0] >softmax_pred_np[i , 1]:\n",
    "        softmax_pred_cls_np[i , 0:1] =1\n",
    "    elif softmax_pred_np[i , 0] <softmax_pred_np[i , 1]:\n",
    "        \n",
    "        softmax_pred_cls_np[i , 1:2] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "36\n",
      "0.923076923077\n"
     ]
    }
   ],
   "source": [
    "accuracy_np = np.equal(softmax_pred_cls_np , val_lab)\n",
    "count=0\n",
    "print len(accuracy_np)\n",
    "for i in range(len(accuracy_np)):\n",
    "    if accuracy_np[i,0]==True:\n",
    "        count+=1\n",
    "print count\n",
    "print float(count)/float(len(test_lab))\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_pred=softmax_pred_np[:,0]\n",
    "roc_true=val_lab[:,0]          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.279934 0.718563\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAFkCAYAAACThxm6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15ce921050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "score = roc_pred\n",
    "y = roc_true\n",
    "\n",
    "roc_x = []\n",
    "roc_y = []\n",
    "min_score = min(score)\n",
    "max_score = max(score)\n",
    "print min_score , max_score\n",
    "thr = np.linspace(min_score, max_score, 30)\n",
    "FP=0\n",
    "TP=0\n",
    "N = sum(y)\n",
    "P = len(y) - N\n",
    "\n",
    "for (i, T) in enumerate(thr):\n",
    "    for i in range(0, len(score)):\n",
    "        if (score[i] > T):\n",
    "            if (y[i]==1):\n",
    "                TP = TP + 1\n",
    "            if (y[i]==0):\n",
    "                FP = FP + 1\n",
    "    roc_x.append(FP/float(N))\n",
    "    roc_y.append(TP/float(P))\n",
    "    FP=0\n",
    "    TP=0\n",
    "plt.scatter(roc_x, roc_y)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_pred_cls_np[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  2]\n",
      " [ 0 20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "roc_pred_list =list(softmax_pred_cls_np[:,0])\n",
    "roc_true_list =list(roc_true)\n",
    "cm=confusion_matrix(roc_true_list, roc_pred_list)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_confusion_mat(true_ , pred_cls):\n",
    "    roc_pred_list =list(pred_cls[:,0])\n",
    "    roc_true_list =list(true_[:,0] )\n",
    "    cm=confusion_matrix(roc_true_list, roc_pred_list)\n",
    "    print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred_cls(softmax_,thred):\n",
    "    softmax_pred_np=np.asarray(softmax_)\n",
    "    softmax_pred_cls_np=np.zeros( [len(softmax_pred_np) , 2])\n",
    "    for i in range(len(softmax_pred_np)):\n",
    "        \n",
    "        if softmax_pred_np[i , 0] >thred:\n",
    "            softmax_pred_cls_np[i , 0:1] =1\n",
    "            softmax_pred_cls_np[i , 1:2] =0\n",
    "        elif softmax_pred_np[i , 0] <thred:\n",
    "            softmax_pred_cls_np[i , 0:1] =0\n",
    "            softmax_pred_cls_np[i , 1:2] =1\n",
    "    return softmax_pred_cls_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_cls=get_pred_cls(softmax_validation , thred=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patient_val=np.zeros([62,2])\n",
    "patient_val[0,:]=np.mean(softmax_validation[0:4] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patient_val[1,:]=np.mean(softmax_validation[4:18] , axis =0)\n",
    "patient_val[2,:]=np.mean(softmax_validation[18:21] , axis =0)\n",
    "patient_val[3,:]=np.mean(softmax_validation[21:27] , axis =0)\n",
    "patient_val[4,:]=np.mean(softmax_validation[27:29] , axis =0) #5\n",
    "patient_val[5,:]=np.mean(softmax_validation[29:32] , axis =0)#6\n",
    "patient_val[6,:]=np.mean(softmax_validation[32:35] , axis =0)#7\n",
    "patient_val[7,:]=np.mean(softmax_validation[35:38] , axis =0)#8\n",
    "patient_val[8,:]=np.mean(softmax_validation[38:49] , axis =0)\n",
    "patient_val[9,:]=np.mean(softmax_validation[49:52] , axis =0) #10\n",
    "patient_val[10,:]=np.mean(softmax_validation[52:53] , axis =0)#11\n",
    "patient_val[11,:]=np.mean(softmax_validation[53:65] , axis =0)\n",
    "patient_val[12,:]=np.mean(softmax_validation[65:74] , axis =0)\n",
    "patient_val[13,:]=np.mean(softmax_validation[74:77] , axis =0)\n",
    "patient_val[14,:]=np.mean(softmax_validation[74:83] , axis =0)#15\n",
    "patient_val[15,:]=np.mean(softmax_validation[83:85] , axis =0)\n",
    "patient_val[16,:]=np.mean(softmax_validation[85:87] , axis =0)\n",
    "patient_val[17,:]=np.mean(softmax_validation[87:89] , axis =0)\n",
    "patient_val[18,:]=np.mean(softmax_validation[89:92] , axis =0)\n",
    "patient_val[19,:]=np.mean(softmax_validation[92:95] , axis =0)#20\n",
    "patient_val[20,:]=np.mean(softmax_validation[95:97] , axis =0)#21\n",
    "patient_val[21,:]=np.mean(softmax_validation[97:103] , axis =0)\n",
    "patient_val[22,:]=np.mean(softmax_validation[103:109] , axis =0)\n",
    "patient_val[23,:]=np.mean(softmax_validation[109:110] , axis =0)\n",
    "patient_val[24,:]=np.mean(softmax_validation[110:113] , axis =0)\n",
    "patient_val[25,:]=np.mean(softmax_validation[113:130] , axis =0)\n",
    "patient_val[26,:]=np.mean(softmax_validation[130:135] , axis =0)\n",
    "patient_val[27,:]=np.mean(softmax_validation[135:138] , axis =0)\n",
    "patient_val[28,:]=np.mean(softmax_validation[138:140] , axis =0)\n",
    "patient_val[29,:]=np.mean(softmax_validation[140:148] , axis =0)\n",
    "patient_val[30,:]=np.mean(softmax_validation[148:154] , axis =0)\n",
    "patient_val[31,:]=np.mean(softmax_validation[154:158] , axis =0)\n",
    "patient_val[32,:]=np.mean(softmax_validation[158:170] , axis =0)\n",
    "patient_val[33,:]=np.mean(softmax_validation[170:196] , axis =0)\n",
    "patient_val[34,:]=np.mean(softmax_validation[196:203] , axis =0)\n",
    "patient_val[35,:]=np.mean(softmax_validation[203:208] , axis =0)\n",
    "patient_val[36,:]=np.mean(softmax_validation[208:215] , axis =0)\n",
    "patient_val[37,:]=np.mean(softmax_validation[215:217] , axis =0)\n",
    "patient_val[38,:]=np.mean(softmax_validation[217:219] , axis =0)\n",
    "patient_val[39,:]=np.mean(softmax_validation[219:224] , axis =0)\n",
    "patient_val[40,:]=np.mean(softmax_validation[224:252] , axis =0)\n",
    "patient_val[41,:]=np.mean(softmax_validation[252:256] , axis =0)\n",
    "patient_val[42,:]=np.mean(softmax_validation[256:259] , axis =0)\n",
    "patient_val[43,:]=np.mean(softmax_validation[259:271] , axis =0)\n",
    "patient_val[44,:]=np.mean(softmax_validation[271:274] , axis =0)\n",
    "patient_val[45,:]=np.mean(softmax_validation[274:276] , axis =0)\n",
    "patient_val[46,:]=np.mean(softmax_validation[276:282] , axis =0)\n",
    "patient_val[47,:]=np.mean(softmax_validation[282:284] , axis =0)\n",
    "patient_val[48,:]=np.mean(softmax_validation[284:289] , axis =0)\n",
    "patient_val[49,:]=np.mean(softmax_validation[289:292] , axis =0)\n",
    "patient_val[50,:]=np.mean(softmax_validation[292:297] , axis =0)\n",
    "patient_val[51,:]=np.mean(softmax_validation[297:307] , axis =0)\n",
    "patient_val[52,:]=np.mean(softmax_validation[307:309] , axis =0)\n",
    "patient_val[53,:]=np.mean(softmax_validation[309:313] , axis =0)\n",
    "patient_val[54,:]=np.mean(softmax_validation[313:319] , axis =0)\n",
    "patient_val[55,:]=np.mean(softmax_validation[319:321] , axis =0)\n",
    "patient_val[56,:]=np.mean(softmax_validation[321:325] , axis =0)\n",
    "patient_val[57,:]=np.mean(softmax_validation[321:334] , axis =0)\n",
    "patient_val[58,:]=np.mean(softmax_validation[334:336] , axis =0)\n",
    "patient_val[59,:]=np.mean(softmax_validation[336:342] , axis =0)\n",
    "patient_val[60,:]=np.mean(softmax_validation[342:347] , axis =0)\n",
    "patient_val[61,:]=np.mean(softmax_validation[347:352] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.53794956  0.46205044]\n",
      " [ 0.71349442  0.28650555]\n",
      " [ 0.39050546  0.60949451]\n",
      " [ 0.64365083  0.35634914]\n",
      " [ 0.47939426  0.52060574]\n",
      " [ 0.28096727  0.7190327 ]\n",
      " [ 0.53442639  0.46557364]\n",
      " [ 0.71784371  0.28215626]\n",
      " [ 0.67916566  0.32083431]\n",
      " [ 0.7169978   0.28300226]\n",
      " [ 0.71916556  0.28083447]\n",
      " [ 0.65966207  0.34033787]\n",
      " [ 0.70684057  0.29315946]\n",
      " [ 0.34316158  0.65683848]\n",
      " [ 0.49552473  0.5044753 ]\n",
      " [ 0.67928374  0.32071632]\n",
      " [ 0.71577513  0.2842249 ]\n",
      " [ 0.49892351  0.50107652]\n",
      " [ 0.53994578  0.46005425]\n",
      " [ 0.58959234  0.41040766]\n",
      " [ 0.71747208  0.28252786]\n",
      " [ 0.58612889  0.41387105]\n",
      " [ 0.49683914  0.50316089]\n",
      " [ 0.71785223  0.28214774]\n",
      " [ 0.64273053  0.35726944]\n",
      " [ 0.56768888  0.43231115]\n",
      " [ 0.28236121  0.71763873]\n",
      " [ 0.57154614  0.42845383]\n",
      " [ 0.49888986  0.50111014]\n",
      " [ 0.53840595  0.46159399]\n",
      " [ 0.50278765  0.49721238]\n",
      " [ 0.71658301  0.28341702]\n",
      " [ 0.71694607  0.28305396]\n",
      " [ 0.64004731  0.35995272]\n",
      " [ 0.66496009  0.33503991]\n",
      " [ 0.71682084  0.28317922]\n",
      " [ 0.6369316   0.36306834]\n",
      " [ 0.71739101  0.28260899]\n",
      " [ 0.71663475  0.28336522]\n",
      " [ 0.49317068  0.50682938]\n",
      " [ 0.66157609  0.33842379]\n",
      " [ 0.71347547  0.28652456]\n",
      " [ 0.56640434  0.43359566]\n",
      " [ 0.65081412  0.34918585]\n",
      " [ 0.71229714  0.28770283]\n",
      " [ 0.65583646  0.34416357]\n",
      " [ 0.63836879  0.36163116]\n",
      " [ 0.66934025  0.33065975]\n",
      " [ 0.63350767  0.3664923 ]\n",
      " [ 0.71624678  0.28375328]\n",
      " [ 0.62400979  0.37599021]\n",
      " [ 0.63908505  0.36091498]\n",
      " [ 0.71795487  0.28204519]\n",
      " [ 0.4987421   0.5012579 ]\n",
      " [ 0.57981139  0.42018864]\n",
      " [ 0.71717989  0.28282005]\n",
      " [ 0.60429549  0.39570457]\n",
      " [ 0.5441888   0.4558112 ]\n",
      " [ 0.66521001  0.33478999]\n",
      " [ 0.33164805  0.66835195]\n",
      " [ 0.71151477  0.28848523]\n",
      " [ 0.45199841  0.54800147]]\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print patient_val\n",
    "print len(patient_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "pred_cls=get_pred_cls(patient_val , thred=0.5)\n",
    "print pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
