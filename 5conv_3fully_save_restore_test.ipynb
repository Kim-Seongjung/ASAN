{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 100, 100, 3)\n",
      "(38, 2)\n",
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_locate='/home/seongjung/바탕화면/Numpy_ASAN/Mal_vs_Benign/100_100/0/0/'\n",
    "test_img = np.load(file_locate+'val_img.npy')\n",
    "test_lab = np.load(file_locate+'val_lab.npy')\n",
    "\n",
    "\n",
    "\"\"\"val_img =np.load(file_locate+'val_img.npy')\n",
    "test_img = np.concatenate((val_img , test_img) , axis=0 )\n",
    "test_lab = np.load(file_locate+'test_lab.npy')\n",
    "val_lab =np.load(file_locate+'val_lab.npy')\n",
    "test_lab = np.concatenate((val_lab , test_lab) , axis=0 )\n",
    "\"\"\"\n",
    "\n",
    "print np.shape(test_img)\n",
    "\n",
    "print np.shape(test_lab)\n",
    "img_row =100\n",
    "img_col=100\n",
    "    \n",
    "divide_flag= False\n",
    "restore_flag =True\n",
    "#2_4\n",
    "#model_save_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/0_0/'\n",
    "restore_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/0_0/'\n",
    "name=restore_path.split('/')[-2]\n",
    "batch_size=30\n",
    "print img_row ,img_col\n",
    "n_classes =2\n",
    "in_ch =3\n",
    "out_ch1=200\n",
    "out_ch2=200\n",
    "out_ch3=200\n",
    "out_ch4=200\n",
    "out_ch5=200\n",
    "\n",
    "\n",
    "fully_ch1=1024\n",
    "fully_ch2 =1024\n",
    "fully_ch3 =1024\n",
    "\n",
    "\n",
    "\n",
    "strides_1=[1,2,2,1]\n",
    "strides_2=[1,1,1,1]\n",
    "strides_3=[1,1,1,1]\n",
    "strides_4=[1,1,1,1]\n",
    "strides_5=[1,1,1,1]\n",
    "\n",
    "\n",
    "x= tf.placeholder(\"float\",shape=[None,img_col , img_row , 3],  name = 'x-input')\n",
    "#y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,3])\n",
    "\n",
    "iterate=100000\n",
    "\n",
    "\n",
    "\n",
    "weight_row =3 ; weight_col=3\n",
    "\n",
    "\n",
    "\n",
    "print img_col , img_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Weight and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "with tf.device('/gpu:0'):\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1 , shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    def conv2d(x,w,strides_):\n",
    "        return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            b_conv1 = bias_variable([out_ch1])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv1 = bias_variable([out_ch1])\n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        try:\n",
    "            w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        try:\n",
    "            b_conv2= bias_variable([out_ch2])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv2= bias_variable([out_ch2])\n",
    "\n",
    "    with tf.variable_scope('layer3') as scope:\n",
    "        try:\n",
    "            w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer3') as scope:\n",
    "        try:\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "\n",
    "    with tf.variable_scope('layer4') as scope:\n",
    "        try:\n",
    "            w_conv4 =tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer4') as scope:\n",
    "        try:\n",
    "            b_conv4 = bias_variable([out_ch4])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "\n",
    "    with tf.variable_scope('layer5') as scope:\n",
    "        try:\n",
    "            w_conv5 = tf.get_variable(\"W5\",[weight_row,weight_col,out_ch4,out_ch5] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W5\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer5') as scope:\n",
    "        try:\n",
    "            b_conv5 = bias_variable([out_ch5])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==True:\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            b_conv1 = tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv1 =tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "    with tf.variable_scope(\"layer2\") as scope:\n",
    "        try:\n",
    "            w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "    with tf.variable_scope(\"layer2\") as scope:\n",
    "        try:\n",
    "            b_conv2 = tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv2 =tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "    with tf.variable_scope(\"layer3\") as scope:\n",
    "        try:\n",
    "            w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "    with tf.variable_scope(\"layer3\") as scope:\n",
    "        try:\n",
    "            b_conv3 = tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 =tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "    with tf.variable_scope(\"layer4\") as scope:\n",
    "        try:\n",
    "            w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "    with tf.variable_scope(\"layer4\") as scope:\n",
    "        try:\n",
    "            b_conv4 = tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv4 =tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "    with tf.variable_scope(\"layer5\") as scope:\n",
    "        try:\n",
    "            w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "    with tf.variable_scope(\"layer5\") as scope:\n",
    "        try:\n",
    "            b_conv5 = tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv5 =tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_8:0\", shape=(?, 50, 50, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_10:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_11:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool_5:0\", shape=(?, 13, 13, 200), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "#conncect hidden layer \n",
    "with tf.device('/gpu:0'):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image , w_conv1 ,strides_1)+b_conv1)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1 , w_conv2 ,strides_2)+b_conv2)\n",
    "    h_conv2 = max_pool_2x2(h_conv2)#pooling\n",
    "    \n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2 , w_conv3,strides_3)+b_conv3)\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3 , w_conv4,strides_4)+b_conv4)\n",
    "    h_pool4 = max_pool_2x2(h_conv4) #pooling \n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, w_conv5,strides_5)+b_conv5)\n",
    "    h_conv5= max_pool_2x2(h_conv5) #pooling \n",
    "\n",
    "    print h_conv1\n",
    "    print h_conv2\n",
    "    print h_conv3\n",
    "    print h_conv4\n",
    "    print h_conv5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_conv = h_conv5\n",
    "#print conv2d(h_pool1 , w_conv2).get_shape()\n",
    "end_conv_row=int(h_conv5.get_shape()[1])\n",
    "end_conv_col=int(h_conv5.get_shape()[2])\n",
    "end_conv_ch=int(h_conv5.get_shape()[3])\n",
    "#connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            try:\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "\n",
    "        \n",
    "with tf.device('/gpu:0'): # flat conv layer \n",
    "    end_flat_conv =tf.reshape(end_conv, [-1,end_conv_col*end_conv_row*end_conv_ch])\n",
    "   \n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc1 = tf.nn.relu(tf.matmul(end_flat_conv , w_fc1)+ b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 1024)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.load('/home/seongjung/variable_save/w_fc1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            try:\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "\n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1 , w_fc2)+ b_fc2)\n",
    "    h_fc2 = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            try:\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy'),name=\"fc3_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy',name=\"fc3_B\"))\n",
    "\n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2 , w_fc3)+ b_fc3)\n",
    "    h_fc3 = tf.nn.dropout(h_fc3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_fc=h_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope('fc3') as scope:\n",
    "            try:\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes ],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_end = bias_variable([n_classes])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end = bias_variable([n_classes])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            try:\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "\n",
    "with tf.device('/gpu:0'):  # join flat layer with fully  connnected layer \n",
    "    y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    print list_files\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_numpy_weight( model_save_path ):\n",
    "    \n",
    "    np_w_conv1,np_w_conv2,np_w_conv3,np_w_conv4,np_w_conv5=sess.run([w_conv1,w_conv2,w_conv3,w_conv4,w_conv5])\n",
    "    np_b_conv1,np_b_conv2,np_b_conv3,np_b_conv4,np_b_conv5=sess.run([b_conv1,b_conv2,b_conv3,b_conv4,b_conv5])\n",
    "    np_w_fc1 , np_w_fc2,np_w_fc3,np_w_end=sess.run([w_fc1 , w_fc2,w_fc3 ,w_end])\n",
    "    np_b_fc1 , np_b_fc2,np_b_fc3,np_b_end=sess.run([b_fc1 , b_fc2,b_fc3,b_end])\n",
    "    \n",
    "    np_w_conv1=np.asarray(np_w_conv1)\n",
    "    np_w_conv2=np.asarray(np_w_conv2)\n",
    "    np_w_conv3=np.asarray(np_w_conv3)\n",
    "    np_w_conv4=np.asarray(np_w_conv4)\n",
    "    np_w_conv5=np.asarray(np_w_conv5)\n",
    "    \n",
    "    np_b_conv1=np.asarray(np_b_conv1)\n",
    "    np_b_conv2=np.asarray(np_b_conv2)\n",
    "    np_b_conv3=np.asarray(np_b_conv3)\n",
    "    np_b_conv4=np.asarray(np_b_conv4)\n",
    "    np_b_conv5=np.asarray(np_b_conv5)\n",
    "    \n",
    "    np_w_fc1=np.asarray(np_w_fc1)\n",
    "    np_w_fc2=np.asarray(np_w_fc2)\n",
    "    np_w_fc3=np.asarray(np_w_fc3)\n",
    "    np_w_end=np.asarray(np_w_end)\n",
    "    \n",
    "    np_b_fc1=np.asarray(np_b_fc1)\n",
    "    np_b_fc2=np.asarray(np_b_fc2)\n",
    "    np_b_fc3=np.asarray(np_b_fc3)\n",
    "    np_b_end=np.asarray(np_b_end)\n",
    "    \n",
    "    \n",
    "    np.save(model_save_path +'w_conv1' , np_w_conv1)\n",
    "    np.save(model_save_path +'w_conv2' , np_w_conv2)\n",
    "    np.save(model_save_path +'w_conv3' , np_w_conv3)\n",
    "    np.save(model_save_path +'w_conv4' , np_w_conv4)\n",
    "    np.save(model_save_path +'w_conv5' , np_w_conv5)\n",
    "    \n",
    "    np.save(model_save_path +'b_conv1' , np_b_conv1)\n",
    "    np.save(model_save_path +'b_conv2' , np_b_conv2)\n",
    "    np.save(model_save_path +'b_conv3' , np_b_conv3)\n",
    "    np.save(model_save_path +'b_conv4' , np_b_conv4)\n",
    "    np.save(model_save_path +'b_conv5' , np_b_conv5)\n",
    "\n",
    "    np.save(model_save_path +'w_fc1' , np_w_fc1)\n",
    "    np.save(model_save_path +'w_fc2' , np_w_fc2)\n",
    "    np.save(model_save_path +'w_fc3' , np_w_fc3)\n",
    "    np.save(model_save_path +'w_end' , np_w_end)\n",
    "    \n",
    "    np.save(model_save_path +'b_fc1' , np_b_fc1)\n",
    "    np.save(model_save_path +'b_fc2' , np_b_fc2)\n",
    "    np.save(model_save_path +'b_fc3' , np_b_fc3)\n",
    "    np.save(model_save_path +'b_end' , np_b_end)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-60-6b5a4dc8564e>:11 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#sm_conv= tf.nn.softmax(y_conv)\n",
    "    #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    start_time = time.time()\n",
    "\n",
    "    regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "    pred=tf.nn.softmax(y_conv)\n",
    "    pred_cls = tf.argmax(y_conv ,1)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n",
    "    softmax_pred= sess.run( pred , feed_dict={x:test_img  , keep_prob: 1.0})        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 2)\n",
      "[[ 0.28212392  0.71787608]\n",
      " [ 0.71789473  0.28210527]\n",
      " [ 0.62942225  0.37057775]\n",
      " [ 0.28238854  0.71761143]\n",
      " [ 0.28182077  0.71817923]\n",
      " [ 0.4516035   0.54839647]\n",
      " [ 0.28369328  0.71630675]\n",
      " [ 0.71634513  0.2836549 ]\n",
      " [ 0.28230771  0.71769226]\n",
      " [ 0.71389335  0.28610662]\n",
      " [ 0.28190592  0.71809405]\n",
      " [ 0.71589875  0.28410128]\n",
      " [ 0.71771961  0.28228033]\n",
      " [ 0.28247997  0.71752   ]\n",
      " [ 0.7156415   0.2843585 ]\n",
      " [ 0.71654803  0.28345188]\n",
      " [ 0.71597075  0.28402928]\n",
      " [ 0.28173211  0.71826786]\n",
      " [ 0.28198841  0.71801162]\n",
      " [ 0.71784627  0.28215376]\n",
      " [ 0.71617758  0.28382242]\n",
      " [ 0.28141966  0.71858031]\n",
      " [ 0.31366456  0.68633544]\n",
      " [ 0.71595985  0.28404012]\n",
      " [ 0.65987861  0.34012136]\n",
      " [ 0.28276071  0.71723926]\n",
      " [ 0.55909795  0.44090205]\n",
      " [ 0.28288627  0.71711373]\n",
      " [ 0.28226629  0.71773368]\n",
      " [ 0.71616489  0.2838352 ]\n",
      " [ 0.71550828  0.28449166]\n",
      " [ 0.7163077   0.28369233]\n",
      " [ 0.28176135  0.71823865]\n",
      " [ 0.71584213  0.28415787]\n",
      " [ 0.36881378  0.63118625]\n",
      " [ 0.71583873  0.28416118]\n",
      " [ 0.66448987  0.33551008]\n",
      " [ 0.71724463  0.28275535]]\n"
     ]
    }
   ],
   "source": [
    "softmax_pred_np=np.asarray(softmax_pred)\n",
    "softmax_pred_cls_np=np.zeros([len(softmax_pred_np) , 2])\n",
    "print np.shape(softmax_pred_cls_np)\n",
    "print softmax_pred_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(softmax_pred_np)):\n",
    "    if softmax_pred_np[i , 0] >softmax_pred_np[i , 1]:\n",
    "        softmax_pred_cls_np[i , 0:1] =1\n",
    "    elif softmax_pred_np[i , 0] <softmax_pred_np[i , 1]:\n",
    "        \n",
    "        softmax_pred_cls_np[i , 1:2] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "37\n",
      "0.973684210526\n"
     ]
    }
   ],
   "source": [
    "accuracy_np = np.equal(softmax_pred_cls_np , test_lab)\n",
    "count=0\n",
    "print len(accuracy_np)\n",
    "for i in range(len(accuracy_np)):\n",
    "    if accuracy_np[i,0]==True:\n",
    "        count+=1\n",
    "print count\n",
    "print float(count)/float(len(test_lab))\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_pred=softmax_pred_np[:,0]\n",
    "roc_true=test_lab[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28142 0.717895\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAFkCAYAAACThxm6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137813a490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "score = roc_pred\n",
    "y = roc_true\n",
    "\n",
    "roc_x = []\n",
    "roc_y = []\n",
    "min_score = min(score)\n",
    "max_score = max(score)\n",
    "print min_score , max_score\n",
    "thr = np.linspace(min_score, max_score, 30)\n",
    "FP=0\n",
    "TP=0\n",
    "N = sum(y)\n",
    "P = len(y) - N\n",
    "\n",
    "for (i, T) in enumerate(thr):\n",
    "    for i in range(0, len(score)):\n",
    "        if (score[i] > T):\n",
    "            if (y[i]==1):\n",
    "                TP = TP + 1\n",
    "            if (y[i]==0):\n",
    "                FP = FP + 1\n",
    "    roc_x.append(FP/float(N))\n",
    "    roc_y.append(TP/float(P))\n",
    "    FP=0\n",
    "    TP=0\n",
    "plt.scatter(roc_x, roc_y)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_pred_cls_np[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "roc_pred_list =list(softmax_pred_cls_np[:,0])\n",
    "roc_true_list =list(roc_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  1]\n",
      " [ 0 20]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(roc_true_list, roc_pred_list)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_pred_np=np.asarray(softmax_pred)\n",
    "np_save_folder='/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/Softmax_np/'\n",
    "np.save(np_save_folder+name,softmax_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28212392,  0.71787608],\n",
       "       [ 0.71789473,  0.28210527],\n",
       "       [ 0.62942225,  0.37057775],\n",
       "       [ 0.28238854,  0.71761143],\n",
       "       [ 0.28182077,  0.71817923],\n",
       "       [ 0.4516035 ,  0.54839647],\n",
       "       [ 0.28369328,  0.71630675],\n",
       "       [ 0.71634513,  0.2836549 ],\n",
       "       [ 0.28230771,  0.71769226],\n",
       "       [ 0.71389335,  0.28610662],\n",
       "       [ 0.28190592,  0.71809405],\n",
       "       [ 0.71589875,  0.28410128],\n",
       "       [ 0.71771961,  0.28228033],\n",
       "       [ 0.28247997,  0.71752   ],\n",
       "       [ 0.7156415 ,  0.2843585 ],\n",
       "       [ 0.71654803,  0.28345188],\n",
       "       [ 0.71597075,  0.28402928],\n",
       "       [ 0.28173211,  0.71826786],\n",
       "       [ 0.28198841,  0.71801162],\n",
       "       [ 0.71784627,  0.28215376],\n",
       "       [ 0.71617758,  0.28382242],\n",
       "       [ 0.28141966,  0.71858031],\n",
       "       [ 0.31366456,  0.68633544],\n",
       "       [ 0.71595985,  0.28404012],\n",
       "       [ 0.65987861,  0.34012136],\n",
       "       [ 0.28276071,  0.71723926],\n",
       "       [ 0.55909795,  0.44090205],\n",
       "       [ 0.28288627,  0.71711373],\n",
       "       [ 0.28226629,  0.71773368],\n",
       "       [ 0.71616489,  0.2838352 ],\n",
       "       [ 0.71550828,  0.28449166],\n",
       "       [ 0.7163077 ,  0.28369233],\n",
       "       [ 0.28176135,  0.71823865],\n",
       "       [ 0.71584213,  0.28415787],\n",
       "       [ 0.36881378,  0.63118625],\n",
       "       [ 0.71583873,  0.28416118],\n",
       "       [ 0.66448987,  0.33551008],\n",
       "       [ 0.71724463,  0.28275535]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/Softmax_np/0_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50941229,  0.49058771],\n",
       "       [ 0.43891898,  0.56108105],\n",
       "       [ 0.37799591,  0.62200403],\n",
       "       [ 0.70078057,  0.29921952],\n",
       "       [ 0.71415222,  0.28584781],\n",
       "       [ 0.71756274,  0.28243729],\n",
       "       [ 0.68068248,  0.31931755],\n",
       "       [ 0.71232474,  0.28767523],\n",
       "       [ 0.73285276,  0.26714724],\n",
       "       [ 0.73301286,  0.26698714],\n",
       "       [ 0.72139841,  0.27860162],\n",
       "       [ 0.65489841,  0.34510159],\n",
       "       [ 0.72141153,  0.2785885 ],\n",
       "       [ 0.70857787,  0.29142213],\n",
       "       [ 0.66585028,  0.33414972],\n",
       "       [ 0.71356505,  0.28643492],\n",
       "       [ 0.71167392,  0.28832608],\n",
       "       [ 0.71821624,  0.28178376],\n",
       "       [ 0.55373955,  0.44626039],\n",
       "       [ 0.67995417,  0.32004589],\n",
       "       [ 0.72010183,  0.27989817],\n",
       "       [ 0.72032446,  0.27967557],\n",
       "       [ 0.72601742,  0.27398258],\n",
       "       [ 0.69325846,  0.30674154],\n",
       "       [ 0.71389431,  0.28610569],\n",
       "       [ 0.3472918 ,  0.65270823],\n",
       "       [ 0.66359866,  0.33640125],\n",
       "       [ 0.32483071,  0.67516929],\n",
       "       [ 0.70924342,  0.29075655],\n",
       "       [ 0.71540827,  0.28459179],\n",
       "       [ 0.71432227,  0.28567776],\n",
       "       [ 0.41653565,  0.58346444],\n",
       "       [ 0.72299194,  0.27700809],\n",
       "       [ 0.5749386 ,  0.42506146],\n",
       "       [ 0.35662699,  0.64337301],\n",
       "       [ 0.71668857,  0.28331149],\n",
       "       [ 0.71553481,  0.28446525],\n",
       "       [ 0.44645697,  0.55354303],\n",
       "       [ 0.71591485,  0.28408518],\n",
       "       [ 0.72027403,  0.27972603],\n",
       "       [ 0.40412289,  0.59587711],\n",
       "       [ 0.7029196 ,  0.2970804 ],\n",
       "       [ 0.71702456,  0.28297547],\n",
       "       [ 0.71209979,  0.28790027],\n",
       "       [ 0.70929015,  0.29070985],\n",
       "       [ 0.71056169,  0.28943828],\n",
       "       [ 0.72269082,  0.27730912],\n",
       "       [ 0.71146512,  0.28853485],\n",
       "       [ 0.72029847,  0.27970156],\n",
       "       [ 0.71090049,  0.28909951],\n",
       "       [ 0.71164548,  0.28835446],\n",
       "       [ 0.72508448,  0.27491552],\n",
       "       [ 0.71147829,  0.28852168],\n",
       "       [ 0.71784061,  0.28215939],\n",
       "       [ 0.70881993,  0.2911801 ],\n",
       "       [ 0.62193781,  0.37806216],\n",
       "       [ 0.71102977,  0.28897026],\n",
       "       [ 0.70616776,  0.29383224],\n",
       "       [ 0.71911597,  0.28088403],\n",
       "       [ 0.71947736,  0.28052267],\n",
       "       [ 0.72407418,  0.27592584],\n",
       "       [ 0.72594631,  0.27405369],\n",
       "       [ 0.72175622,  0.27824381],\n",
       "       [ 0.71925235,  0.28074762],\n",
       "       [ 0.64350069,  0.35649934],\n",
       "       [ 0.58697134,  0.4130286 ],\n",
       "       [ 0.70360684,  0.29639307],\n",
       "       [ 0.71946651,  0.28053346],\n",
       "       [ 0.72982854,  0.27017146],\n",
       "       [ 0.71689469,  0.28310528],\n",
       "       [ 0.38817531,  0.61182463],\n",
       "       [ 0.37333572,  0.62666428],\n",
       "       [ 0.32724428,  0.67275566],\n",
       "       [ 0.34789687,  0.65210313],\n",
       "       [ 0.35722351,  0.64277643],\n",
       "       [ 0.37334791,  0.62665206],\n",
       "       [ 0.32099611,  0.67900395],\n",
       "       [ 0.2982747 ,  0.7017253 ],\n",
       "       [ 0.28917742,  0.71082252],\n",
       "       [ 0.60933328,  0.39066669],\n",
       "       [ 0.31188864,  0.68811136],\n",
       "       [ 0.65802109,  0.34197894],\n",
       "       [ 0.55426985,  0.44573009],\n",
       "       [ 0.70771831,  0.29228166],\n",
       "       [ 0.7324959 ,  0.26750416],\n",
       "       [ 0.40836626,  0.59163374],\n",
       "       [ 0.38188681,  0.61811316],\n",
       "       [ 0.31987146,  0.68012851],\n",
       "       [ 0.55128723,  0.44871283],\n",
       "       [ 0.71195883,  0.28804114],\n",
       "       [ 0.70168531,  0.29831469],\n",
       "       [ 0.6785534 ,  0.32144669],\n",
       "       [ 0.70565832,  0.29434165],\n",
       "       [ 0.7157042 ,  0.28429577],\n",
       "       [ 0.71511453,  0.28488544],\n",
       "       [ 0.58740866,  0.41259131],\n",
       "       [ 0.66585535,  0.33414471],\n",
       "       [ 0.30014256,  0.69985741],\n",
       "       [ 0.30314848,  0.69685149],\n",
       "       [ 0.70449328,  0.29550669],\n",
       "       [ 0.72042686,  0.27957311],\n",
       "       [ 0.70763874,  0.29236123],\n",
       "       [ 0.69766903,  0.30233097],\n",
       "       [ 0.71349716,  0.28650287],\n",
       "       [ 0.7126587 ,  0.28734127],\n",
       "       [ 0.67608827,  0.3239117 ],\n",
       "       [ 0.71125066,  0.28874928],\n",
       "       [ 0.70027703,  0.29972297],\n",
       "       [ 0.4385483 ,  0.56145173],\n",
       "       [ 0.70438164,  0.29561833],\n",
       "       [ 0.62345219,  0.37654775],\n",
       "       [ 0.71385431,  0.28614566],\n",
       "       [ 0.71372652,  0.28627342],\n",
       "       [ 0.57843292,  0.42156705],\n",
       "       [ 0.30411839,  0.69588161],\n",
       "       [ 0.30235463,  0.69764537],\n",
       "       [ 0.35158247,  0.64841759],\n",
       "       [ 0.42256072,  0.57743925],\n",
       "       [ 0.5626424 ,  0.4373576 ],\n",
       "       [ 0.72078115,  0.27921891],\n",
       "       [ 0.31680945,  0.68319052],\n",
       "       [ 0.6998713 ,  0.3001287 ],\n",
       "       [ 0.71238112,  0.28761891],\n",
       "       [ 0.72100753,  0.27899253],\n",
       "       [ 0.71966696,  0.28033304],\n",
       "       [ 0.72423255,  0.27576748],\n",
       "       [ 0.71993345,  0.28006652],\n",
       "       [ 0.72207445,  0.27792555],\n",
       "       [ 0.71252584,  0.28747413],\n",
       "       [ 0.71288007,  0.28711993],\n",
       "       [ 0.5764392 ,  0.42356077],\n",
       "       [ 0.62160152,  0.37839848],\n",
       "       [ 0.48516738,  0.51483262],\n",
       "       [ 0.31076846,  0.68923151],\n",
       "       [ 0.30720118,  0.69279885],\n",
       "       [ 0.7205953 ,  0.2794047 ],\n",
       "       [ 0.66328031,  0.33671966],\n",
       "       [ 0.70676225,  0.29323772],\n",
       "       [ 0.6176216 ,  0.38237843],\n",
       "       [ 0.47805914,  0.52194083],\n",
       "       [ 0.61793786,  0.38206211],\n",
       "       [ 0.72491223,  0.2750878 ],\n",
       "       [ 0.72326773,  0.27673227],\n",
       "       [ 0.71966583,  0.28033414],\n",
       "       [ 0.71915126,  0.28084877],\n",
       "       [ 0.70175594,  0.29824406],\n",
       "       [ 0.71115935,  0.28884065],\n",
       "       [ 0.6486994 ,  0.35130057],\n",
       "       [ 0.69766891,  0.302331  ],\n",
       "       [ 0.68525803,  0.31474203],\n",
       "       [ 0.65839666,  0.34160331],\n",
       "       [ 0.71694601,  0.28305399],\n",
       "       [ 0.66573387,  0.3342661 ],\n",
       "       [ 0.53873193,  0.46126801],\n",
       "       [ 0.7118004 ,  0.28819963],\n",
       "       [ 0.71309268,  0.28690726],\n",
       "       [ 0.71787268,  0.28212726],\n",
       "       [ 0.72078031,  0.27921963],\n",
       "       [ 0.70885086,  0.29114908],\n",
       "       [ 0.72036642,  0.27963361],\n",
       "       [ 0.72502553,  0.27497441],\n",
       "       [ 0.72268933,  0.27731058],\n",
       "       [ 0.72102338,  0.27897662],\n",
       "       [ 0.7163716 ,  0.28362843],\n",
       "       [ 0.71268928,  0.28731069],\n",
       "       [ 0.67918247,  0.3208175 ],\n",
       "       [ 0.71331131,  0.28668872],\n",
       "       [ 0.71530807,  0.2846919 ],\n",
       "       [ 0.70979112,  0.29020885],\n",
       "       [ 0.71495861,  0.28504136],\n",
       "       [ 0.67129219,  0.32870787],\n",
       "       [ 0.71359104,  0.28640896],\n",
       "       [ 0.71737629,  0.28262377],\n",
       "       [ 0.71714932,  0.28285071],\n",
       "       [ 0.71478599,  0.28521404],\n",
       "       [ 0.72105694,  0.27894303],\n",
       "       [ 0.72818226,  0.27181774],\n",
       "       [ 0.70811236,  0.29188758],\n",
       "       [ 0.6861524 ,  0.31384763],\n",
       "       [ 0.71862298,  0.28137702],\n",
       "       [ 0.71251506,  0.28748494],\n",
       "       [ 0.69977325,  0.30022678],\n",
       "       [ 0.71711981,  0.28288022],\n",
       "       [ 0.7099402 ,  0.29005978],\n",
       "       [ 0.71836114,  0.28163889],\n",
       "       [ 0.70583779,  0.29416227],\n",
       "       [ 0.69115263,  0.3088474 ],\n",
       "       [ 0.7137416 ,  0.28625834],\n",
       "       [ 0.71166497,  0.288335  ],\n",
       "       [ 0.70950812,  0.29049191],\n",
       "       [ 0.70932347,  0.29067656],\n",
       "       [ 0.3716656 ,  0.62833446],\n",
       "       [ 0.70628893,  0.2937111 ],\n",
       "       [ 0.71234131,  0.28765872],\n",
       "       [ 0.70015067,  0.29984936],\n",
       "       [ 0.71844399,  0.28155601],\n",
       "       [ 0.48438194,  0.51561809],\n",
       "       [ 0.55249625,  0.44750378],\n",
       "       [ 0.72005975,  0.27994031],\n",
       "       [ 0.71513885,  0.28486115],\n",
       "       [ 0.71229434,  0.28770563],\n",
       "       [ 0.72455275,  0.27544728],\n",
       "       [ 0.67245591,  0.32754406],\n",
       "       [ 0.43960419,  0.56039578],\n",
       "       [ 0.7210992 ,  0.2789008 ],\n",
       "       [ 0.70127004,  0.29872987],\n",
       "       [ 0.70876575,  0.29123434],\n",
       "       [ 0.66121757,  0.33878249],\n",
       "       [ 0.7200219 ,  0.2799781 ],\n",
       "       [ 0.72496963,  0.2750304 ],\n",
       "       [ 0.71897388,  0.28102618],\n",
       "       [ 0.72004801,  0.27995208],\n",
       "       [ 0.72125435,  0.27874568],\n",
       "       [ 0.71419823,  0.2858018 ],\n",
       "       [ 0.71358931,  0.2864106 ],\n",
       "       [ 0.71127784,  0.28872219],\n",
       "       [ 0.71513671,  0.28486326],\n",
       "       [ 0.71802878,  0.28197128],\n",
       "       [ 0.71575284,  0.28424719],\n",
       "       [ 0.706034  ,  0.293966  ],\n",
       "       [ 0.7182492 ,  0.2817508 ],\n",
       "       [ 0.71931052,  0.28068951],\n",
       "       [ 0.71823972,  0.28176033],\n",
       "       [ 0.72004688,  0.27995318],\n",
       "       [ 0.72181302,  0.27818695],\n",
       "       [ 0.72097832,  0.27902165],\n",
       "       [ 0.72160167,  0.27839828],\n",
       "       [ 0.71787924,  0.28212073],\n",
       "       [ 0.71290457,  0.2870954 ],\n",
       "       [ 0.7164883 ,  0.28351164],\n",
       "       [ 0.72235847,  0.27764151],\n",
       "       [ 0.71885431,  0.28114566],\n",
       "       [ 0.71796197,  0.28203806],\n",
       "       [ 0.71562564,  0.28437436],\n",
       "       [ 0.69008178,  0.30991817],\n",
       "       [ 0.65912092,  0.34087905],\n",
       "       [ 0.69508982,  0.30491024],\n",
       "       [ 0.69108105,  0.30891892],\n",
       "       [ 0.59770685,  0.40229312],\n",
       "       [ 0.59266764,  0.40733236],\n",
       "       [ 0.65336925,  0.34663069],\n",
       "       [ 0.71644545,  0.28355461],\n",
       "       [ 0.72198808,  0.27801183],\n",
       "       [ 0.71570379,  0.28429621],\n",
       "       [ 0.72057885,  0.27942112],\n",
       "       [ 0.71802324,  0.28197682],\n",
       "       [ 0.54470849,  0.45529151],\n",
       "       [ 0.71883839,  0.28116167],\n",
       "       [ 0.36121881,  0.63878119],\n",
       "       [ 0.39326188,  0.60673809],\n",
       "       [ 0.68896568,  0.31103429],\n",
       "       [ 0.35978857,  0.6402114 ],\n",
       "       [ 0.70666778,  0.29333222],\n",
       "       [ 0.70675528,  0.29324466],\n",
       "       [ 0.61528099,  0.38471901],\n",
       "       [ 0.68495083,  0.3150492 ],\n",
       "       [ 0.71750718,  0.28249282],\n",
       "       [ 0.71730888,  0.28269112],\n",
       "       [ 0.64536226,  0.35463774],\n",
       "       [ 0.38430682,  0.61569321],\n",
       "       [ 0.71675485,  0.28324509],\n",
       "       [ 0.71774679,  0.28225321],\n",
       "       [ 0.32378158,  0.67621845],\n",
       "       [ 0.69279635,  0.30720368],\n",
       "       [ 0.5258621 ,  0.4741379 ],\n",
       "       [ 0.71268326,  0.28731668],\n",
       "       [ 0.71302837,  0.28697154],\n",
       "       [ 0.72204113,  0.27795887],\n",
       "       [ 0.61035872,  0.38964126],\n",
       "       [ 0.64184672,  0.35815331],\n",
       "       [ 0.6245873 ,  0.37541267],\n",
       "       [ 0.72368205,  0.27631801],\n",
       "       [ 0.71524101,  0.28475893],\n",
       "       [ 0.56368756,  0.43631241],\n",
       "       [ 0.70661283,  0.2933872 ],\n",
       "       [ 0.71153331,  0.28846666],\n",
       "       [ 0.70975244,  0.29024756],\n",
       "       [ 0.55236012,  0.44763988],\n",
       "       [ 0.72409064,  0.27590939],\n",
       "       [ 0.72022092,  0.27977911],\n",
       "       [ 0.70416361,  0.29583639],\n",
       "       [ 0.7206021 ,  0.2793979 ],\n",
       "       [ 0.71405172,  0.28594834],\n",
       "       [ 0.70979935,  0.29020068],\n",
       "       [ 0.70503551,  0.29496443],\n",
       "       [ 0.71813494,  0.28186506],\n",
       "       [ 0.45826915,  0.54173088],\n",
       "       [ 0.40307581,  0.59692419],\n",
       "       [ 0.37381947,  0.62618047],\n",
       "       [ 0.51421666,  0.48578328],\n",
       "       [ 0.71823907,  0.2817609 ],\n",
       "       [ 0.71216679,  0.28783321],\n",
       "       [ 0.70690173,  0.29309827],\n",
       "       [ 0.54923475,  0.45076522],\n",
       "       [ 0.31632888,  0.68367106],\n",
       "       [ 0.50288743,  0.49711251],\n",
       "       [ 0.7174387 ,  0.28256136],\n",
       "       [ 0.6440056 ,  0.35599446],\n",
       "       [ 0.6387043 ,  0.36129573],\n",
       "       [ 0.70855778,  0.29144219],\n",
       "       [ 0.59709275,  0.40290725],\n",
       "       [ 0.69264132,  0.30735868],\n",
       "       [ 0.72154754,  0.27845249],\n",
       "       [ 0.71599287,  0.28400713],\n",
       "       [ 0.719172  ,  0.28082794],\n",
       "       [ 0.71916366,  0.28083637],\n",
       "       [ 0.7190538 ,  0.28094625],\n",
       "       [ 0.72251081,  0.27748919],\n",
       "       [ 0.7069214 ,  0.29307863],\n",
       "       [ 0.72341847,  0.27658156],\n",
       "       [ 0.47720727,  0.5227927 ],\n",
       "       [ 0.62469471,  0.37530524],\n",
       "       [ 0.50036514,  0.49963483],\n",
       "       [ 0.61561275,  0.38438725],\n",
       "       [ 0.6715107 ,  0.32848939],\n",
       "       [ 0.696859  ,  0.303141  ],\n",
       "       [ 0.30200246,  0.69799751],\n",
       "       [ 0.34011385,  0.65988612],\n",
       "       [ 0.35347292,  0.64652705],\n",
       "       [ 0.68434465,  0.31565535],\n",
       "       [ 0.65706599,  0.34293401],\n",
       "       [ 0.71122724,  0.28877279],\n",
       "       [ 0.60680348,  0.39319649],\n",
       "       [ 0.71813756,  0.28186238],\n",
       "       [ 0.70874071,  0.29125929],\n",
       "       [ 0.71527982,  0.28472015],\n",
       "       [ 0.70819491,  0.29180506],\n",
       "       [ 0.36092985,  0.63907015],\n",
       "       [ 0.30184516,  0.69815481],\n",
       "       [ 0.71693218,  0.28306791],\n",
       "       [ 0.38038361,  0.61961639],\n",
       "       [ 0.71698964,  0.28301033],\n",
       "       [ 0.72048205,  0.27951795],\n",
       "       [ 0.71721548,  0.28278452],\n",
       "       [ 0.72430199,  0.27569801],\n",
       "       [ 0.3795217 ,  0.62047827],\n",
       "       [ 0.38224223,  0.61775774],\n",
       "       [ 0.38245967,  0.61754036],\n",
       "       [ 0.60812145,  0.39187855],\n",
       "       [ 0.5724079 ,  0.4275921 ],\n",
       "       [ 0.47283179,  0.52716821],\n",
       "       [ 0.32782021,  0.67217976],\n",
       "       [ 0.60870904,  0.39129093],\n",
       "       [ 0.30131966,  0.69868034],\n",
       "       [ 0.58950102,  0.41049904],\n",
       "       [ 0.66632771,  0.33367231],\n",
       "       [ 0.71414918,  0.28585085],\n",
       "       [ 0.6942715 ,  0.30572844],\n",
       "       [ 0.6390903 ,  0.3609097 ],\n",
       "       [ 0.71017671,  0.28982326],\n",
       "       [ 0.71016878,  0.28983125],\n",
       "       [ 0.72050917,  0.27949083],\n",
       "       [ 0.70584261,  0.29415739],\n",
       "       [ 0.68655175,  0.31344822]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/Softmax_np/2_4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (354,2) (38,2) (354,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-0afc2c070c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/Softmax_np/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (354,2) (38,2) (354,2) "
     ]
    }
   ],
   "source": [
    "pred=np.zeros([354,2])\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        pred+=np.load('/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/Softmax_np/'+str(i)+'_'+str(j)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=pred/15\n",
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/media/seongjung/Seagate Backup Plus Drive/data/ASAN_Validatation_Set/Softmax_np/pred',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[0:4] , axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[4:18] , axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[18:21] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[21:27] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[27:29] , axis =0) #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[29:32] , axis =0)#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[32:35] , axis =0)#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[35:38] , axis =0)#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[38:49] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[49:52] , axis =0) #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[52:53] , axis =0)#11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[53:65] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[65:74] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[74:77] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[74:83] , axis =0)#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[83:85] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[85:87] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[87:89] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[89:92] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[92:95] , axis =0)#20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[95:97] , axis =0)#21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[97:103] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[103:109] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[109:110] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[110:113] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[113:130] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[130:135] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[135:138] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[138:140] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[140:148] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[148:154] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[154:158] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[158:170] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[170:196] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[196:203] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[203:208] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[208:215] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[215:217] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[217:219] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[219:224] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[224:252] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(pred[252:256] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[256:259] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[259:271] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[271:274] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[274:276] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[276:282] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[282:284] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[284:289] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[289:292] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[292:297 ], axis =0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[297:307] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[307:309] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[309:313] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[313:319] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[319:321] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[321:325] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[321:334] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[334:336] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[336:342] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[342:347] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pred[347:352] , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
