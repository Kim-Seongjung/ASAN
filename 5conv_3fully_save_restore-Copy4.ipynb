{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "file_locate='../Training_data_set/'\n",
    "sess = tf.InteractiveSession()\n",
    "aug_flag=False\n",
    "model_number=0\n",
    "if aug_flag == True :\n",
    "\n",
    "    img_row = 64\n",
    "    img_col = 64\n",
    "    in_ch =1\n",
    "else:\n",
    "    img_row = 100\n",
    "    img_col = 100\n",
    "    in_ch =1\n",
    "    \n",
    "divide_flag= False\n",
    "restore_flag =False\n",
    "save_flag=True\n",
    "learning_rate=1e-4\n",
    "\n",
    "model_save_path='/home/user01/ASAN/Model_save/'+str(model_number)+'/'\n",
    "if os.path.isdir(model_save_path)==False:\n",
    "    print 'a'\n",
    "    os.mkdir(model_save_path)\n",
    "if restore_flag ==True:\n",
    "    restore_path=model_save_path\n",
    "batch_size=30\n",
    "print img_row ,img_col\n",
    "n_classes =2\n",
    "\n",
    "out_ch1=200\n",
    "out_ch2=200\n",
    "out_ch3=200\n",
    "out_ch4=200\n",
    "out_ch5=200\n",
    "\n",
    "\n",
    "fully_ch1=1024\n",
    "fully_ch2 =1024\n",
    "fully_ch3 =1024\n",
    "\n",
    "\n",
    "\n",
    "strides_1=[1,2,2,1]\n",
    "strides_2=[1,1,1,1]\n",
    "strides_3=[1,1,1,1]\n",
    "strides_4=[1,1,1,1]\n",
    "strides_5=[1,1,1,1]\n",
    "\n",
    "\n",
    "x= tf.placeholder(\"float\",shape=[None,img_col , img_row , in_ch],  name = 'x-input')\n",
    "y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,in_ch])\n",
    "\n",
    "iterate=100000\n",
    "\n",
    "\n",
    "\n",
    "weight_row =3 ; weight_col=3\n",
    "\n",
    "\n",
    "pooling_row_size1=int(img_row/2)\n",
    "pooling_row_size2=int(pooling_row_size1/2)\n",
    "pooling_row_size3=int(pooling_row_size2/2)\n",
    "pooling_row_size4=int(pooling_row_size3/2)\n",
    "pooling_row_size5=int(pooling_row_size4/2)\n",
    "pooling_col_size1=int(img_col/2)\n",
    "pooling_col_size2=int(pooling_col_size1/2)\n",
    "pooling_col_size3=int(pooling_col_size2/2)\n",
    "pooling_col_size4=int(pooling_col_size3/2)\n",
    "pooling_col_size5=int(pooling_col_size4/2)\n",
    "\n",
    "print img_col , img_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Weight and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user01/ASAN/ASAN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (310, 100, 100, 1)\n",
      "Training Data Label (310, 2)\n",
      "Test Data Label (39, 2)\n",
      "val Data Label (39, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "#with tf.device('/gpu:1'):\n",
    "    if aug_flag == True:\n",
    "        img=np.load(file_locate+'train_img_'+str(model_number)+'.npy');\n",
    "        lab=np.load(file_locate+'train_lab_'+str(model_number)+'.npy');\n",
    "\n",
    "        train_img=img[:int(len(img)*0.8)]\n",
    "        train_lab=lab[:int(len(lab)*0.8)]\n",
    "        \n",
    "        val_img=img[int(len(img)*0.8):int(len(img)*0.9)]\n",
    "        val_lab=lab[int(len(lab)*0.8):int(len(img)*0.9)]\n",
    "        \n",
    "        \n",
    "        test_img=img[int(len(img)*0.9):]\n",
    "        test_lab=lab[int(len(lab)*0.9):]\n",
    "    else:   \n",
    "        if divide_flag == False:\n",
    "            img=np.load(file_locate+'train_img_'+str(model_number)+'.npy');\n",
    "            lab=np.load(file_locate+'train_lab_'+str(model_number)+'.npy');\n",
    "\n",
    "            train_img=img[:int(len(img)*0.8)]\n",
    "            train_lab=lab[:int(len(lab)*0.8)]\n",
    "\n",
    "            val_img=img[int(len(img)*0.8):int(len(img)*0.9)]\n",
    "            val_lab=lab[int(len(lab)*0.8):int(len(img)*0.9)]\n",
    "\n",
    "\n",
    "            test_img=img[int(len(img)*0.9):]\n",
    "            test_lab=lab[int(len(lab)*0.9):]\n",
    "            print \"Training Data\",np.shape(train_img)\n",
    "            print \"Training Data Label\",np.shape(train_lab)\n",
    "            print \"Test Data Label\",np.shape(test_lab)\n",
    "            print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "            n_train= np.shape(train_img)[0]\n",
    "            n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "with tf.device('/gpu:1'):\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1 , shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "\n",
    "    def conv2d(x,w,strides_):\n",
    "        return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    if restore_flag==False:\n",
    "        with tf.variable_scope(\"layer1\") as scope:\n",
    "            try:\n",
    "                w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,in_ch,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,in_ch,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        with tf.variable_scope(\"layer1\") as scope:\n",
    "            try:\n",
    "                b_conv1 = bias_variable([out_ch1])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv1 = bias_variable([out_ch1])\n",
    "        with tf.variable_scope('layer2') as scope:\n",
    "            try:\n",
    "                w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        with tf.variable_scope('layer2') as scope:\n",
    "            try:\n",
    "                b_conv2= bias_variable([out_ch2])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv2= bias_variable([out_ch2])\n",
    "\n",
    "        with tf.variable_scope('layer3') as scope:\n",
    "            try:\n",
    "                w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        with tf.variable_scope('layer3') as scope:\n",
    "            try:\n",
    "                b_conv3 = bias_variable([out_ch3])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv3 = bias_variable([out_ch3])\n",
    "\n",
    "        with tf.variable_scope('layer4') as scope:\n",
    "            try:\n",
    "                w_conv4 =tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv3 = tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        with tf.variable_scope('layer4') as scope:\n",
    "            try:\n",
    "                b_conv4 = bias_variable([out_ch4])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv3 = bias_variable([out_ch4])\n",
    "\n",
    "        with tf.variable_scope('layer5') as scope:\n",
    "            try:\n",
    "                w_conv5 = tf.get_variable(\"W5\",[weight_row,weight_col,out_ch4,out_ch5] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv3 = tf.get_variable(\"W5\" ,[weight_row,weight_col,out_ch4,out_ch5] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        with tf.variable_scope('layer5') as scope:\n",
    "            try:\n",
    "                b_conv5 = bias_variable([out_ch5])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv3 = bias_variable([out_ch5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    if restore_flag==True:\n",
    "        with tf.variable_scope(\"layer1\") as scope:\n",
    "            try:\n",
    "                w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "        with tf.variable_scope(\"layer1\") as scope:\n",
    "            try:\n",
    "                b_conv1 = tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv1 =tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "        with tf.variable_scope(\"layer2\") as scope:\n",
    "            try:\n",
    "                w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "        with tf.variable_scope(\"layer2\") as scope:\n",
    "            try:\n",
    "                b_conv2 = tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv2 =tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "        with tf.variable_scope(\"layer3\") as scope:\n",
    "            try:\n",
    "                w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "        with tf.variable_scope(\"layer3\") as scope:\n",
    "            try:\n",
    "                b_conv3 = tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv3 =tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "        with tf.variable_scope(\"layer4\") as scope:\n",
    "            try:\n",
    "                w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "        with tf.variable_scope(\"layer4\") as scope:\n",
    "            try:\n",
    "                b_conv4 = tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv4 =tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "        with tf.variable_scope(\"layer5\") as scope:\n",
    "            try:\n",
    "                w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "        with tf.variable_scope(\"layer5\") as scope:\n",
    "            try:\n",
    "                b_conv5 = tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv5 =tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 50, 50, 200), dtype=float32, device=/device:GPU:1)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:1)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:1)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:1)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 13, 13, 200), dtype=float32, device=/device:GPU:1)\n"
     ]
    }
   ],
   "source": [
    "#conncect hidden layer \n",
    "with tf.device('/gpu:1'):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image , w_conv1 ,strides_1)+b_conv1)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1 , w_conv2 ,strides_2)+b_conv2)\n",
    "    h_conv2 = max_pool_2x2(h_conv2)#pooling\n",
    "    \n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2 , w_conv3,strides_3)+b_conv3)\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3 , w_conv4,strides_4)+b_conv4)\n",
    "    h_pool4 = max_pool_2x2(h_conv4) #pooling \n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, w_conv5,strides_5)+b_conv5)\n",
    "    h_conv5= max_pool_2x2(h_conv5) #pooling \n",
    "\n",
    "    print h_conv1\n",
    "    print h_conv2\n",
    "    print h_conv3\n",
    "    print h_conv4\n",
    "    print h_conv5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_conv = h_conv5\n",
    "#print conv2d(h_pool1 , w_conv2).get_shape()\n",
    "end_conv_row=int(h_conv5.get_shape()[1])\n",
    "end_conv_col=int(h_conv5.get_shape()[2])\n",
    "end_conv_ch=int(h_conv5.get_shape()[3])\n",
    "#connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            try:\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "\n",
    "        \n",
    "with tf.device('/gpu:1'): # flat conv layer \n",
    "    end_flat_conv =tf.reshape(end_conv, [-1,end_conv_col*end_conv_row*end_conv_ch])\n",
    "   \n",
    "with tf.device('/gpu:1'): # connect flat layer with fully  connnected layer \n",
    "    h_fc1 = tf.nn.relu(tf.matmul(end_flat_conv , w_fc1)+ b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            try:\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "\n",
    "with tf.device('/gpu:1'): # connect flat layer with fully  connnected layer \n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1 , w_fc2)+ b_fc2)\n",
    "    h_fc2 = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            try:\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy'),name=\"fc3_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy',name=\"fc3_B\"))\n",
    "\n",
    "with tf.device('/gpu:1'): # connect flat layer with fully  connnected layer \n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2 , w_fc3)+ b_fc3)\n",
    "    h_fc3 = tf.nn.dropout(h_fc3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_fc=h_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope('fc3') as scope:\n",
    "            try:\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes ],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_end = bias_variable([n_classes])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end = bias_variable([n_classes])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:1'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            try:\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "\n",
    "with tf.device('/gpu:1'):  # join flat layer with fully  connnected layer \n",
    "    y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    print list_files\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_loss.npy', 'train_acc.npy', 'val_acc.npy', 'train_lab_9.npy', 'train_lab_2.npy', 'train_img_6.npy', 'train_img_0.npy', 'train_lab_7.npy', 'train_img_3.npy', 'train_img_7.npy', 'train_img_9.npy', 'train_loss.npy', 'train_img_1.npy', 'train_lab_1.npy', 'train_lab_3.npy', 'train_img_2.npy', 'train_lab_0.npy', 'train_img_8.npy', 'train_lab_5.npy', 'train_lab_6.npy', 'train_img_5.npy', 'train_lab_8.npy', 'train_lab_4.npy', 'train_img_4.npy']\n"
     ]
    }
   ],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img_0.npy', 'train_img_1.npy', 'train_img_2.npy', 'train_img_3.npy', 'train_img_4.npy', 'train_img_5.npy', 'train_img_6.npy', 'train_img_7.npy', 'train_img_8.npy', 'train_img_9.npy']\n",
      "['train_lab_0.npy', 'train_lab_1.npy', 'train_lab_2.npy', 'train_lab_3.npy', 'train_lab_4.npy', 'train_lab_5.npy', 'train_lab_6.npy', 'train_lab_7.npy', 'train_lab_8.npy', 'train_lab_9.npy']\n"
     ]
    }
   ],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_numpy_weight( model_save_path ):\n",
    "    \n",
    "    np_w_conv1,np_w_conv2,np_w_conv3,np_w_conv4,np_w_conv5=sess.run([w_conv1,w_conv2,w_conv3,w_conv4,w_conv5])\n",
    "    np_b_conv1,np_b_conv2,np_b_conv3,np_b_conv4,np_b_conv5=sess.run([b_conv1,b_conv2,b_conv3,b_conv4,b_conv5])\n",
    "    np_w_fc1 , np_w_fc2,np_w_fc3,np_w_end=sess.run([w_fc1 , w_fc2,w_fc3 ,w_end])\n",
    "    np_b_fc1 , np_b_fc2,np_b_fc3,np_b_end=sess.run([b_fc1 , b_fc2,b_fc3,b_end])\n",
    "    \n",
    "    np_w_conv1=np.asarray(np_w_conv1)\n",
    "    np_w_conv2=np.asarray(np_w_conv2)\n",
    "    np_w_conv3=np.asarray(np_w_conv3)\n",
    "    np_w_conv4=np.asarray(np_w_conv4)\n",
    "    np_w_conv5=np.asarray(np_w_conv5)\n",
    "    \n",
    "    np_b_conv1=np.asarray(np_b_conv1)\n",
    "    np_b_conv2=np.asarray(np_b_conv2)\n",
    "    np_b_conv3=np.asarray(np_b_conv3)\n",
    "    np_b_conv4=np.asarray(np_b_conv4)\n",
    "    np_b_conv5=np.asarray(np_b_conv5)\n",
    "    \n",
    "    np_w_fc1=np.asarray(np_w_fc1)\n",
    "    np_w_fc2=np.asarray(np_w_fc2)\n",
    "    np_w_fc3=np.asarray(np_w_fc3)\n",
    "    np_w_end=np.asarray(np_w_end)\n",
    "    \n",
    "    np_b_fc1=np.asarray(np_b_fc1)\n",
    "    np_b_fc2=np.asarray(np_b_fc2)\n",
    "    np_b_fc3=np.asarray(np_b_fc3)\n",
    "    np_b_end=np.asarray(np_b_end)\n",
    "    \n",
    "    \n",
    "    np.save(model_save_path +'w_conv1' , np_w_conv1)\n",
    "    np.save(model_save_path +'w_conv2' , np_w_conv2)\n",
    "    np.save(model_save_path +'w_conv3' , np_w_conv3)\n",
    "    np.save(model_save_path +'w_conv4' , np_w_conv4)\n",
    "    np.save(model_save_path +'w_conv5' , np_w_conv5)\n",
    "    \n",
    "    np.save(model_save_path +'b_conv1' , np_b_conv1)\n",
    "    np.save(model_save_path +'b_conv2' , np_b_conv2)\n",
    "    np.save(model_save_path +'b_conv3' , np_b_conv3)\n",
    "    np.save(model_save_path +'b_conv4' , np_b_conv4)\n",
    "    np.save(model_save_path +'b_conv5' , np_b_conv5)\n",
    "\n",
    "    np.save(model_save_path +'w_fc1' , np_w_fc1)\n",
    "    np.save(model_save_path +'w_fc2' , np_w_fc2)\n",
    "    np.save(model_save_path +'w_fc3' , np_w_fc3)\n",
    "    np.save(model_save_path +'w_end' , np_w_end)\n",
    "    \n",
    "    np.save(model_save_path +'b_fc1' , np_b_fc1)\n",
    "    np.save(model_save_path +'b_fc2' , np_b_fc2)\n",
    "    np.save(model_save_path +'b_fc3' , np_b_fc3)\n",
    "    np.save(model_save_path +'b_end' , np_b_end)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,crop_img_row , crop_img_col , label):\n",
    "    \"\"\"\n",
    "    np_img must 4D \n",
    "    np_img shape : n , row , col , color_ch\n",
    "    \n",
    "    \"\"\"\n",
    "    n_img,img_row,img_col,color_ch=np.shape(np_img)\n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*3\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    count=0\n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(0,n_img):\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "                ret_images[count*3,:,:,:]=cropped_img  \n",
    "                ret_images[(count*3+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "                ret_images[(count*3+2) , :,:,:] =np.flipud(cropped_img )\n",
    "                \n",
    "                ret_labels[count*3 , : ] = label[n,:]\n",
    "                ret_labels[count*3+1 , : ] = label[n,:]                \n",
    "                ret_labels[count*3+2 , : ] = label[n,:]\n",
    "                count+=1\n",
    "    return ret_images ,ret_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-d26dedee1796>:19 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "#sm_conv= tf.nn.softmax(y_conv)\n",
    "    #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    start_time = time.time()\n",
    "\n",
    "    regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "    pred=tf.nn.softmax(y_conv)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "with tf.device('/gpu:1'):\n",
    "    cost = cost+regular\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost) #1e-4\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_count=0\n",
    "max_acc=0\n",
    "if divide_flag ==True:\n",
    "    n_batch =len(train_images)\n",
    "    batch_count=0\n",
    "show_Exception_flag=True\n",
    "val_acc_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "train_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recorded at :16\n"
     ]
    }
   ],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "\n",
    "dirname='../result/'    \n",
    "count=0\n",
    "while(True):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    elif not os.path.isdir(dirname + str(count)):\n",
    "        dirname=dirname+str(count)\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    else:\n",
    "        count+=1\n",
    "print 'it is recorded at :'+str(count)\n",
    "f=open(dirname+\"/log.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_aug(img ,lab, crop_row, crop_col  , color_ch , n_classes):\n",
    "    test_aug=np.zeros([10,img_row , img_col , color_ch])\n",
    "    test_lab=np.zeros([10,n_classes])\n",
    "    for i in range(10):\n",
    "        test_lab[i,:] = lab\n",
    "    ori_row , ori_col , color_ch = np.shape(img)\n",
    "    test_aug[0]=img[:crop_row , :crop_col, :]\n",
    "    test_aug[1]=img[-crop_row :, :crop_col, :]\n",
    "    test_aug[2]=img[:crop_row , -crop_col:, :]\n",
    "    test_aug[3]=img[-crop_row: , -crop_col:, :]\n",
    "    test_aug[4]=img[(ori_row/2)-(crop_row/2) :(ori_row/2)+(crop_row/2),\\\n",
    "                    (ori_col/2)-(crop_col/2) :(ori_col/2)+(crop_col/2), :]\n",
    "    img=np.fliplr(img)\n",
    "    test_aug[5]=img[:crop_row , :crop_row, :]\n",
    "    test_aug[6]=img[-crop_row :, :crop_row, :]\n",
    "    test_aug[7]=img[:crop_row , -crop_row:, :]\n",
    "    test_aug[8]=img[-crop_row: , -crop_row:, :]\n",
    "    test_aug[4]=img[(ori_row/2)-(crop_row/2) :(ori_row/2)+(crop_row/2),\\\n",
    "                    (ori_col/2)-(crop_col/2) :(ori_col/2)+(crop_col/2), :]\n",
    "    \n",
    "    return test_aug, test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_was_saved\n",
      "step 0 , training  accuracy 0.5\n",
      "step 0 , loss : 60.6578\n",
      "step 0 , validation  accuracy 0.487179\n",
      "step 0 , validation loss : 62.1507\n",
      "step 0 , test  accuracy 0.512821\n",
      "step 0 , test loss : 66.593\n",
      "step 100 , training  accuracy 0.5\n",
      "step 100 , loss : 3039.43\n",
      "step 100 , validation  accuracy 0.512821\n",
      "step 100 , validation loss : 3758.91\n",
      "step 100 , test  accuracy 0.487179\n",
      "step 100 , test loss : 3349.74\n",
      "step 200 , training  accuracy 0.5\n",
      "step 200 , loss : 29.581\n",
      "step 200 , validation  accuracy 0.487179\n",
      "step 200 , validation loss : 34.1287\n",
      "step 200 , test  accuracy 0.512821\n",
      "step 200 , test loss : 38.3703\n",
      "step 300 , training  accuracy 0.5\n",
      "step 300 , loss : 243.073\n",
      "step 300 , validation  accuracy 0.487179\n",
      "step 300 , validation loss : 305.092\n",
      "step 300 , test  accuracy 0.512821\n",
      "step 300 , test loss : 301.47\n",
      "step 400 , training  accuracy 0.5\n",
      "step 400 , loss : 101.423\n",
      "step 400 , validation  accuracy 0.487179\n",
      "step 400 , validation loss : 127.959\n",
      "step 400 , test  accuracy 0.512821\n",
      "step 400 , test loss : 128.878\n",
      "model_was_saved\n",
      "step 500 , training  accuracy 0.566667\n",
      "step 500 , loss : 14.3701\n",
      "step 500 , validation  accuracy 0.589744\n",
      "step 500 , validation loss : 18.2775\n",
      "step 500 , test  accuracy 0.589744\n",
      "step 500 , test loss : 17.2702\n",
      "step 600 , training  accuracy 0.5\n",
      "step 600 , loss : 20.0655\n",
      "step 600 , validation  accuracy 0.512821\n",
      "step 600 , validation loss : 26.5563\n",
      "step 600 , test  accuracy 0.487179\n",
      "step 600 , test loss : 21.5833\n",
      "step 700 , training  accuracy 0.5\n",
      "step 700 , loss : 46.7365\n",
      "step 700 , validation  accuracy 0.512821\n",
      "step 700 , validation loss : 60.9584\n",
      "step 700 , test  accuracy 0.487179\n",
      "step 700 , test loss : 55.3539\n",
      "step 800 , training  accuracy 0.5\n",
      "step 800 , loss : 51.1167\n",
      "step 800 , validation  accuracy 0.512821\n",
      "step 800 , validation loss : 56.0164\n",
      "step 800 , test  accuracy 0.487179\n",
      "step 800 , test loss : 52.3348\n",
      "step 900 , training  accuracy 0.5\n",
      "step 900 , loss : 23.4737\n",
      "step 900 , validation  accuracy 0.512821\n",
      "step 900 , validation loss : 28.5493\n",
      "step 900 , test  accuracy 0.487179\n",
      "step 900 , test loss : 27.8677\n",
      "step 1000 , training  accuracy 0.5\n",
      "step 1000 , loss : 8.69966\n",
      "step 1000 , validation  accuracy 0.512821\n",
      "step 1000 , validation loss : 9.59784\n",
      "step 1000 , test  accuracy 0.487179\n",
      "step 1000 , test loss : 9.92571\n",
      "step 1100 , training  accuracy 0.466667\n",
      "step 1100 , loss : 1.80387\n",
      "step 1100 , validation  accuracy 0.512821\n",
      "step 1100 , validation loss : 1.59333\n",
      "step 1100 , test  accuracy 0.461538\n",
      "step 1100 , test loss : 1.99711\n",
      "step 1200 , training  accuracy 0.633333\n",
      "step 1200 , loss : 1.33852\n",
      "step 1200 , validation  accuracy 0.48718\n",
      "step 1200 , validation loss : 1.62297\n",
      "step 1200 , test  accuracy 0.512821\n",
      "step 1200 , test loss : 1.64412\n",
      "step 1300 , training  accuracy 0.5\n",
      "step 1300 , loss : 2.12978\n",
      "step 1300 , validation  accuracy 0.435897\n",
      "step 1300 , validation loss : 2.1964\n",
      "step 1300 , test  accuracy 0.538462\n",
      "step 1300 , test loss : 2.19101\n",
      "step 1400 , training  accuracy 0.433333\n",
      "step 1400 , loss : 1.68369\n",
      "step 1400 , validation  accuracy 0.435897\n",
      "step 1400 , validation loss : 1.77895\n",
      "step 1400 , test  accuracy 0.512821\n",
      "step 1400 , test loss : 1.91909\n",
      "step 1500 , training  accuracy 0.333333\n",
      "step 1500 , loss : 1.08106\n",
      "step 1500 , validation  accuracy 0.435897\n",
      "step 1500 , validation loss : 1.19834\n",
      "step 1500 , test  accuracy 0.564103\n",
      "step 1500 , test loss : 1.46687\n",
      "step 1600 , training  accuracy 0.4\n",
      "step 1600 , loss : 1.21698\n",
      "step 1600 , validation  accuracy 0.538462\n",
      "step 1600 , validation loss : 0.984698\n",
      "step 1600 , test  accuracy 0.538462\n",
      "step 1600 , test loss : 1.18514\n",
      "model_was_saved\n",
      "step 1700 , training  accuracy 0.433333\n",
      "step 1700 , loss : 1.08185\n",
      "step 1700 , validation  accuracy 0.641026\n",
      "step 1700 , validation loss : 1.12034\n",
      "step 1700 , test  accuracy 0.564103\n",
      "step 1700 , test loss : 1.18958\n",
      "step 1800 , training  accuracy 0.6\n",
      "step 1800 , loss : 1.60647\n",
      "step 1800 , validation  accuracy 0.564103\n",
      "step 1800 , validation loss : 1.54293\n",
      "step 1800 , test  accuracy 0.564103\n",
      "step 1800 , test loss : 1.51123\n",
      "step 1900 , training  accuracy 0.5\n",
      "step 1900 , loss : 2.05307\n",
      "step 1900 , validation  accuracy 0.564103\n",
      "step 1900 , validation loss : 1.99013\n",
      "step 1900 , test  accuracy 0.487179\n",
      "step 1900 , test loss : 1.87786\n",
      "step 2000 , training  accuracy 0.533333\n",
      "step 2000 , loss : 1.93277\n",
      "step 2000 , validation  accuracy 0.538462\n",
      "step 2000 , validation loss : 2.1402\n",
      "step 2000 , test  accuracy 0.487179\n",
      "step 2000 , test loss : 2.03627\n",
      "step 2100 , training  accuracy 0.5\n",
      "step 2100 , loss : 2.15162\n",
      "step 2100 , validation  accuracy 0.512821\n",
      "step 2100 , validation loss : 2.11369\n",
      "step 2100 , test  accuracy 0.487179\n",
      "step 2100 , test loss : 2.02031\n",
      "step 2200 , training  accuracy 0.5\n",
      "step 2200 , loss : 1.7976\n",
      "step 2200 , validation  accuracy 0.512821\n",
      "step 2200 , validation loss : 2.05623\n",
      "step 2200 , test  accuracy 0.487179\n",
      "step 2200 , test loss : 1.98963\n",
      "step 2300 , training  accuracy 0.5\n",
      "step 2300 , loss : 1.82066\n",
      "step 2300 , validation  accuracy 0.512821\n",
      "step 2300 , validation loss : 1.85288\n",
      "step 2300 , test  accuracy 0.487179\n",
      "step 2300 , test loss : 1.81958\n",
      "step 2400 , training  accuracy 0.5\n",
      "step 2400 , loss : 1.53186\n",
      "step 2400 , validation  accuracy 0.512821\n",
      "step 2400 , validation loss : 1.55929\n",
      "step 2400 , test  accuracy 0.487179\n",
      "step 2400 , test loss : 1.55402\n",
      "step 2500 , training  accuracy 0.5\n",
      "step 2500 , loss : 1.29779\n",
      "step 2500 , validation  accuracy 0.512821\n",
      "step 2500 , validation loss : 1.26932\n",
      "step 2500 , test  accuracy 0.487179\n",
      "step 2500 , test loss : 1.28508\n",
      "step 2600 , training  accuracy 0.533333\n",
      "step 2600 , loss : 1.09841\n",
      "step 2600 , validation  accuracy 0.538462\n",
      "step 2600 , validation loss : 1.02174\n",
      "step 2600 , test  accuracy 0.487179\n",
      "step 2600 , test loss : 1.03645\n",
      "step 2700 , training  accuracy 0.566667\n",
      "step 2700 , loss : 0.875332\n",
      "step 2700 , validation  accuracy 0.564103\n",
      "step 2700 , validation loss : 0.835559\n",
      "step 2700 , test  accuracy 0.512821\n",
      "step 2700 , test loss : 0.850076\n",
      "step 2800 , training  accuracy 0.533333\n",
      "step 2800 , loss : 0.767398\n",
      "step 2800 , validation  accuracy 0.461538\n",
      "step 2800 , validation loss : 0.767333\n",
      "step 2800 , test  accuracy 0.48718\n",
      "step 2800 , test loss : 0.767894\n",
      "step 2900 , training  accuracy 0.566667\n",
      "step 2900 , loss : 0.738072\n",
      "step 2900 , validation  accuracy 0.564103\n",
      "step 2900 , validation loss : 0.78435\n",
      "step 2900 , test  accuracy 0.589744\n",
      "step 2900 , test loss : 0.779751\n",
      "step 3000 , training  accuracy 0.5\n",
      "step 3000 , loss : 0.797366\n",
      "step 3000 , validation  accuracy 0.487179\n",
      "step 3000 , validation loss : 0.815543\n",
      "step 3000 , test  accuracy 0.564103\n",
      "step 3000 , test loss : 0.815263\n",
      "step 3100 , training  accuracy 0.5\n",
      "step 3100 , loss : 0.800544\n",
      "step 3100 , validation  accuracy 0.512821\n",
      "step 3100 , validation loss : 0.830505\n",
      "step 3100 , test  accuracy 0.512821\n",
      "step 3100 , test loss : 0.836426\n",
      "step 3200 , training  accuracy 0.466667\n",
      "step 3200 , loss : 0.755379\n",
      "step 3200 , validation  accuracy 0.512821\n",
      "step 3200 , validation loss : 0.815289\n",
      "step 3200 , test  accuracy 0.512821\n",
      "step 3200 , test loss : 0.828296\n",
      "step 3300 , training  accuracy 0.466667\n",
      "step 3300 , loss : 0.825854\n",
      "step 3300 , validation  accuracy 0.512821\n",
      "step 3300 , validation loss : 0.778719\n",
      "step 3300 , test  accuracy 0.538462\n",
      "step 3300 , test loss : 0.799474\n",
      "step 3400 , training  accuracy 0.433333\n",
      "step 3400 , loss : 0.77686\n",
      "step 3400 , validation  accuracy 0.512821\n",
      "step 3400 , validation loss : 0.742324\n",
      "step 3400 , test  accuracy 0.641026\n",
      "step 3400 , test loss : 0.773141\n",
      "step 3500 , training  accuracy 0.666667\n",
      "step 3500 , loss : 0.684678\n",
      "step 3500 , validation  accuracy 0.461538\n",
      "step 3500 , validation loss : 0.718789\n",
      "step 3500 , test  accuracy 0.512821\n",
      "step 3500 , test loss : 0.759742\n",
      "step 3600 , training  accuracy 0.466667\n",
      "step 3600 , loss : 0.742408\n",
      "step 3600 , validation  accuracy 0.564103\n",
      "step 3600 , validation loss : 0.714342\n",
      "step 3600 , test  accuracy 0.538462\n",
      "step 3600 , test loss : 0.764858\n",
      "step 3700 , training  accuracy 0.633333\n",
      "step 3700 , loss : 0.702634\n",
      "step 3700 , validation  accuracy 0.564103\n",
      "step 3700 , validation loss : 0.729388\n",
      "step 3700 , test  accuracy 0.512821\n",
      "step 3700 , test loss : 0.786341\n",
      "step 3800 , training  accuracy 0.566667\n",
      "step 3800 , loss : 0.745636\n",
      "step 3800 , validation  accuracy 0.538462\n",
      "step 3800 , validation loss : 0.751707\n",
      "step 3800 , test  accuracy 0.461538\n",
      "step 3800 , test loss : 0.812174\n",
      "step 3900 , training  accuracy 0.5\n",
      "step 3900 , loss : 0.784336\n",
      "step 3900 , validation  accuracy 0.538462\n",
      "step 3900 , validation loss : 0.767752\n",
      "step 3900 , test  accuracy 0.461538\n",
      "step 3900 , test loss : 0.828883\n",
      "step 4000 , training  accuracy 0.533333\n",
      "step 4000 , loss : 0.762786\n",
      "step 4000 , validation  accuracy 0.538462\n",
      "step 4000 , validation loss : 0.775433\n",
      "step 4000 , test  accuracy 0.461538\n",
      "step 4000 , test loss : 0.829322\n",
      "step 4100 , training  accuracy 0.566667\n",
      "step 4100 , loss : 0.742469\n",
      "step 4100 , validation  accuracy 0.538462\n",
      "step 4100 , validation loss : 0.769336\n",
      "step 4100 , test  accuracy 0.461538\n",
      "step 4100 , test loss : 0.81558\n",
      "step 4200 , training  accuracy 0.566667\n",
      "step 4200 , loss : 0.727647\n",
      "step 4200 , validation  accuracy 0.538462\n",
      "step 4200 , validation loss : 0.758243\n",
      "step 4200 , test  accuracy 0.435897\n",
      "step 4200 , test loss : 0.793642\n",
      "step 4300 , training  accuracy 0.5\n",
      "step 4300 , loss : 0.724984\n",
      "step 4300 , validation  accuracy 0.538462\n",
      "step 4300 , validation loss : 0.747805\n",
      "step 4300 , test  accuracy 0.435897\n",
      "step 4300 , test loss : 0.768272\n",
      "step 4400 , training  accuracy 0.5\n",
      "step 4400 , loss : 0.714024\n",
      "step 4400 , validation  accuracy 0.512821\n",
      "step 4400 , validation loss : 0.740474\n",
      "step 4400 , test  accuracy 0.487179\n",
      "step 4400 , test loss : 0.75296\n",
      "step 4500 , training  accuracy 0.6\n",
      "step 4500 , loss : 0.694479\n",
      "step 4500 , validation  accuracy 0.538462\n",
      "step 4500 , validation loss : 0.735149\n",
      "step 4500 , test  accuracy 0.512821\n",
      "step 4500 , test loss : 0.741893\n",
      "step 4600 , training  accuracy 0.666667\n",
      "step 4600 , loss : 0.678416\n",
      "step 4600 , validation  accuracy 0.615385\n",
      "step 4600 , validation loss : 0.731798\n",
      "step 4600 , test  accuracy 0.512821\n",
      "step 4600 , test loss : 0.733658\n",
      "step 4700 , training  accuracy 0.566667\n",
      "step 4700 , loss : 0.719834\n",
      "step 4700 , validation  accuracy 0.564103\n",
      "step 4700 , validation loss : 0.727786\n",
      "step 4700 , test  accuracy 0.512821\n",
      "step 4700 , test loss : 0.72884\n",
      "step 4800 , training  accuracy 0.6\n",
      "step 4800 , loss : 0.689293\n",
      "step 4800 , validation  accuracy 0.615385\n",
      "step 4800 , validation loss : 0.723407\n",
      "step 4800 , test  accuracy 0.589744\n",
      "step 4800 , test loss : 0.725774\n",
      "step 4900 , training  accuracy 0.666667\n",
      "step 4900 , loss : 0.683174\n",
      "step 4900 , validation  accuracy 0.615385\n",
      "step 4900 , validation loss : 0.7204\n",
      "step 4900 , test  accuracy 0.538462\n",
      "step 4900 , test loss : 0.721999\n",
      "step 5000 , training  accuracy 0.766667\n",
      "step 5000 , loss : 0.639044\n",
      "step 5000 , validation  accuracy 0.564103\n",
      "step 5000 , validation loss : 0.717583\n",
      "step 5000 , test  accuracy 0.615385\n",
      "step 5000 , test loss : 0.718099\n",
      "step 5100 , training  accuracy 0.866667\n",
      "step 5100 , loss : 0.628003\n",
      "step 5100 , validation  accuracy 0.564103\n",
      "step 5100 , validation loss : 0.713571\n",
      "step 5100 , test  accuracy 0.641026\n",
      "step 5100 , test loss : 0.715967\n",
      "model_was_saved\n",
      "step 5200 , training  accuracy 0.8\n",
      "step 5200 , loss : 0.665813\n",
      "step 5200 , validation  accuracy 0.615385\n",
      "step 5200 , validation loss : 0.710222\n",
      "step 5200 , test  accuracy 0.615385\n",
      "step 5200 , test loss : 0.713336\n",
      "model_was_saved\n",
      "step 5300 , training  accuracy 0.8\n",
      "step 5300 , loss : 0.60822\n",
      "step 5300 , validation  accuracy 0.666667\n",
      "step 5300 , validation loss : 0.709778\n",
      "step 5300 , test  accuracy 0.641026\n",
      "step 5300 , test loss : 0.7124\n",
      "step 5400 , training  accuracy 0.733333\n",
      "step 5400 , loss : 0.646802\n",
      "step 5400 , validation  accuracy 0.641026\n",
      "step 5400 , validation loss : 0.710279\n",
      "step 5400 , test  accuracy 0.615385\n",
      "step 5400 , test loss : 0.711081\n",
      "step 5500 , training  accuracy 0.633333\n",
      "step 5500 , loss : 0.655805\n",
      "step 5500 , validation  accuracy 0.666667\n",
      "step 5500 , validation loss : 0.714687\n",
      "step 5500 , test  accuracy 0.538462\n",
      "step 5500 , test loss : 0.71243\n",
      "step 5600 , training  accuracy 0.666667\n",
      "step 5600 , loss : 0.648185\n",
      "step 5600 , validation  accuracy 0.615385\n",
      "step 5600 , validation loss : 0.718039\n",
      "step 5600 , test  accuracy 0.512821\n",
      "step 5600 , test loss : 0.714024\n",
      "step 5700 , training  accuracy 0.666667\n",
      "step 5700 , loss : 0.670843\n",
      "step 5700 , validation  accuracy 0.641026\n",
      "step 5700 , validation loss : 0.71987\n",
      "step 5700 , test  accuracy 0.461538\n",
      "step 5700 , test loss : 0.716302\n",
      "step 5800 , training  accuracy 0.733333\n",
      "step 5800 , loss : 0.632545\n",
      "step 5800 , validation  accuracy 0.666667\n",
      "step 5800 , validation loss : 0.717802\n",
      "step 5800 , test  accuracy 0.461538\n",
      "step 5800 , test loss : 0.715706\n",
      "step 5900 , training  accuracy 0.766667\n",
      "step 5900 , loss : 0.636745\n",
      "step 5900 , validation  accuracy 0.666667\n",
      "step 5900 , validation loss : 0.713898\n",
      "step 5900 , test  accuracy 0.487179\n",
      "step 5900 , test loss : 0.713945\n",
      "step 6000 , training  accuracy 0.7\n",
      "step 6000 , loss : 0.665302\n",
      "step 6000 , validation  accuracy 0.666667\n",
      "step 6000 , validation loss : 0.709286\n",
      "step 6000 , test  accuracy 0.512821\n",
      "step 6000 , test loss : 0.71164\n",
      "step 6100 , training  accuracy 0.666667\n",
      "step 6100 , loss : 0.66509\n",
      "step 6100 , validation  accuracy 0.666667\n",
      "step 6100 , validation loss : 0.70532\n",
      "step 6100 , test  accuracy 0.512821\n",
      "step 6100 , test loss : 0.70918\n",
      "step 6200 , training  accuracy 0.8\n",
      "step 6200 , loss : 0.61474\n",
      "step 6200 , validation  accuracy 0.666667\n",
      "step 6200 , validation loss : 0.701501\n",
      "step 6200 , test  accuracy 0.512821\n",
      "step 6200 , test loss : 0.706238\n",
      "step 6300 , training  accuracy 0.833333\n",
      "step 6300 , loss : 0.617928\n",
      "step 6300 , validation  accuracy 0.692308\n",
      "step 6300 , validation loss : 0.698284\n",
      "step 6300 , test  accuracy 0.512821\n",
      "step 6300 , test loss : 0.705855\n",
      "step 6400 , training  accuracy 0.8\n",
      "step 6400 , loss : 0.598693\n",
      "step 6400 , validation  accuracy 0.692308\n",
      "step 6400 , validation loss : 0.695927\n",
      "step 6400 , test  accuracy 0.512821\n",
      "step 6400 , test loss : 0.703987\n",
      "step 6500 , training  accuracy 0.8\n",
      "step 6500 , loss : 0.630215\n",
      "step 6500 , validation  accuracy 0.692308\n",
      "step 6500 , validation loss : 0.692591\n",
      "step 6500 , test  accuracy 0.538462\n",
      "step 6500 , test loss : 0.699604\n",
      "step 6600 , training  accuracy 0.733333\n",
      "step 6600 , loss : 0.609188\n",
      "step 6600 , validation  accuracy 0.692308\n",
      "step 6600 , validation loss : 0.688544\n",
      "step 6600 , test  accuracy 0.564103\n",
      "step 6600 , test loss : 0.695443\n",
      "model_was_saved\n",
      "step 6700 , training  accuracy 0.7\n",
      "step 6700 , loss : 0.647352\n",
      "step 6700 , validation  accuracy 0.717949\n",
      "step 6700 , validation loss : 0.683358\n",
      "step 6700 , test  accuracy 0.615385\n",
      "step 6700 , test loss : 0.691529\n",
      "step 6800 , training  accuracy 0.8\n",
      "step 6800 , loss : 0.614341\n",
      "step 6800 , validation  accuracy 0.717949\n",
      "step 6800 , validation loss : 0.677828\n",
      "step 6800 , test  accuracy 0.615385\n",
      "step 6800 , test loss : 0.688566\n",
      "model_was_saved\n",
      "step 6900 , training  accuracy 0.766667\n",
      "step 6900 , loss : 0.612709\n",
      "step 6900 , validation  accuracy 0.74359\n",
      "step 6900 , validation loss : 0.672668\n",
      "step 6900 , test  accuracy 0.641026\n",
      "step 6900 , test loss : 0.685696\n",
      "model_was_saved\n",
      "step 7000 , training  accuracy 0.766667\n",
      "step 7000 , loss : 0.629726\n",
      "step 7000 , validation  accuracy 0.74359\n",
      "step 7000 , validation loss : 0.669252\n",
      "step 7000 , test  accuracy 0.666667\n",
      "step 7000 , test loss : 0.684074\n",
      "model_was_saved\n",
      "step 7100 , training  accuracy 0.9\n",
      "step 7100 , loss : 0.57199\n",
      "step 7100 , validation  accuracy 0.74359\n",
      "step 7100 , validation loss : 0.668107\n",
      "step 7100 , test  accuracy 0.692308\n",
      "step 7100 , test loss : 0.681826\n",
      "model_was_saved\n",
      "step 7200 , training  accuracy 0.866667\n",
      "step 7200 , loss : 0.610535\n",
      "step 7200 , validation  accuracy 0.74359\n",
      "step 7200 , validation loss : 0.667103\n",
      "step 7200 , test  accuracy 0.74359\n",
      "step 7200 , test loss : 0.678878\n",
      "step 7300 , training  accuracy 0.933333\n",
      "step 7300 , loss : 0.583964\n",
      "step 7300 , validation  accuracy 0.717949\n",
      "step 7300 , validation loss : 0.667759\n",
      "step 7300 , test  accuracy 0.74359\n",
      "step 7300 , test loss : 0.676191\n",
      "step 7400 , training  accuracy 0.6\n",
      "step 7400 , loss : 0.680136\n",
      "step 7400 , validation  accuracy 0.717949\n",
      "step 7400 , validation loss : 0.668095\n",
      "step 7400 , test  accuracy 0.769231\n",
      "step 7400 , test loss : 0.673308\n",
      "step 7500 , training  accuracy 0.7\n",
      "step 7500 , loss : 0.631294\n",
      "step 7500 , validation  accuracy 0.717949\n",
      "step 7500 , validation loss : 0.668819\n",
      "step 7500 , test  accuracy 0.74359\n",
      "step 7500 , test loss : 0.66997\n",
      "step 7600 , training  accuracy 0.866667\n",
      "step 7600 , loss : 0.585999\n",
      "step 7600 , validation  accuracy 0.717949\n",
      "step 7600 , validation loss : 0.66869\n",
      "step 7600 , test  accuracy 0.74359\n",
      "step 7600 , test loss : 0.666392\n",
      "step 7700 , training  accuracy 0.866667\n",
      "step 7700 , loss : 0.590247\n",
      "step 7700 , validation  accuracy 0.717949\n",
      "step 7700 , validation loss : 0.668738\n",
      "step 7700 , test  accuracy 0.74359\n",
      "step 7700 , test loss : 0.662845\n",
      "model_was_saved\n",
      "step 7800 , training  accuracy 0.7\n",
      "step 7800 , loss : 0.659426\n",
      "step 7800 , validation  accuracy 0.717949\n",
      "step 7800 , validation loss : 0.668648\n",
      "step 7800 , test  accuracy 0.794872\n",
      "step 7800 , test loss : 0.659308\n",
      "step 7900 , training  accuracy 0.833333\n",
      "step 7900 , loss : 0.600107\n",
      "step 7900 , validation  accuracy 0.692308\n",
      "step 7900 , validation loss : 0.670047\n",
      "step 7900 , test  accuracy 0.794872\n",
      "step 7900 , test loss : 0.657442\n",
      "step 8000 , training  accuracy 0.933333\n",
      "step 8000 , loss : 0.556654\n",
      "step 8000 , validation  accuracy 0.666667\n",
      "step 8000 , validation loss : 0.673058\n",
      "step 8000 , test  accuracy 0.794872\n",
      "step 8000 , test loss : 0.657718\n",
      "step 8100 , training  accuracy 0.7\n",
      "step 8100 , loss : 0.64123\n",
      "step 8100 , validation  accuracy 0.666667\n",
      "step 8100 , validation loss : 0.675614\n",
      "step 8100 , test  accuracy 0.769231\n",
      "step 8100 , test loss : 0.657817\n",
      "step 8200 , training  accuracy 0.9\n",
      "step 8200 , loss : 0.581549\n",
      "step 8200 , validation  accuracy 0.692308\n",
      "step 8200 , validation loss : 0.67556\n",
      "step 8200 , test  accuracy 0.769231\n",
      "step 8200 , test loss : 0.659672\n",
      "step 8300 , training  accuracy 0.9\n",
      "step 8300 , loss : 0.580853\n",
      "step 8300 , validation  accuracy 0.692308\n",
      "step 8300 , validation loss : 0.675541\n",
      "step 8300 , test  accuracy 0.74359\n",
      "step 8300 , test loss : 0.660834\n",
      "step 8400 , training  accuracy 0.966667\n",
      "step 8400 , loss : 0.554943\n",
      "step 8400 , validation  accuracy 0.692308\n",
      "step 8400 , validation loss : 0.675138\n",
      "step 8400 , test  accuracy 0.717949\n",
      "step 8400 , test loss : 0.661472\n",
      "step 8500 , training  accuracy 0.933333\n",
      "step 8500 , loss : 0.583691\n",
      "step 8500 , validation  accuracy 0.692308\n",
      "step 8500 , validation loss : 0.675043\n",
      "step 8500 , test  accuracy 0.74359\n",
      "step 8500 , test loss : 0.661576\n",
      "step 8600 , training  accuracy 0.933333\n",
      "step 8600 , loss : 0.576777\n",
      "step 8600 , validation  accuracy 0.692308\n",
      "step 8600 , validation loss : 0.673708\n",
      "step 8600 , test  accuracy 0.794872\n",
      "step 8600 , test loss : 0.660012\n",
      "step 8700 , training  accuracy 0.933333\n",
      "step 8700 , loss : 0.56824\n",
      "step 8700 , validation  accuracy 0.692308\n",
      "step 8700 , validation loss : 0.672575\n",
      "step 8700 , test  accuracy 0.794872\n",
      "step 8700 , test loss : 0.65834\n",
      "step 8800 , training  accuracy 0.866667\n",
      "step 8800 , loss : 0.589053\n",
      "step 8800 , validation  accuracy 0.692308\n",
      "step 8800 , validation loss : 0.669639\n",
      "step 8800 , test  accuracy 0.769231\n",
      "step 8800 , test loss : 0.655553\n",
      "step 8900 , training  accuracy 0.9\n",
      "step 8900 , loss : 0.562186\n",
      "step 8900 , validation  accuracy 0.74359\n",
      "step 8900 , validation loss : 0.665949\n",
      "step 8900 , test  accuracy 0.74359\n",
      "step 8900 , test loss : 0.652946\n",
      "step 9000 , training  accuracy 0.833333\n",
      "step 9000 , loss : 0.586829\n",
      "step 9000 , validation  accuracy 0.74359\n",
      "step 9000 , validation loss : 0.662332\n",
      "step 9000 , test  accuracy 0.74359\n",
      "step 9000 , test loss : 0.651059\n",
      "step 9100 , training  accuracy 1\n",
      "step 9100 , loss : 0.523152\n",
      "step 9100 , validation  accuracy 0.74359\n",
      "step 9100 , validation loss : 0.658881\n",
      "step 9100 , test  accuracy 0.692308\n",
      "step 9100 , test loss : 0.649406\n",
      "step 9200 , training  accuracy 0.933333\n",
      "step 9200 , loss : 0.551578\n",
      "step 9200 , validation  accuracy 0.74359\n",
      "step 9200 , validation loss : 0.655274\n",
      "step 9200 , test  accuracy 0.717949\n",
      "step 9200 , test loss : 0.648175\n",
      "step 9300 , training  accuracy 1\n",
      "step 9300 , loss : 0.538584\n",
      "step 9300 , validation  accuracy 0.769231\n",
      "step 9300 , validation loss : 0.652155\n",
      "step 9300 , test  accuracy 0.74359\n",
      "step 9300 , test loss : 0.645864\n",
      "step 9400 , training  accuracy 0.933333\n",
      "step 9400 , loss : 0.562797\n",
      "step 9400 , validation  accuracy 0.794872\n",
      "step 9400 , validation loss : 0.650151\n",
      "step 9400 , test  accuracy 0.717949\n",
      "step 9400 , test loss : 0.644726\n",
      "step 9500 , training  accuracy 0.9\n",
      "step 9500 , loss : 0.561516\n",
      "step 9500 , validation  accuracy 0.74359\n",
      "step 9500 , validation loss : 0.650459\n",
      "step 9500 , test  accuracy 0.692308\n",
      "step 9500 , test loss : 0.643942\n",
      "step 9600 , training  accuracy 0.8\n",
      "step 9600 , loss : 0.578001\n",
      "step 9600 , validation  accuracy 0.717949\n",
      "step 9600 , validation loss : 0.651548\n",
      "step 9600 , test  accuracy 0.692308\n",
      "step 9600 , test loss : 0.644063\n",
      "step 9700 , training  accuracy 0.933333\n",
      "step 9700 , loss : 0.544701\n",
      "step 9700 , validation  accuracy 0.717949\n",
      "step 9700 , validation loss : 0.652336\n",
      "step 9700 , test  accuracy 0.692308\n",
      "step 9700 , test loss : 0.644476\n",
      "step 9800 , training  accuracy 0.9\n",
      "step 9800 , loss : 0.548232\n",
      "step 9800 , validation  accuracy 0.717949\n",
      "step 9800 , validation loss : 0.652801\n",
      "step 9800 , test  accuracy 0.692308\n",
      "step 9800 , test loss : 0.645117\n",
      "step 9900 , training  accuracy 0.933333\n",
      "step 9900 , loss : 0.568435\n",
      "step 9900 , validation  accuracy 0.717949\n",
      "step 9900 , validation loss : 0.65311\n",
      "step 9900 , test  accuracy 0.692308\n",
      "step 9900 , test loss : 0.645354\n",
      "step 10000 , training  accuracy 0.966667\n",
      "step 10000 , loss : 0.54376\n",
      "step 10000 , validation  accuracy 0.717949\n",
      "step 10000 , validation loss : 0.655712\n",
      "step 10000 , test  accuracy 0.692308\n",
      "step 10000 , test loss : 0.646339\n",
      "step 10100 , training  accuracy 0.666667\n",
      "step 10100 , loss : 0.671406\n",
      "step 10100 , validation  accuracy 0.717949\n",
      "step 10100 , validation loss : 0.657005\n",
      "step 10100 , test  accuracy 0.666667\n",
      "step 10100 , test loss : 0.647017\n",
      "step 10200 , training  accuracy 0.966667\n",
      "step 10200 , loss : 0.554098\n",
      "step 10200 , validation  accuracy 0.717949\n",
      "step 10200 , validation loss : 0.658289\n",
      "step 10200 , test  accuracy 0.666667\n",
      "step 10200 , test loss : 0.648829\n",
      "step 10300 , training  accuracy 0.933333\n",
      "step 10300 , loss : 0.523287\n",
      "step 10300 , validation  accuracy 0.692308\n",
      "step 10300 , validation loss : 0.658967\n",
      "step 10300 , test  accuracy 0.717949\n",
      "step 10300 , test loss : 0.649464\n",
      "step 10400 , training  accuracy 0.8\n",
      "step 10400 , loss : 0.612078\n",
      "step 10400 , validation  accuracy 0.692308\n",
      "step 10400 , validation loss : 0.658674\n",
      "step 10400 , test  accuracy 0.692308\n",
      "step 10400 , test loss : 0.647343\n",
      "step 10500 , training  accuracy 0.966667\n",
      "step 10500 , loss : 0.528504\n",
      "step 10500 , validation  accuracy 0.692308\n",
      "step 10500 , validation loss : 0.656912\n",
      "step 10500 , test  accuracy 0.692308\n",
      "step 10500 , test loss : 0.646093\n",
      "step 10600 , training  accuracy 1\n",
      "step 10600 , loss : 0.507927\n",
      "step 10600 , validation  accuracy 0.769231\n",
      "step 10600 , validation loss : 0.654817\n",
      "step 10600 , test  accuracy 0.666667\n",
      "step 10600 , test loss : 0.644319\n",
      "step 10700 , training  accuracy 1\n",
      "step 10700 , loss : 0.534614\n",
      "step 10700 , validation  accuracy 0.717949\n",
      "step 10700 , validation loss : 0.653405\n",
      "step 10700 , test  accuracy 0.692308\n",
      "step 10700 , test loss : 0.64313\n",
      "step 10800 , training  accuracy 1\n",
      "step 10800 , loss : 0.534811\n",
      "step 10800 , validation  accuracy 0.717949\n",
      "step 10800 , validation loss : 0.652335\n",
      "step 10800 , test  accuracy 0.692308\n",
      "step 10800 , test loss : 0.642601\n",
      "step 10900 , training  accuracy 0.733333\n",
      "step 10900 , loss : 0.624166\n",
      "step 10900 , validation  accuracy 0.717949\n",
      "step 10900 , validation loss : 0.652273\n",
      "step 10900 , test  accuracy 0.717949\n",
      "step 10900 , test loss : 0.643597\n",
      "step 11000 , training  accuracy 0.9\n",
      "step 11000 , loss : 0.538942\n",
      "step 11000 , validation  accuracy 0.74359\n",
      "step 11000 , validation loss : 0.652646\n",
      "step 11000 , test  accuracy 0.717949\n",
      "step 11000 , test loss : 0.64414\n",
      "step 11100 , training  accuracy 0.9\n",
      "step 11100 , loss : 0.577608\n",
      "step 11100 , validation  accuracy 0.74359\n",
      "step 11100 , validation loss : 0.653067\n",
      "step 11100 , test  accuracy 0.717949\n",
      "step 11100 , test loss : 0.645463\n",
      "step 11200 , training  accuracy 1\n",
      "step 11200 , loss : 0.526101\n",
      "step 11200 , validation  accuracy 0.74359\n",
      "step 11200 , validation loss : 0.652625\n",
      "step 11200 , test  accuracy 0.717949\n",
      "step 11200 , test loss : 0.646864\n",
      "step 11300 , training  accuracy 1\n",
      "step 11300 , loss : 0.51551\n",
      "step 11300 , validation  accuracy 0.769231\n",
      "step 11300 , validation loss : 0.65266\n",
      "step 11300 , test  accuracy 0.692308\n",
      "step 11300 , test loss : 0.646738\n",
      "step 11400 , training  accuracy 0.966667\n",
      "step 11400 , loss : 0.529308\n",
      "step 11400 , validation  accuracy 0.794872\n",
      "step 11400 , validation loss : 0.653268\n",
      "step 11400 , test  accuracy 0.717949\n",
      "step 11400 , test loss : 0.647536\n",
      "model_was_saved\n",
      "step 11500 , training  accuracy 1\n",
      "step 11500 , loss : 0.509064\n",
      "step 11500 , validation  accuracy 0.794872\n",
      "step 11500 , validation loss : 0.654166\n",
      "step 11500 , test  accuracy 0.74359\n",
      "step 11500 , test loss : 0.648841\n",
      "step 11600 , training  accuracy 0.9\n",
      "step 11600 , loss : 0.557136\n",
      "step 11600 , validation  accuracy 0.769231\n",
      "step 11600 , validation loss : 0.6549\n",
      "step 11600 , test  accuracy 0.74359\n",
      "step 11600 , test loss : 0.649773\n",
      "step 11700 , training  accuracy 0.933333\n",
      "step 11700 , loss : 0.526805\n",
      "step 11700 , validation  accuracy 0.74359\n",
      "step 11700 , validation loss : 0.65408\n",
      "step 11700 , test  accuracy 0.74359\n",
      "step 11700 , test loss : 0.651263\n",
      "step 11800 , training  accuracy 0.9\n",
      "step 11800 , loss : 0.560878\n",
      "step 11800 , validation  accuracy 0.74359\n",
      "step 11800 , validation loss : 0.654408\n",
      "step 11800 , test  accuracy 0.74359\n",
      "step 11800 , test loss : 0.652369\n",
      "step 11900 , training  accuracy 0.966667\n",
      "step 11900 , loss : 0.523888\n",
      "step 11900 , validation  accuracy 0.74359\n",
      "step 11900 , validation loss : 0.655618\n",
      "step 11900 , test  accuracy 0.717949\n",
      "step 11900 , test loss : 0.653845\n",
      "step 12000 , training  accuracy 0.933333\n",
      "step 12000 , loss : 0.512815\n",
      "step 12000 , validation  accuracy 0.74359\n",
      "step 12000 , validation loss : 0.655729\n",
      "step 12000 , test  accuracy 0.717949\n",
      "step 12000 , test loss : 0.654342\n",
      "step 12100 , training  accuracy 0.9\n",
      "step 12100 , loss : 0.554882\n",
      "step 12100 , validation  accuracy 0.769231\n",
      "step 12100 , validation loss : 0.658096\n",
      "step 12100 , test  accuracy 0.692308\n",
      "step 12100 , test loss : 0.655929\n",
      "step 12200 , training  accuracy 0.866667\n",
      "step 12200 , loss : 0.542073\n",
      "step 12200 , validation  accuracy 0.74359\n",
      "step 12200 , validation loss : 0.661607\n",
      "step 12200 , test  accuracy 0.692308\n",
      "step 12200 , test loss : 0.6593\n",
      "step 12300 , training  accuracy 1\n",
      "step 12300 , loss : 0.515554\n",
      "step 12300 , validation  accuracy 0.74359\n",
      "step 12300 , validation loss : 0.663957\n",
      "step 12300 , test  accuracy 0.641026\n",
      "step 12300 , test loss : 0.662946\n",
      "step 12400 , training  accuracy 0.933333\n",
      "step 12400 , loss : 0.538343\n",
      "step 12400 , validation  accuracy 0.74359\n",
      "step 12400 , validation loss : 0.665228\n",
      "step 12400 , test  accuracy 0.641026\n",
      "step 12400 , test loss : 0.665083\n",
      "step 12500 , training  accuracy 0.933333\n",
      "step 12500 , loss : 0.533066\n",
      "step 12500 , validation  accuracy 0.769231\n",
      "step 12500 , validation loss : 0.664947\n",
      "step 12500 , test  accuracy 0.641026\n",
      "step 12500 , test loss : 0.664634\n",
      "step 12600 , training  accuracy 0.933333\n",
      "step 12600 , loss : 0.538017\n",
      "step 12600 , validation  accuracy 0.74359\n",
      "step 12600 , validation loss : 0.662901\n",
      "step 12600 , test  accuracy 0.666667\n",
      "step 12600 , test loss : 0.660301\n",
      "step 12700 , training  accuracy 1\n",
      "step 12700 , loss : 0.515468\n",
      "step 12700 , validation  accuracy 0.769231\n",
      "step 12700 , validation loss : 0.660783\n",
      "step 12700 , test  accuracy 0.769231\n",
      "step 12700 , test loss : 0.657506\n",
      "model_was_saved\n",
      "step 12800 , training  accuracy 0.966667\n",
      "step 12800 , loss : 0.505902\n",
      "step 12800 , validation  accuracy 0.794872\n",
      "step 12800 , validation loss : 0.658972\n",
      "step 12800 , test  accuracy 0.769231\n",
      "step 12800 , test loss : 0.653616\n",
      "step 12900 , training  accuracy 1\n",
      "step 12900 , loss : 0.514185\n",
      "step 12900 , validation  accuracy 0.769231\n",
      "step 12900 , validation loss : 0.657521\n",
      "step 12900 , test  accuracy 0.769231\n",
      "step 12900 , test loss : 0.651621\n",
      "step 13000 , training  accuracy 1\n",
      "step 13000 , loss : 0.504663\n",
      "step 13000 , validation  accuracy 0.74359\n",
      "step 13000 , validation loss : 0.656916\n",
      "step 13000 , test  accuracy 0.794872\n",
      "step 13000 , test loss : 0.650429\n",
      "step 13100 , training  accuracy 1\n",
      "step 13100 , loss : 0.503515\n",
      "step 13100 , validation  accuracy 0.74359\n",
      "step 13100 , validation loss : 0.657143\n",
      "step 13100 , test  accuracy 0.769231\n",
      "step 13100 , test loss : 0.649308\n",
      "step 13200 , training  accuracy 0.966667\n",
      "step 13200 , loss : 0.531691\n",
      "step 13200 , validation  accuracy 0.74359\n",
      "step 13200 , validation loss : 0.655856\n",
      "step 13200 , test  accuracy 0.74359\n",
      "step 13200 , test loss : 0.646659\n",
      "step 13300 , training  accuracy 0.933333\n",
      "step 13300 , loss : 0.538063\n",
      "step 13300 , validation  accuracy 0.74359\n",
      "step 13300 , validation loss : 0.654148\n",
      "step 13300 , test  accuracy 0.74359\n",
      "step 13300 , test loss : 0.644122\n",
      "step 13400 , training  accuracy 0.933333\n",
      "step 13400 , loss : 0.543505\n",
      "step 13400 , validation  accuracy 0.74359\n",
      "step 13400 , validation loss : 0.651397\n",
      "step 13400 , test  accuracy 0.769231\n",
      "step 13400 , test loss : 0.639982\n",
      "step 13500 , training  accuracy 0.966667\n",
      "step 13500 , loss : 0.510806\n",
      "step 13500 , validation  accuracy 0.74359\n",
      "step 13500 , validation loss : 0.648658\n",
      "step 13500 , test  accuracy 0.769231\n",
      "step 13500 , test loss : 0.63425\n",
      "step 13600 , training  accuracy 1\n",
      "step 13600 , loss : 0.500918\n",
      "step 13600 , validation  accuracy 0.717949\n",
      "step 13600 , validation loss : 0.646837\n",
      "step 13600 , test  accuracy 0.74359\n",
      "step 13600 , test loss : 0.629407\n",
      "step 13700 , training  accuracy 1\n",
      "step 13700 , loss : 0.496897\n",
      "step 13700 , validation  accuracy 0.769231\n",
      "step 13700 , validation loss : 0.646818\n",
      "step 13700 , test  accuracy 0.74359\n",
      "step 13700 , test loss : 0.626722\n",
      "step 13800 , training  accuracy 1\n",
      "step 13800 , loss : 0.500213\n",
      "step 13800 , validation  accuracy 0.769231\n",
      "step 13800 , validation loss : 0.647687\n",
      "step 13800 , test  accuracy 0.692308\n",
      "step 13800 , test loss : 0.626084\n",
      "step 13900 , training  accuracy 1\n",
      "step 13900 , loss : 0.51471\n",
      "step 13900 , validation  accuracy 0.769231\n",
      "step 13900 , validation loss : 0.647973\n",
      "step 13900 , test  accuracy 0.692308\n",
      "step 13900 , test loss : 0.626745\n",
      "step 14000 , training  accuracy 0.966667\n",
      "step 14000 , loss : 0.507348\n",
      "step 14000 , validation  accuracy 0.74359\n",
      "step 14000 , validation loss : 0.649693\n",
      "step 14000 , test  accuracy 0.692308\n",
      "step 14000 , test loss : 0.626653\n",
      "step 14100 , training  accuracy 1\n",
      "step 14100 , loss : 0.515858\n",
      "step 14100 , validation  accuracy 0.74359\n",
      "step 14100 , validation loss : 0.651807\n",
      "step 14100 , test  accuracy 0.692308\n",
      "step 14100 , test loss : 0.626106\n",
      "step 14200 , training  accuracy 1\n",
      "step 14200 , loss : 0.51082\n",
      "step 14200 , validation  accuracy 0.74359\n",
      "step 14200 , validation loss : 0.653548\n",
      "step 14200 , test  accuracy 0.692308\n",
      "step 14200 , test loss : 0.625636\n",
      "step 14300 , training  accuracy 1\n",
      "step 14300 , loss : 0.49086\n",
      "step 14300 , validation  accuracy 0.74359\n",
      "step 14300 , validation loss : 0.652605\n",
      "step 14300 , test  accuracy 0.692308\n",
      "step 14300 , test loss : 0.623203\n",
      "step 14400 , training  accuracy 0.966667\n",
      "step 14400 , loss : 0.507297\n",
      "step 14400 , validation  accuracy 0.717949\n",
      "step 14400 , validation loss : 0.651247\n",
      "step 14400 , test  accuracy 0.717949\n",
      "step 14400 , test loss : 0.621455\n",
      "step 14500 , training  accuracy 0.9\n",
      "step 14500 , loss : 0.537981\n",
      "step 14500 , validation  accuracy 0.666667\n",
      "step 14500 , validation loss : 0.651304\n",
      "step 14500 , test  accuracy 0.74359\n",
      "step 14500 , test loss : 0.621952\n",
      "step 14600 , training  accuracy 1\n",
      "step 14600 , loss : 0.485076\n",
      "step 14600 , validation  accuracy 0.692308\n",
      "step 14600 , validation loss : 0.651879\n",
      "step 14600 , test  accuracy 0.769231\n",
      "step 14600 , test loss : 0.623976\n",
      "step 14700 , training  accuracy 0.966667\n",
      "step 14700 , loss : 0.521554\n",
      "step 14700 , validation  accuracy 0.692308\n",
      "step 14700 , validation loss : 0.652815\n",
      "step 14700 , test  accuracy 0.794872\n",
      "step 14700 , test loss : 0.625755\n",
      "step 14800 , training  accuracy 1\n",
      "step 14800 , loss : 0.49404\n",
      "step 14800 , validation  accuracy 0.692308\n",
      "step 14800 , validation loss : 0.654614\n",
      "step 14800 , test  accuracy 0.820513\n",
      "step 14800 , test loss : 0.626604\n",
      "step 14900 , training  accuracy 1\n",
      "step 14900 , loss : 0.493736\n",
      "step 14900 , validation  accuracy 0.692308\n",
      "step 14900 , validation loss : 0.656812\n",
      "step 14900 , test  accuracy 0.820513\n",
      "step 14900 , test loss : 0.627059\n",
      "step 15000 , training  accuracy 1\n",
      "step 15000 , loss : 0.507517\n",
      "step 15000 , validation  accuracy 0.717949\n",
      "step 15000 , validation loss : 0.657684\n",
      "step 15000 , test  accuracy 0.820513\n",
      "step 15000 , test loss : 0.627029\n",
      "step 15100 , training  accuracy 1\n",
      "step 15100 , loss : 0.48183\n",
      "step 15100 , validation  accuracy 0.717949\n",
      "step 15100 , validation loss : 0.658099\n",
      "step 15100 , test  accuracy 0.820513\n",
      "step 15100 , test loss : 0.62693\n",
      "step 15200 , training  accuracy 1\n",
      "step 15200 , loss : 0.505558\n",
      "step 15200 , validation  accuracy 0.717949\n",
      "step 15200 , validation loss : 0.658092\n",
      "step 15200 , test  accuracy 0.820513\n",
      "step 15200 , test loss : 0.627084\n",
      "step 15300 , training  accuracy 1\n",
      "step 15300 , loss : 0.508212\n",
      "step 15300 , validation  accuracy 0.717949\n",
      "step 15300 , validation loss : 0.657911\n",
      "step 15300 , test  accuracy 0.820513\n",
      "step 15300 , test loss : 0.626821\n",
      "step 15400 , training  accuracy 1\n",
      "step 15400 , loss : 0.488541\n",
      "step 15400 , validation  accuracy 0.74359\n",
      "step 15400 , validation loss : 0.656875\n",
      "step 15400 , test  accuracy 0.794872\n",
      "step 15400 , test loss : 0.62585\n",
      "step 15500 , training  accuracy 1\n",
      "step 15500 , loss : 0.486219\n",
      "step 15500 , validation  accuracy 0.692308\n",
      "step 15500 , validation loss : 0.656035\n",
      "step 15500 , test  accuracy 0.794872\n",
      "step 15500 , test loss : 0.62506\n",
      "step 15600 , training  accuracy 0.966667\n",
      "step 15600 , loss : 0.510834\n",
      "step 15600 , validation  accuracy 0.641026\n",
      "step 15600 , validation loss : 0.655911\n",
      "step 15600 , test  accuracy 0.74359\n",
      "step 15600 , test loss : 0.626028\n",
      "step 15700 , training  accuracy 1\n",
      "step 15700 , loss : 0.49788\n",
      "step 15700 , validation  accuracy 0.666667\n",
      "step 15700 , validation loss : 0.656811\n",
      "step 15700 , test  accuracy 0.74359\n",
      "step 15700 , test loss : 0.627967\n",
      "step 15800 , training  accuracy 1\n",
      "step 15800 , loss : 0.498587\n",
      "step 15800 , validation  accuracy 0.692308\n",
      "step 15800 , validation loss : 0.657917\n",
      "step 15800 , test  accuracy 0.717949\n",
      "step 15800 , test loss : 0.631351\n",
      "step 15900 , training  accuracy 0.966667\n",
      "step 15900 , loss : 0.49722\n",
      "step 15900 , validation  accuracy 0.692308\n",
      "step 15900 , validation loss : 0.659328\n",
      "step 15900 , test  accuracy 0.717949\n",
      "step 15900 , test loss : 0.634161\n",
      "step 16000 , training  accuracy 0.933333\n",
      "step 16000 , loss : 0.507266\n",
      "step 16000 , validation  accuracy 0.717949\n",
      "step 16000 , validation loss : 0.658754\n",
      "step 16000 , test  accuracy 0.692308\n",
      "step 16000 , test loss : 0.63593\n",
      "step 16100 , training  accuracy 1\n",
      "step 16100 , loss : 0.5041\n",
      "step 16100 , validation  accuracy 0.717949\n",
      "step 16100 , validation loss : 0.655339\n",
      "step 16100 , test  accuracy 0.717949\n",
      "step 16100 , test loss : 0.635031\n",
      "step 16200 , training  accuracy 1\n",
      "step 16200 , loss : 0.504491\n",
      "step 16200 , validation  accuracy 0.717949\n",
      "step 16200 , validation loss : 0.649583\n",
      "step 16200 , test  accuracy 0.717949\n",
      "step 16200 , test loss : 0.631557\n",
      "step 16300 , training  accuracy 1\n",
      "step 16300 , loss : 0.490383\n",
      "step 16300 , validation  accuracy 0.74359\n",
      "step 16300 , validation loss : 0.644455\n",
      "step 16300 , test  accuracy 0.794872\n",
      "step 16300 , test loss : 0.629033\n",
      "step 16400 , training  accuracy 0.966667\n",
      "step 16400 , loss : 0.510564\n",
      "step 16400 , validation  accuracy 0.769231\n",
      "step 16400 , validation loss : 0.640732\n",
      "step 16400 , test  accuracy 0.769231\n",
      "step 16400 , test loss : 0.628751\n",
      "step 16500 , training  accuracy 1\n",
      "step 16500 , loss : 0.482566\n",
      "step 16500 , validation  accuracy 0.794872\n",
      "step 16500 , validation loss : 0.63838\n",
      "step 16500 , test  accuracy 0.769231\n",
      "step 16500 , test loss : 0.629037\n",
      "step 16600 , training  accuracy 1\n",
      "step 16600 , loss : 0.487356\n",
      "step 16600 , validation  accuracy 0.794872\n",
      "step 16600 , validation loss : 0.637879\n",
      "step 16600 , test  accuracy 0.769231\n",
      "step 16600 , test loss : 0.628118\n",
      "model_was_saved\n",
      "step 16700 , training  accuracy 1\n",
      "step 16700 , loss : 0.486232\n",
      "step 16700 , validation  accuracy 0.820513\n",
      "step 16700 , validation loss : 0.637119\n",
      "step 16700 , test  accuracy 0.794872\n",
      "step 16700 , test loss : 0.627583\n",
      "step 16800 , training  accuracy 0.966667\n",
      "step 16800 , loss : 0.509387\n",
      "step 16800 , validation  accuracy 0.820513\n",
      "step 16800 , validation loss : 0.636757\n",
      "step 16800 , test  accuracy 0.794872\n",
      "step 16800 , test loss : 0.627806\n",
      "step 16900 , training  accuracy 1\n",
      "step 16900 , loss : 0.483399\n",
      "step 16900 , validation  accuracy 0.820513\n",
      "step 16900 , validation loss : 0.635897\n",
      "step 16900 , test  accuracy 0.794872\n",
      "step 16900 , test loss : 0.628068\n",
      "step 17000 , training  accuracy 1\n",
      "step 17000 , loss : 0.477862\n",
      "step 17000 , validation  accuracy 0.820513\n",
      "step 17000 , validation loss : 0.63477\n",
      "step 17000 , test  accuracy 0.794872\n",
      "step 17000 , test loss : 0.62815\n",
      "step 17100 , training  accuracy 1\n",
      "step 17100 , loss : 0.478719\n",
      "step 17100 , validation  accuracy 0.820513\n",
      "step 17100 , validation loss : 0.633703\n",
      "step 17100 , test  accuracy 0.794872\n",
      "step 17100 , test loss : 0.628036\n",
      "step 17200 , training  accuracy 1\n",
      "step 17200 , loss : 0.493863\n",
      "step 17200 , validation  accuracy 0.820513\n",
      "step 17200 , validation loss : 0.633004\n",
      "step 17200 , test  accuracy 0.769231\n",
      "step 17200 , test loss : 0.627715\n",
      "step 17300 , training  accuracy 1\n",
      "step 17300 , loss : 0.484765\n",
      "step 17300 , validation  accuracy 0.769231\n",
      "step 17300 , validation loss : 0.63286\n",
      "step 17300 , test  accuracy 0.769231\n",
      "step 17300 , test loss : 0.626645\n",
      "step 17400 , training  accuracy 1\n",
      "step 17400 , loss : 0.477614\n",
      "step 17400 , validation  accuracy 0.769231\n",
      "step 17400 , validation loss : 0.634465\n",
      "step 17400 , test  accuracy 0.769231\n",
      "step 17400 , test loss : 0.625873\n",
      "step 17500 , training  accuracy 1\n",
      "step 17500 , loss : 0.480308\n",
      "step 17500 , validation  accuracy 0.74359\n",
      "step 17500 , validation loss : 0.635047\n",
      "step 17500 , test  accuracy 0.769231\n",
      "step 17500 , test loss : 0.625669\n",
      "step 17600 , training  accuracy 1\n",
      "step 17600 , loss : 0.487146\n",
      "step 17600 , validation  accuracy 0.769231\n",
      "step 17600 , validation loss : 0.636245\n",
      "step 17600 , test  accuracy 0.769231\n",
      "step 17600 , test loss : 0.625287\n",
      "step 17700 , training  accuracy 0.966667\n",
      "step 17700 , loss : 0.512978\n",
      "step 17700 , validation  accuracy 0.769231\n",
      "step 17700 , validation loss : 0.638806\n",
      "step 17700 , test  accuracy 0.794872\n",
      "step 17700 , test loss : 0.625291\n",
      "step 17800 , training  accuracy 1\n",
      "step 17800 , loss : 0.487294\n",
      "step 17800 , validation  accuracy 0.794872\n",
      "step 17800 , validation loss : 0.640126\n",
      "step 17800 , test  accuracy 0.794872\n",
      "step 17800 , test loss : 0.624464\n",
      "step 17900 , training  accuracy 1\n",
      "step 17900 , loss : 0.502974\n",
      "step 17900 , validation  accuracy 0.794872\n",
      "step 17900 , validation loss : 0.64037\n",
      "step 17900 , test  accuracy 0.794872\n",
      "step 17900 , test loss : 0.623856\n",
      "step 18000 , training  accuracy 1\n",
      "step 18000 , loss : 0.48593\n",
      "step 18000 , validation  accuracy 0.769231\n",
      "step 18000 , validation loss : 0.637305\n",
      "step 18000 , test  accuracy 0.769231\n",
      "step 18000 , test loss : 0.623325\n",
      "step 18100 , training  accuracy 1\n",
      "step 18100 , loss : 0.47962\n",
      "step 18100 , validation  accuracy 0.74359\n",
      "step 18100 , validation loss : 0.635678\n",
      "step 18100 , test  accuracy 0.794872\n",
      "step 18100 , test loss : 0.624035\n",
      "step 18200 , training  accuracy 1\n",
      "step 18200 , loss : 0.493595\n",
      "step 18200 , validation  accuracy 0.74359\n",
      "step 18200 , validation loss : 0.634026\n",
      "step 18200 , test  accuracy 0.769231\n",
      "step 18200 , test loss : 0.626459\n",
      "step 18300 , training  accuracy 1\n",
      "step 18300 , loss : 0.49711\n",
      "step 18300 , validation  accuracy 0.769231\n",
      "step 18300 , validation loss : 0.633131\n",
      "step 18300 , test  accuracy 0.74359\n",
      "step 18300 , test loss : 0.628615\n",
      "step 18400 , training  accuracy 1\n",
      "step 18400 , loss : 0.485659\n",
      "step 18400 , validation  accuracy 0.794872\n",
      "step 18400 , validation loss : 0.632225\n",
      "step 18400 , test  accuracy 0.74359\n",
      "step 18400 , test loss : 0.631344\n",
      "step 18500 , training  accuracy 1\n",
      "step 18500 , loss : 0.483847\n",
      "step 18500 , validation  accuracy 0.820513\n",
      "step 18500 , validation loss : 0.631987\n",
      "step 18500 , test  accuracy 0.769231\n",
      "step 18500 , test loss : 0.633147\n",
      "step 18600 , training  accuracy 1\n",
      "step 18600 , loss : 0.478872\n",
      "step 18600 , validation  accuracy 0.820513\n",
      "step 18600 , validation loss : 0.631912\n",
      "step 18600 , test  accuracy 0.769231\n",
      "step 18600 , test loss : 0.630673\n",
      "step 18700 , training  accuracy 1\n",
      "step 18700 , loss : 0.478024\n",
      "step 18700 , validation  accuracy 0.769231\n",
      "step 18700 , validation loss : 0.632425\n",
      "step 18700 , test  accuracy 0.74359\n",
      "step 18700 , test loss : 0.6279\n",
      "step 18800 , training  accuracy 1\n",
      "step 18800 , loss : 0.480753\n",
      "step 18800 , validation  accuracy 0.769231\n",
      "step 18800 , validation loss : 0.632873\n",
      "step 18800 , test  accuracy 0.769231\n",
      "step 18800 , test loss : 0.625776\n",
      "step 18900 , training  accuracy 1\n",
      "step 18900 , loss : 0.484709\n",
      "step 18900 , validation  accuracy 0.769231\n",
      "step 18900 , validation loss : 0.634189\n",
      "step 18900 , test  accuracy 0.769231\n",
      "step 18900 , test loss : 0.62558\n",
      "step 19000 , training  accuracy 1\n",
      "step 19000 , loss : 0.487824\n",
      "step 19000 , validation  accuracy 0.74359\n",
      "step 19000 , validation loss : 0.635533\n",
      "step 19000 , test  accuracy 0.769231\n",
      "step 19000 , test loss : 0.626483\n",
      "step 19100 , training  accuracy 1\n",
      "step 19100 , loss : 0.479162\n",
      "step 19100 , validation  accuracy 0.74359\n",
      "step 19100 , validation loss : 0.636528\n",
      "step 19100 , test  accuracy 0.769231\n",
      "step 19100 , test loss : 0.62773\n",
      "step 19200 , training  accuracy 1\n",
      "step 19200 , loss : 0.487935\n",
      "step 19200 , validation  accuracy 0.74359\n",
      "step 19200 , validation loss : 0.636748\n",
      "step 19200 , test  accuracy 0.794872\n",
      "step 19200 , test loss : 0.627744\n",
      "step 19300 , training  accuracy 1\n",
      "step 19300 , loss : 0.505685\n",
      "step 19300 , validation  accuracy 0.74359\n",
      "step 19300 , validation loss : 0.635622\n",
      "step 19300 , test  accuracy 0.74359\n",
      "step 19300 , test loss : 0.628483\n",
      "step 19400 , training  accuracy 1\n",
      "step 19400 , loss : 0.485927\n",
      "step 19400 , validation  accuracy 0.74359\n",
      "step 19400 , validation loss : 0.634523\n",
      "step 19400 , test  accuracy 0.74359\n",
      "step 19400 , test loss : 0.62877\n",
      "step 19500 , training  accuracy 1\n",
      "step 19500 , loss : 0.478185\n",
      "step 19500 , validation  accuracy 0.74359\n",
      "step 19500 , validation loss : 0.635418\n",
      "step 19500 , test  accuracy 0.769231\n",
      "step 19500 , test loss : 0.630437\n",
      "step 19600 , training  accuracy 0.966667\n",
      "step 19600 , loss : 0.517925\n",
      "step 19600 , validation  accuracy 0.769231\n",
      "step 19600 , validation loss : 0.637444\n",
      "step 19600 , test  accuracy 0.769231\n",
      "step 19600 , test loss : 0.634016\n",
      "step 19700 , training  accuracy 1\n",
      "step 19700 , loss : 0.488239\n",
      "step 19700 , validation  accuracy 0.74359\n",
      "step 19700 , validation loss : 0.63763\n",
      "step 19700 , test  accuracy 0.74359\n",
      "step 19700 , test loss : 0.636016\n",
      "step 19800 , training  accuracy 1\n",
      "step 19800 , loss : 0.485542\n",
      "step 19800 , validation  accuracy 0.74359\n",
      "step 19800 , validation loss : 0.636294\n",
      "step 19800 , test  accuracy 0.74359\n",
      "step 19800 , test loss : 0.637101\n",
      "step 19900 , training  accuracy 1\n",
      "step 19900 , loss : 0.478278\n",
      "step 19900 , validation  accuracy 0.769231\n",
      "step 19900 , validation loss : 0.633412\n",
      "step 19900 , test  accuracy 0.769231\n",
      "step 19900 , test loss : 0.636092\n",
      "step 20000 , training  accuracy 1\n",
      "step 20000 , loss : 0.477636\n",
      "step 20000 , validation  accuracy 0.74359\n",
      "step 20000 , validation loss : 0.630909\n",
      "step 20000 , test  accuracy 0.74359\n",
      "step 20000 , test loss : 0.633098\n",
      "step 20100 , training  accuracy 1\n",
      "step 20100 , loss : 0.483156\n",
      "step 20100 , validation  accuracy 0.74359\n",
      "step 20100 , validation loss : 0.629526\n",
      "step 20100 , test  accuracy 0.769231\n",
      "step 20100 , test loss : 0.630155\n",
      "step 20200 , training  accuracy 1\n",
      "step 20200 , loss : 0.483799\n",
      "step 20200 , validation  accuracy 0.794872\n",
      "step 20200 , validation loss : 0.630068\n",
      "step 20200 , test  accuracy 0.769231\n",
      "step 20200 , test loss : 0.628844\n",
      "step 20300 , training  accuracy 1\n",
      "step 20300 , loss : 0.475388\n",
      "step 20300 , validation  accuracy 0.820513\n",
      "step 20300 , validation loss : 0.629281\n",
      "step 20300 , test  accuracy 0.769231\n",
      "step 20300 , test loss : 0.627719\n",
      "model_was_saved\n",
      "step 20400 , training  accuracy 1\n",
      "step 20400 , loss : 0.476651\n",
      "step 20400 , validation  accuracy 0.846154\n",
      "step 20400 , validation loss : 0.629491\n",
      "step 20400 , test  accuracy 0.794872\n",
      "step 20400 , test loss : 0.628664\n",
      "step 20500 , training  accuracy 1\n",
      "step 20500 , loss : 0.489428\n",
      "step 20500 , validation  accuracy 0.846154\n",
      "step 20500 , validation loss : 0.629122\n",
      "step 20500 , test  accuracy 0.794872\n",
      "step 20500 , test loss : 0.630909\n",
      "step 20600 , training  accuracy 1\n",
      "step 20600 , loss : 0.474895\n",
      "step 20600 , validation  accuracy 0.820513\n",
      "step 20600 , validation loss : 0.628776\n",
      "step 20600 , test  accuracy 0.794872\n",
      "step 20600 , test loss : 0.632819\n",
      "step 20700 , training  accuracy 1\n",
      "step 20700 , loss : 0.478885\n",
      "step 20700 , validation  accuracy 0.820513\n",
      "step 20700 , validation loss : 0.628702\n",
      "step 20700 , test  accuracy 0.794872\n",
      "step 20700 , test loss : 0.635149\n",
      "step 20800 , training  accuracy 1\n",
      "step 20800 , loss : 0.479777\n",
      "step 20800 , validation  accuracy 0.820513\n",
      "step 20800 , validation loss : 0.628509\n",
      "step 20800 , test  accuracy 0.794872\n",
      "step 20800 , test loss : 0.636738\n",
      "step 20900 , training  accuracy 1\n",
      "step 20900 , loss : 0.476028\n",
      "step 20900 , validation  accuracy 0.820513\n",
      "step 20900 , validation loss : 0.628392\n",
      "step 20900 , test  accuracy 0.794872\n",
      "step 20900 , test loss : 0.637996\n",
      "step 21000 , training  accuracy 1\n",
      "step 21000 , loss : 0.476643\n",
      "step 21000 , validation  accuracy 0.820513\n",
      "step 21000 , validation loss : 0.628075\n",
      "step 21000 , test  accuracy 0.794872\n",
      "step 21000 , test loss : 0.639375\n",
      "step 21100 , training  accuracy 1\n",
      "step 21100 , loss : 0.485583\n",
      "step 21100 , validation  accuracy 0.820513\n",
      "step 21100 , validation loss : 0.627632\n",
      "step 21100 , test  accuracy 0.794872\n",
      "step 21100 , test loss : 0.639992\n",
      "step 21200 , training  accuracy 1\n",
      "step 21200 , loss : 0.474856\n",
      "step 21200 , validation  accuracy 0.820513\n",
      "step 21200 , validation loss : 0.628392\n",
      "step 21200 , test  accuracy 0.820513\n",
      "step 21200 , test loss : 0.640255\n",
      "step 21300 , training  accuracy 1\n",
      "step 21300 , loss : 0.488543\n",
      "step 21300 , validation  accuracy 0.820513\n",
      "step 21300 , validation loss : 0.631954\n",
      "step 21300 , test  accuracy 0.769231\n",
      "step 21300 , test loss : 0.639279\n",
      "step 21400 , training  accuracy 1\n",
      "step 21400 , loss : 0.480635\n",
      "step 21400 , validation  accuracy 0.794872\n",
      "step 21400 , validation loss : 0.634822\n",
      "step 21400 , test  accuracy 0.717949\n",
      "step 21400 , test loss : 0.641561\n",
      "step 21500 , training  accuracy 1\n",
      "step 21500 , loss : 0.473459\n",
      "step 21500 , validation  accuracy 0.769231\n",
      "step 21500 , validation loss : 0.63898\n",
      "step 21500 , test  accuracy 0.692308\n",
      "step 21500 , test loss : 0.644817\n",
      "step 21600 , training  accuracy 1\n",
      "step 21600 , loss : 0.476244\n",
      "step 21600 , validation  accuracy 0.74359\n",
      "step 21600 , validation loss : 0.643048\n",
      "step 21600 , test  accuracy 0.692308\n",
      "step 21600 , test loss : 0.64911\n",
      "step 21700 , training  accuracy 1\n",
      "step 21700 , loss : 0.485329\n",
      "step 21700 , validation  accuracy 0.717949\n",
      "step 21700 , validation loss : 0.648246\n",
      "step 21700 , test  accuracy 0.692308\n",
      "step 21700 , test loss : 0.654644\n",
      "step 21800 , training  accuracy 1\n",
      "step 21800 , loss : 0.483711\n",
      "step 21800 , validation  accuracy 0.717949\n",
      "step 21800 , validation loss : 0.64814\n",
      "step 21800 , test  accuracy 0.692308\n",
      "step 21800 , test loss : 0.65701\n",
      "step 21900 , training  accuracy 1\n",
      "step 21900 , loss : 0.49303\n",
      "step 21900 , validation  accuracy 0.717949\n",
      "step 21900 , validation loss : 0.647664\n",
      "step 21900 , test  accuracy 0.692308\n",
      "step 21900 , test loss : 0.659314\n",
      "step 22000 , training  accuracy 0.9\n",
      "step 22000 , loss : 0.541377\n",
      "step 22000 , validation  accuracy 0.74359\n",
      "step 22000 , validation loss : 0.64779\n",
      "step 22000 , test  accuracy 0.692308\n",
      "step 22000 , test loss : 0.661333\n",
      "step 22100 , training  accuracy 1\n",
      "step 22100 , loss : 0.488491\n",
      "step 22100 , validation  accuracy 0.717949\n",
      "step 22100 , validation loss : 0.645433\n",
      "step 22100 , test  accuracy 0.692308\n",
      "step 22100 , test loss : 0.659437\n",
      "step 22200 , training  accuracy 1\n",
      "step 22200 , loss : 0.477674\n",
      "step 22200 , validation  accuracy 0.717949\n",
      "step 22200 , validation loss : 0.64283\n",
      "step 22200 , test  accuracy 0.692308\n",
      "step 22200 , test loss : 0.656831\n",
      "step 22300 , training  accuracy 1\n",
      "step 22300 , loss : 0.476118\n",
      "step 22300 , validation  accuracy 0.74359\n",
      "step 22300 , validation loss : 0.640498\n",
      "step 22300 , test  accuracy 0.692308\n",
      "step 22300 , test loss : 0.655658\n",
      "step 22400 , training  accuracy 1\n",
      "step 22400 , loss : 0.480556\n",
      "step 22400 , validation  accuracy 0.769231\n",
      "step 22400 , validation loss : 0.638151\n",
      "step 22400 , test  accuracy 0.717949\n",
      "step 22400 , test loss : 0.655454\n",
      "step 22500 , training  accuracy 1\n",
      "step 22500 , loss : 0.476893\n",
      "step 22500 , validation  accuracy 0.820513\n",
      "step 22500 , validation loss : 0.636744\n",
      "step 22500 , test  accuracy 0.74359\n",
      "step 22500 , test loss : 0.656225\n",
      "step 22600 , training  accuracy 1\n",
      "step 22600 , loss : 0.470478\n",
      "step 22600 , validation  accuracy 0.820513\n",
      "step 22600 , validation loss : 0.636083\n",
      "step 22600 , test  accuracy 0.769231\n",
      "step 22600 , test loss : 0.656079\n",
      "step 22700 , training  accuracy 1\n",
      "step 22700 , loss : 0.473944\n",
      "step 22700 , validation  accuracy 0.794872\n",
      "step 22700 , validation loss : 0.635897\n",
      "step 22700 , test  accuracy 0.769231\n",
      "step 22700 , test loss : 0.654904\n",
      "step 22800 , training  accuracy 1\n",
      "step 22800 , loss : 0.473844\n",
      "step 22800 , validation  accuracy 0.820513\n",
      "step 22800 , validation loss : 0.635132\n",
      "step 22800 , test  accuracy 0.769231\n",
      "step 22800 , test loss : 0.6525\n",
      "step 22900 , training  accuracy 1\n",
      "step 22900 , loss : 0.479081\n",
      "step 22900 , validation  accuracy 0.820513\n",
      "step 22900 , validation loss : 0.634189\n",
      "step 22900 , test  accuracy 0.769231\n",
      "step 22900 , test loss : 0.651124\n",
      "step 23000 , training  accuracy 1\n",
      "step 23000 , loss : 0.478455\n",
      "step 23000 , validation  accuracy 0.820513\n",
      "step 23000 , validation loss : 0.632879\n",
      "step 23000 , test  accuracy 0.769231\n",
      "step 23000 , test loss : 0.64843\n",
      "step 23100 , training  accuracy 1\n",
      "step 23100 , loss : 0.475606\n",
      "step 23100 , validation  accuracy 0.820513\n",
      "step 23100 , validation loss : 0.630693\n",
      "step 23100 , test  accuracy 0.769231\n",
      "step 23100 , test loss : 0.647392\n",
      "step 23200 , training  accuracy 1\n",
      "step 23200 , loss : 0.473455\n",
      "step 23200 , validation  accuracy 0.820513\n",
      "step 23200 , validation loss : 0.629453\n",
      "step 23200 , test  accuracy 0.769231\n",
      "step 23200 , test loss : 0.645356\n",
      "step 23300 , training  accuracy 1\n",
      "step 23300 , loss : 0.471681\n",
      "step 23300 , validation  accuracy 0.794872\n",
      "step 23300 , validation loss : 0.628686\n",
      "step 23300 , test  accuracy 0.769231\n",
      "step 23300 , test loss : 0.643347\n",
      "step 23400 , training  accuracy 1\n",
      "step 23400 , loss : 0.483676\n",
      "step 23400 , validation  accuracy 0.794872\n",
      "step 23400 , validation loss : 0.627568\n",
      "step 23400 , test  accuracy 0.74359\n",
      "step 23400 , test loss : 0.641405\n",
      "step 23500 , training  accuracy 1\n",
      "step 23500 , loss : 0.475114\n",
      "step 23500 , validation  accuracy 0.794872\n",
      "step 23500 , validation loss : 0.627504\n",
      "step 23500 , test  accuracy 0.74359\n",
      "step 23500 , test loss : 0.639514\n",
      "step 23600 , training  accuracy 0.966667\n",
      "step 23600 , loss : 0.494827\n",
      "step 23600 , validation  accuracy 0.820513\n",
      "step 23600 , validation loss : 0.627289\n",
      "step 23600 , test  accuracy 0.74359\n",
      "step 23600 , test loss : 0.638484\n",
      "step 23700 , training  accuracy 1\n",
      "step 23700 , loss : 0.473368\n",
      "step 23700 , validation  accuracy 0.820513\n",
      "step 23700 , validation loss : 0.628016\n",
      "step 23700 , test  accuracy 0.769231\n",
      "step 23700 , test loss : 0.638816\n",
      "step 23800 , training  accuracy 1\n",
      "step 23800 , loss : 0.470797\n",
      "step 23800 , validation  accuracy 0.794872\n",
      "step 23800 , validation loss : 0.62943\n",
      "step 23800 , test  accuracy 0.769231\n",
      "step 23800 , test loss : 0.637931\n",
      "step 23900 , training  accuracy 0.833333\n",
      "step 23900 , loss : 0.58697\n",
      "step 23900 , validation  accuracy 0.794872\n",
      "step 23900 , validation loss : 0.629114\n",
      "step 23900 , test  accuracy 0.769231\n",
      "step 23900 , test loss : 0.636074\n",
      "step 24000 , training  accuracy 1\n",
      "step 24000 , loss : 0.476232\n",
      "step 24000 , validation  accuracy 0.794872\n",
      "step 24000 , validation loss : 0.6298\n",
      "step 24000 , test  accuracy 0.769231\n",
      "step 24000 , test loss : 0.635323\n",
      "step 24100 , training  accuracy 1\n",
      "step 24100 , loss : 0.4716\n",
      "step 24100 , validation  accuracy 0.794872\n",
      "step 24100 , validation loss : 0.631077\n",
      "step 24100 , test  accuracy 0.794872\n",
      "step 24100 , test loss : 0.634311\n",
      "step 24200 , training  accuracy 1\n",
      "step 24200 , loss : 0.472014\n",
      "step 24200 , validation  accuracy 0.769231\n",
      "step 24200 , validation loss : 0.631527\n",
      "step 24200 , test  accuracy 0.794872\n",
      "step 24200 , test loss : 0.634522\n",
      "step 24300 , training  accuracy 1\n",
      "step 24300 , loss : 0.476714\n",
      "step 24300 , validation  accuracy 0.769231\n",
      "step 24300 , validation loss : 0.632267\n",
      "step 24300 , test  accuracy 0.769231\n",
      "step 24300 , test loss : 0.634903\n",
      "step 24400 , training  accuracy 1\n",
      "step 24400 , loss : 0.478421\n",
      "step 24400 , validation  accuracy 0.769231\n",
      "step 24400 , validation loss : 0.633992\n",
      "step 24400 , test  accuracy 0.769231\n",
      "step 24400 , test loss : 0.634586\n",
      "step 24500 , training  accuracy 1\n",
      "step 24500 , loss : 0.470731\n",
      "step 24500 , validation  accuracy 0.769231\n",
      "step 24500 , validation loss : 0.635332\n",
      "step 24500 , test  accuracy 0.769231\n",
      "step 24500 , test loss : 0.634583\n",
      "step 24600 , training  accuracy 1\n",
      "step 24600 , loss : 0.480607\n",
      "step 24600 , validation  accuracy 0.769231\n",
      "step 24600 , validation loss : 0.636662\n",
      "step 24600 , test  accuracy 0.769231\n",
      "step 24600 , test loss : 0.634476\n",
      "step 24700 , training  accuracy 0.966667\n",
      "step 24700 , loss : 0.488354\n",
      "step 24700 , validation  accuracy 0.769231\n",
      "step 24700 , validation loss : 0.638488\n",
      "step 24700 , test  accuracy 0.769231\n",
      "step 24700 , test loss : 0.634203\n",
      "step 24800 , training  accuracy 1\n",
      "step 24800 , loss : 0.475902\n",
      "step 24800 , validation  accuracy 0.769231\n",
      "step 24800 , validation loss : 0.638819\n",
      "step 24800 , test  accuracy 0.769231\n",
      "step 24800 , test loss : 0.633638\n",
      "step 24900 , training  accuracy 1\n",
      "step 24900 , loss : 0.475534\n",
      "step 24900 , validation  accuracy 0.769231\n",
      "step 24900 , validation loss : 0.63935\n",
      "step 24900 , test  accuracy 0.769231\n",
      "step 24900 , test loss : 0.632984\n",
      "step 25000 , training  accuracy 1\n",
      "step 25000 , loss : 0.470129\n",
      "step 25000 , validation  accuracy 0.769231\n",
      "step 25000 , validation loss : 0.640429\n",
      "step 25000 , test  accuracy 0.794872\n",
      "step 25000 , test loss : 0.633648\n",
      "step 25100 , training  accuracy 1\n",
      "step 25100 , loss : 0.477729\n",
      "step 25100 , validation  accuracy 0.74359\n",
      "step 25100 , validation loss : 0.640645\n",
      "step 25100 , test  accuracy 0.794872\n",
      "step 25100 , test loss : 0.634037\n",
      "step 25200 , training  accuracy 1\n",
      "step 25200 , loss : 0.481412\n",
      "step 25200 , validation  accuracy 0.769231\n",
      "step 25200 , validation loss : 0.639145\n",
      "step 25200 , test  accuracy 0.794872\n",
      "step 25200 , test loss : 0.633906\n",
      "step 25300 , training  accuracy 1\n",
      "step 25300 , loss : 0.476171\n",
      "step 25300 , validation  accuracy 0.820513\n",
      "step 25300 , validation loss : 0.63568\n",
      "step 25300 , test  accuracy 0.794872\n",
      "step 25300 , test loss : 0.633145\n",
      "step 25400 , training  accuracy 1\n",
      "step 25400 , loss : 0.484138\n",
      "step 25400 , validation  accuracy 0.794872\n",
      "step 25400 , validation loss : 0.632055\n",
      "step 25400 , test  accuracy 0.769231\n",
      "step 25400 , test loss : 0.63265\n",
      "step 25500 , training  accuracy 1\n",
      "step 25500 , loss : 0.471929\n",
      "step 25500 , validation  accuracy 0.794872\n",
      "step 25500 , validation loss : 0.629187\n",
      "step 25500 , test  accuracy 0.769231\n",
      "step 25500 , test loss : 0.632887\n",
      "step 25600 , training  accuracy 1\n",
      "step 25600 , loss : 0.477641\n",
      "step 25600 , validation  accuracy 0.820513\n",
      "step 25600 , validation loss : 0.627563\n",
      "step 25600 , test  accuracy 0.769231\n",
      "step 25600 , test loss : 0.633164\n",
      "step 25700 , training  accuracy 1\n",
      "step 25700 , loss : 0.479106\n",
      "step 25700 , validation  accuracy 0.820513\n",
      "step 25700 , validation loss : 0.626186\n",
      "step 25700 , test  accuracy 0.74359\n",
      "step 25700 , test loss : 0.633569\n",
      "step 25800 , training  accuracy 1\n",
      "step 25800 , loss : 0.470845\n",
      "step 25800 , validation  accuracy 0.794872\n",
      "step 25800 , validation loss : 0.625574\n",
      "step 25800 , test  accuracy 0.74359\n",
      "step 25800 , test loss : 0.632826\n",
      "step 25900 , training  accuracy 1\n",
      "step 25900 , loss : 0.471017\n",
      "step 25900 , validation  accuracy 0.794872\n",
      "step 25900 , validation loss : 0.625001\n",
      "step 25900 , test  accuracy 0.74359\n",
      "step 25900 , test loss : 0.631847\n",
      "step 26000 , training  accuracy 1\n",
      "step 26000 , loss : 0.471964\n",
      "step 26000 , validation  accuracy 0.820513\n",
      "step 26000 , validation loss : 0.624672\n",
      "step 26000 , test  accuracy 0.769231\n",
      "step 26000 , test loss : 0.6304\n",
      "step 26100 , training  accuracy 1\n",
      "step 26100 , loss : 0.47397\n",
      "step 26100 , validation  accuracy 0.820513\n",
      "step 26100 , validation loss : 0.624388\n",
      "step 26100 , test  accuracy 0.794872\n",
      "step 26100 , test loss : 0.627902\n",
      "step 26200 , training  accuracy 1\n",
      "step 26200 , loss : 0.472205\n",
      "step 26200 , validation  accuracy 0.820513\n",
      "step 26200 , validation loss : 0.623912\n",
      "step 26200 , test  accuracy 0.794872\n",
      "step 26200 , test loss : 0.625954\n",
      "step 26300 , training  accuracy 1\n",
      "step 26300 , loss : 0.478323\n",
      "step 26300 , validation  accuracy 0.846154\n",
      "step 26300 , validation loss : 0.623544\n",
      "step 26300 , test  accuracy 0.769231\n",
      "step 26300 , test loss : 0.624397\n",
      "step 26400 , training  accuracy 1\n",
      "step 26400 , loss : 0.469652\n",
      "step 26400 , validation  accuracy 0.820513\n",
      "step 26400 , validation loss : 0.623619\n",
      "step 26400 , test  accuracy 0.769231\n",
      "step 26400 , test loss : 0.622898\n",
      "step 26500 , training  accuracy 1\n",
      "step 26500 , loss : 0.471225\n",
      "step 26500 , validation  accuracy 0.820513\n",
      "step 26500 , validation loss : 0.623504\n",
      "step 26500 , test  accuracy 0.769231\n",
      "step 26500 , test loss : 0.6212\n",
      "step 26600 , training  accuracy 1\n",
      "step 26600 , loss : 0.469636\n",
      "step 26600 , validation  accuracy 0.820513\n",
      "step 26600 , validation loss : 0.623428\n",
      "step 26600 , test  accuracy 0.769231\n",
      "step 26600 , test loss : 0.619848\n",
      "step 26700 , training  accuracy 1\n",
      "step 26700 , loss : 0.471261\n",
      "step 26700 , validation  accuracy 0.846154\n",
      "step 26700 , validation loss : 0.624315\n",
      "step 26700 , test  accuracy 0.74359\n",
      "step 26700 , test loss : 0.619595\n",
      "step 26800 , training  accuracy 1\n",
      "step 26800 , loss : 0.472732\n",
      "step 26800 , validation  accuracy 0.846154\n",
      "step 26800 , validation loss : 0.625129\n",
      "step 26800 , test  accuracy 0.74359\n",
      "step 26800 , test loss : 0.620572\n",
      "step 26900 , training  accuracy 1\n",
      "step 26900 , loss : 0.473978\n",
      "step 26900 , validation  accuracy 0.846154\n",
      "step 26900 , validation loss : 0.627233\n",
      "step 26900 , test  accuracy 0.769231\n",
      "step 26900 , test loss : 0.622571\n",
      "step 27000 , training  accuracy 1\n",
      "step 27000 , loss : 0.478863\n",
      "step 27000 , validation  accuracy 0.846154\n",
      "step 27000 , validation loss : 0.628823\n",
      "step 27000 , test  accuracy 0.769231\n",
      "step 27000 , test loss : 0.624683\n",
      "step 27100 , training  accuracy 1\n",
      "step 27100 , loss : 0.483352\n",
      "step 27100 , validation  accuracy 0.846154\n",
      "step 27100 , validation loss : 0.629731\n",
      "step 27100 , test  accuracy 0.769231\n",
      "step 27100 , test loss : 0.626038\n",
      "step 27200 , training  accuracy 1\n",
      "step 27200 , loss : 0.472597\n",
      "step 27200 , validation  accuracy 0.846154\n",
      "step 27200 , validation loss : 0.630574\n",
      "step 27200 , test  accuracy 0.74359\n",
      "step 27200 , test loss : 0.626548\n",
      "step 27300 , training  accuracy 0.9\n",
      "step 27300 , loss : 0.535336\n",
      "step 27300 , validation  accuracy 0.846154\n",
      "step 27300 , validation loss : 0.630097\n",
      "step 27300 , test  accuracy 0.74359\n",
      "step 27300 , test loss : 0.625791\n",
      "step 27400 , training  accuracy 1\n",
      "step 27400 , loss : 0.469878\n",
      "step 27400 , validation  accuracy 0.846154\n",
      "step 27400 , validation loss : 0.629716\n",
      "step 27400 , test  accuracy 0.74359\n",
      "step 27400 , test loss : 0.625525\n",
      "step 27500 , training  accuracy 1\n",
      "step 27500 , loss : 0.477209\n",
      "step 27500 , validation  accuracy 0.871795\n",
      "step 27500 , validation loss : 0.629211\n",
      "step 27500 , test  accuracy 0.769231\n",
      "step 27500 , test loss : 0.625221\n",
      "model_was_saved\n",
      "step 27600 , training  accuracy 1\n",
      "step 27600 , loss : 0.472181\n",
      "step 27600 , validation  accuracy 0.871795\n",
      "step 27600 , validation loss : 0.628409\n",
      "step 27600 , test  accuracy 0.794872\n",
      "step 27600 , test loss : 0.624834\n",
      "step 27700 , training  accuracy 1\n",
      "step 27700 , loss : 0.475803\n",
      "step 27700 , validation  accuracy 0.846154\n",
      "step 27700 , validation loss : 0.628467\n",
      "step 27700 , test  accuracy 0.794872\n",
      "step 27700 , test loss : 0.624969\n",
      "step 27800 , training  accuracy 1\n",
      "step 27800 , loss : 0.471334\n",
      "step 27800 , validation  accuracy 0.794872\n",
      "step 27800 , validation loss : 0.628007\n",
      "step 27800 , test  accuracy 0.769231\n",
      "step 27800 , test loss : 0.626569\n",
      "step 27900 , training  accuracy 1\n",
      "step 27900 , loss : 0.469866\n",
      "step 27900 , validation  accuracy 0.794872\n",
      "step 27900 , validation loss : 0.628037\n",
      "step 27900 , test  accuracy 0.717949\n",
      "step 27900 , test loss : 0.629124\n",
      "step 28000 , training  accuracy 1\n",
      "step 28000 , loss : 0.468625\n",
      "step 28000 , validation  accuracy 0.769231\n",
      "step 28000 , validation loss : 0.628014\n",
      "step 28000 , test  accuracy 0.717949\n",
      "step 28000 , test loss : 0.632283\n",
      "step 28100 , training  accuracy 1\n",
      "step 28100 , loss : 0.468917\n",
      "step 28100 , validation  accuracy 0.769231\n",
      "step 28100 , validation loss : 0.628172\n",
      "step 28100 , test  accuracy 0.717949\n",
      "step 28100 , test loss : 0.634772\n",
      "step 28200 , training  accuracy 1\n",
      "step 28200 , loss : 0.469249\n",
      "step 28200 , validation  accuracy 0.769231\n",
      "step 28200 , validation loss : 0.627678\n",
      "step 28200 , test  accuracy 0.717949\n",
      "step 28200 , test loss : 0.637033\n",
      "step 28300 , training  accuracy 0.966667\n",
      "step 28300 , loss : 0.48221\n",
      "step 28300 , validation  accuracy 0.769231\n",
      "step 28300 , validation loss : 0.626577\n",
      "step 28300 , test  accuracy 0.692308\n",
      "step 28300 , test loss : 0.637592\n",
      "step 28400 , training  accuracy 1\n",
      "step 28400 , loss : 0.473188\n",
      "step 28400 , validation  accuracy 0.794872\n",
      "step 28400 , validation loss : 0.625935\n",
      "step 28400 , test  accuracy 0.692308\n",
      "step 28400 , test loss : 0.637848\n",
      "step 28500 , training  accuracy 1\n",
      "step 28500 , loss : 0.476768\n",
      "step 28500 , validation  accuracy 0.820513\n",
      "step 28500 , validation loss : 0.625113\n",
      "step 28500 , test  accuracy 0.692308\n",
      "step 28500 , test loss : 0.63891\n",
      "step 28600 , training  accuracy 1\n",
      "step 28600 , loss : 0.473934\n",
      "step 28600 , validation  accuracy 0.820513\n",
      "step 28600 , validation loss : 0.624246\n",
      "step 28600 , test  accuracy 0.692308\n",
      "step 28600 , test loss : 0.639938\n",
      "step 28700 , training  accuracy 0.966667\n",
      "step 28700 , loss : 0.496975\n",
      "step 28700 , validation  accuracy 0.820513\n",
      "step 28700 , validation loss : 0.623805\n",
      "step 28700 , test  accuracy 0.692308\n",
      "step 28700 , test loss : 0.640267\n",
      "step 28800 , training  accuracy 1\n",
      "step 28800 , loss : 0.475562\n",
      "step 28800 , validation  accuracy 0.820513\n",
      "step 28800 , validation loss : 0.622753\n",
      "step 28800 , test  accuracy 0.717949\n",
      "step 28800 , test loss : 0.639261\n",
      "step 28900 , training  accuracy 1\n",
      "step 28900 , loss : 0.476096\n",
      "step 28900 , validation  accuracy 0.820513\n",
      "step 28900 , validation loss : 0.622459\n",
      "step 28900 , test  accuracy 0.717949\n",
      "step 28900 , test loss : 0.638395\n",
      "step 29000 , training  accuracy 1\n",
      "step 29000 , loss : 0.478549\n",
      "step 29000 , validation  accuracy 0.846154\n",
      "step 29000 , validation loss : 0.622698\n",
      "step 29000 , test  accuracy 0.74359\n",
      "step 29000 , test loss : 0.637245\n",
      "step 29100 , training  accuracy 0.866667\n",
      "step 29100 , loss : 0.552102\n",
      "step 29100 , validation  accuracy 0.846154\n",
      "step 29100 , validation loss : 0.62309\n",
      "step 29100 , test  accuracy 0.74359\n",
      "step 29100 , test loss : 0.636523\n",
      "step 29200 , training  accuracy 1\n",
      "step 29200 , loss : 0.477831\n",
      "step 29200 , validation  accuracy 0.846154\n",
      "step 29200 , validation loss : 0.623414\n",
      "step 29200 , test  accuracy 0.794872\n",
      "step 29200 , test loss : 0.635928\n",
      "step 29300 , training  accuracy 1\n",
      "step 29300 , loss : 0.475086\n",
      "step 29300 , validation  accuracy 0.846154\n",
      "step 29300 , validation loss : 0.622982\n",
      "step 29300 , test  accuracy 0.794872\n",
      "step 29300 , test loss : 0.634575\n",
      "step 29400 , training  accuracy 1\n",
      "step 29400 , loss : 0.471739\n",
      "step 29400 , validation  accuracy 0.846154\n",
      "step 29400 , validation loss : 0.62093\n",
      "step 29400 , test  accuracy 0.794872\n",
      "step 29400 , test loss : 0.633095\n",
      "step 29500 , training  accuracy 1\n",
      "step 29500 , loss : 0.473296\n",
      "step 29500 , validation  accuracy 0.871795\n",
      "step 29500 , validation loss : 0.6194\n",
      "step 29500 , test  accuracy 0.769231\n",
      "step 29500 , test loss : 0.631984\n",
      "step 29600 , training  accuracy 1\n",
      "step 29600 , loss : 0.472856\n",
      "step 29600 , validation  accuracy 0.871795\n",
      "step 29600 , validation loss : 0.619844\n",
      "step 29600 , test  accuracy 0.794872\n",
      "step 29600 , test loss : 0.632031\n",
      "model_was_saved\n",
      "step 29700 , training  accuracy 1\n",
      "step 29700 , loss : 0.476317\n",
      "step 29700 , validation  accuracy 0.871795\n",
      "step 29700 , validation loss : 0.620976\n",
      "step 29700 , test  accuracy 0.820513\n",
      "step 29700 , test loss : 0.631737\n",
      "step 29800 , training  accuracy 1\n",
      "step 29800 , loss : 0.471228\n",
      "step 29800 , validation  accuracy 0.871795\n",
      "step 29800 , validation loss : 0.620968\n",
      "step 29800 , test  accuracy 0.794872\n",
      "step 29800 , test loss : 0.630682\n",
      "step 29900 , training  accuracy 1\n",
      "step 29900 , loss : 0.471574\n",
      "step 29900 , validation  accuracy 0.871795\n",
      "step 29900 , validation loss : 0.620279\n",
      "step 29900 , test  accuracy 0.794872\n",
      "step 29900 , test loss : 0.629736\n",
      "step 30000 , training  accuracy 1\n",
      "step 30000 , loss : 0.475423\n",
      "step 30000 , validation  accuracy 0.871795\n",
      "step 30000 , validation loss : 0.620817\n",
      "step 30000 , test  accuracy 0.794872\n",
      "step 30000 , test loss : 0.629671\n",
      "step 30100 , training  accuracy 0.933333\n",
      "step 30100 , loss : 0.503369\n",
      "step 30100 , validation  accuracy 0.846154\n",
      "step 30100 , validation loss : 0.621681\n",
      "step 30100 , test  accuracy 0.769231\n",
      "step 30100 , test loss : 0.629355\n",
      "step 30200 , training  accuracy 1\n",
      "step 30200 , loss : 0.484408\n",
      "step 30200 , validation  accuracy 0.820513\n",
      "step 30200 , validation loss : 0.623474\n",
      "step 30200 , test  accuracy 0.74359\n",
      "step 30200 , test loss : 0.62949\n",
      "step 30300 , training  accuracy 1\n",
      "step 30300 , loss : 0.472515\n",
      "step 30300 , validation  accuracy 0.794872\n",
      "step 30300 , validation loss : 0.624858\n",
      "step 30300 , test  accuracy 0.74359\n",
      "step 30300 , test loss : 0.630643\n",
      "step 30400 , training  accuracy 1\n",
      "step 30400 , loss : 0.474728\n",
      "step 30400 , validation  accuracy 0.794872\n",
      "step 30400 , validation loss : 0.62591\n",
      "step 30400 , test  accuracy 0.74359\n",
      "step 30400 , test loss : 0.632141\n",
      "step 30500 , training  accuracy 1\n",
      "step 30500 , loss : 0.47443\n",
      "step 30500 , validation  accuracy 0.820513\n",
      "step 30500 , validation loss : 0.626166\n",
      "step 30500 , test  accuracy 0.74359\n",
      "step 30500 , test loss : 0.632997\n",
      "step 30600 , training  accuracy 1\n",
      "step 30600 , loss : 0.475304\n",
      "step 30600 , validation  accuracy 0.820513\n",
      "step 30600 , validation loss : 0.626399\n",
      "step 30600 , test  accuracy 0.74359\n",
      "step 30600 , test loss : 0.633577\n",
      "step 30700 , training  accuracy 0.966667\n",
      "step 30700 , loss : 0.509979\n",
      "step 30700 , validation  accuracy 0.769231\n",
      "step 30700 , validation loss : 0.626365\n",
      "step 30700 , test  accuracy 0.74359\n",
      "step 30700 , test loss : 0.634703\n",
      "step 30800 , training  accuracy 1\n",
      "step 30800 , loss : 0.478339\n",
      "step 30800 , validation  accuracy 0.794872\n",
      "step 30800 , validation loss : 0.626692\n",
      "step 30800 , test  accuracy 0.74359\n",
      "step 30800 , test loss : 0.63583\n",
      "step 30900 , training  accuracy 1\n",
      "step 30900 , loss : 0.476527\n",
      "step 30900 , validation  accuracy 0.769231\n",
      "step 30900 , validation loss : 0.628729\n",
      "step 30900 , test  accuracy 0.74359\n",
      "step 30900 , test loss : 0.637465\n",
      "step 31000 , training  accuracy 1\n",
      "step 31000 , loss : 0.474178\n",
      "step 31000 , validation  accuracy 0.769231\n",
      "step 31000 , validation loss : 0.631084\n",
      "step 31000 , test  accuracy 0.74359\n",
      "step 31000 , test loss : 0.639765\n",
      "step 31100 , training  accuracy 1\n",
      "step 31100 , loss : 0.475756\n",
      "step 31100 , validation  accuracy 0.769231\n",
      "step 31100 , validation loss : 0.633402\n",
      "step 31100 , test  accuracy 0.74359\n",
      "step 31100 , test loss : 0.640656\n",
      "step 31200 , training  accuracy 1\n",
      "step 31200 , loss : 0.478233\n",
      "step 31200 , validation  accuracy 0.769231\n",
      "step 31200 , validation loss : 0.635438\n",
      "step 31200 , test  accuracy 0.74359\n",
      "step 31200 , test loss : 0.641874\n",
      "step 31300 , training  accuracy 1\n",
      "step 31300 , loss : 0.472141\n",
      "step 31300 , validation  accuracy 0.769231\n",
      "step 31300 , validation loss : 0.636797\n",
      "step 31300 , test  accuracy 0.74359\n",
      "step 31300 , test loss : 0.642729\n",
      "step 31400 , training  accuracy 1\n",
      "step 31400 , loss : 0.470548\n",
      "step 31400 , validation  accuracy 0.717949\n",
      "step 31400 , validation loss : 0.637937\n",
      "step 31400 , test  accuracy 0.74359\n",
      "step 31400 , test loss : 0.64425\n",
      "step 31500 , training  accuracy 1\n",
      "step 31500 , loss : 0.467095\n",
      "step 31500 , validation  accuracy 0.717949\n",
      "step 31500 , validation loss : 0.639024\n",
      "step 31500 , test  accuracy 0.74359\n",
      "step 31500 , test loss : 0.647182\n",
      "step 31600 , training  accuracy 1\n",
      "step 31600 , loss : 0.473352\n",
      "step 31600 , validation  accuracy 0.717949\n",
      "step 31600 , validation loss : 0.639341\n",
      "step 31600 , test  accuracy 0.74359\n",
      "step 31600 , test loss : 0.649592\n",
      "step 31700 , training  accuracy 1\n",
      "step 31700 , loss : 0.472794\n",
      "step 31700 , validation  accuracy 0.717949\n",
      "step 31700 , validation loss : 0.639767\n",
      "step 31700 , test  accuracy 0.74359\n",
      "step 31700 , test loss : 0.652034\n",
      "step 31800 , training  accuracy 1\n",
      "step 31800 , loss : 0.471524\n",
      "step 31800 , validation  accuracy 0.666667\n",
      "step 31800 , validation loss : 0.64059\n",
      "step 31800 , test  accuracy 0.692308\n",
      "step 31800 , test loss : 0.654778\n",
      "step 31900 , training  accuracy 1\n",
      "step 31900 , loss : 0.475689\n",
      "step 31900 , validation  accuracy 0.641026\n",
      "step 31900 , validation loss : 0.640947\n",
      "step 31900 , test  accuracy 0.692308\n",
      "step 31900 , test loss : 0.6576\n",
      "step 32000 , training  accuracy 1\n",
      "step 32000 , loss : 0.475083\n",
      "step 32000 , validation  accuracy 0.692308\n",
      "step 32000 , validation loss : 0.639815\n",
      "step 32000 , test  accuracy 0.692308\n",
      "step 32000 , test loss : 0.659885\n",
      "step 32100 , training  accuracy 1\n",
      "step 32100 , loss : 0.473099\n",
      "step 32100 , validation  accuracy 0.666667\n",
      "step 32100 , validation loss : 0.639495\n",
      "step 32100 , test  accuracy 0.717949\n",
      "step 32100 , test loss : 0.662011\n",
      "step 32200 , training  accuracy 1\n",
      "step 32200 , loss : 0.470434\n",
      "step 32200 , validation  accuracy 0.666667\n",
      "step 32200 , validation loss : 0.639682\n",
      "step 32200 , test  accuracy 0.666667\n",
      "step 32200 , test loss : 0.663352\n",
      "step 32300 , training  accuracy 1\n",
      "step 32300 , loss : 0.472822\n",
      "step 32300 , validation  accuracy 0.692308\n",
      "step 32300 , validation loss : 0.639282\n",
      "step 32300 , test  accuracy 0.666667\n",
      "step 32300 , test loss : 0.664557\n",
      "step 32400 , training  accuracy 1\n",
      "step 32400 , loss : 0.473351\n",
      "step 32400 , validation  accuracy 0.692308\n",
      "step 32400 , validation loss : 0.638374\n",
      "step 32400 , test  accuracy 0.666667\n",
      "step 32400 , test loss : 0.663849\n",
      "step 32500 , training  accuracy 1\n",
      "step 32500 , loss : 0.470912\n",
      "step 32500 , validation  accuracy 0.692308\n",
      "step 32500 , validation loss : 0.637469\n",
      "step 32500 , test  accuracy 0.666667\n",
      "step 32500 , test loss : 0.662512\n",
      "step 32600 , training  accuracy 1\n",
      "step 32600 , loss : 0.481183\n",
      "step 32600 , validation  accuracy 0.692308\n",
      "step 32600 , validation loss : 0.635911\n",
      "step 32600 , test  accuracy 0.666667\n",
      "step 32600 , test loss : 0.659767\n",
      "step 32700 , training  accuracy 1\n",
      "step 32700 , loss : 0.46891\n",
      "step 32700 , validation  accuracy 0.692308\n",
      "step 32700 , validation loss : 0.63494\n",
      "step 32700 , test  accuracy 0.692308\n",
      "step 32700 , test loss : 0.656304\n",
      "step 32800 , training  accuracy 1\n",
      "step 32800 , loss : 0.475018\n",
      "step 32800 , validation  accuracy 0.717949\n",
      "step 32800 , validation loss : 0.635372\n",
      "step 32800 , test  accuracy 0.717949\n",
      "step 32800 , test loss : 0.653638\n",
      "step 32900 , training  accuracy 0.966667\n",
      "step 32900 , loss : 0.47804\n",
      "step 32900 , validation  accuracy 0.666667\n",
      "step 32900 , validation loss : 0.634402\n",
      "step 32900 , test  accuracy 0.74359\n",
      "step 32900 , test loss : 0.652388\n",
      "step 33000 , training  accuracy 1\n",
      "step 33000 , loss : 0.473309\n",
      "step 33000 , validation  accuracy 0.717949\n",
      "step 33000 , validation loss : 0.632876\n",
      "step 33000 , test  accuracy 0.74359\n",
      "step 33000 , test loss : 0.651062\n",
      "step 33100 , training  accuracy 1\n",
      "step 33100 , loss : 0.473975\n",
      "step 33100 , validation  accuracy 0.74359\n",
      "step 33100 , validation loss : 0.630076\n",
      "step 33100 , test  accuracy 0.74359\n",
      "step 33100 , test loss : 0.650627\n",
      "step 33200 , training  accuracy 1\n",
      "step 33200 , loss : 0.472203\n",
      "step 33200 , validation  accuracy 0.74359\n",
      "step 33200 , validation loss : 0.627174\n",
      "step 33200 , test  accuracy 0.74359\n",
      "step 33200 , test loss : 0.651079\n",
      "step 33300 , training  accuracy 1\n",
      "step 33300 , loss : 0.468978\n",
      "step 33300 , validation  accuracy 0.769231\n",
      "step 33300 , validation loss : 0.625866\n",
      "step 33300 , test  accuracy 0.74359\n",
      "step 33300 , test loss : 0.651469\n",
      "step 33400 , training  accuracy 1\n",
      "step 33400 , loss : 0.469602\n",
      "step 33400 , validation  accuracy 0.794872\n",
      "step 33400 , validation loss : 0.62428\n",
      "step 33400 , test  accuracy 0.74359\n",
      "step 33400 , test loss : 0.651452\n",
      "step 33500 , training  accuracy 1\n",
      "step 33500 , loss : 0.474084\n",
      "step 33500 , validation  accuracy 0.794872\n",
      "step 33500 , validation loss : 0.622947\n",
      "step 33500 , test  accuracy 0.74359\n",
      "step 33500 , test loss : 0.651182\n",
      "step 33600 , training  accuracy 1\n",
      "step 33600 , loss : 0.47513\n",
      "step 33600 , validation  accuracy 0.794872\n",
      "step 33600 , validation loss : 0.622522\n",
      "step 33600 , test  accuracy 0.74359\n",
      "step 33600 , test loss : 0.651447\n",
      "step 33700 , training  accuracy 1\n",
      "step 33700 , loss : 0.473967\n",
      "step 33700 , validation  accuracy 0.794872\n",
      "step 33700 , validation loss : 0.619964\n",
      "step 33700 , test  accuracy 0.74359\n",
      "step 33700 , test loss : 0.650562\n",
      "step 33800 , training  accuracy 1\n",
      "step 33800 , loss : 0.46946\n",
      "step 33800 , validation  accuracy 0.794872\n",
      "step 33800 , validation loss : 0.6192\n",
      "step 33800 , test  accuracy 0.717949\n",
      "step 33800 , test loss : 0.649295\n",
      "step 33900 , training  accuracy 1\n",
      "step 33900 , loss : 0.487104\n",
      "step 33900 , validation  accuracy 0.794872\n",
      "step 33900 , validation loss : 0.618563\n",
      "step 33900 , test  accuracy 0.717949\n",
      "step 33900 , test loss : 0.648413\n",
      "step 34000 , training  accuracy 1\n",
      "step 34000 , loss : 0.468962\n",
      "step 34000 , validation  accuracy 0.794872\n",
      "step 34000 , validation loss : 0.618773\n",
      "step 34000 , test  accuracy 0.692308\n",
      "step 34000 , test loss : 0.648913\n",
      "step 34100 , training  accuracy 1\n",
      "step 34100 , loss : 0.469605\n",
      "step 34100 , validation  accuracy 0.794872\n",
      "step 34100 , validation loss : 0.620052\n",
      "step 34100 , test  accuracy 0.692308\n",
      "step 34100 , test loss : 0.649031\n",
      "step 34200 , training  accuracy 1\n",
      "step 34200 , loss : 0.473566\n",
      "step 34200 , validation  accuracy 0.794872\n",
      "step 34200 , validation loss : 0.621258\n",
      "step 34200 , test  accuracy 0.692308\n",
      "step 34200 , test loss : 0.648291\n",
      "step 34300 , training  accuracy 1\n",
      "step 34300 , loss : 0.480567\n",
      "step 34300 , validation  accuracy 0.820513\n",
      "step 34300 , validation loss : 0.621968\n",
      "step 34300 , test  accuracy 0.717949\n",
      "step 34300 , test loss : 0.648542\n",
      "step 34400 , training  accuracy 1\n",
      "step 34400 , loss : 0.474592\n",
      "step 34400 , validation  accuracy 0.846154\n",
      "step 34400 , validation loss : 0.622098\n",
      "step 34400 , test  accuracy 0.717949\n",
      "step 34400 , test loss : 0.649109\n",
      "step 34500 , training  accuracy 1\n",
      "step 34500 , loss : 0.472255\n",
      "step 34500 , validation  accuracy 0.846154\n",
      "step 34500 , validation loss : 0.621882\n",
      "step 34500 , test  accuracy 0.717949\n",
      "step 34500 , test loss : 0.649996\n",
      "step 34600 , training  accuracy 0.966667\n",
      "step 34600 , loss : 0.502519\n",
      "step 34600 , validation  accuracy 0.846154\n",
      "step 34600 , validation loss : 0.621744\n",
      "step 34600 , test  accuracy 0.717949\n",
      "step 34600 , test loss : 0.650157\n",
      "step 34700 , training  accuracy 1\n",
      "step 34700 , loss : 0.472666\n",
      "step 34700 , validation  accuracy 0.794872\n",
      "step 34700 , validation loss : 0.621567\n",
      "step 34700 , test  accuracy 0.717949\n",
      "step 34700 , test loss : 0.650715\n",
      "step 34800 , training  accuracy 1\n",
      "step 34800 , loss : 0.470808\n",
      "step 34800 , validation  accuracy 0.769231\n",
      "step 34800 , validation loss : 0.62123\n",
      "step 34800 , test  accuracy 0.692308\n",
      "step 34800 , test loss : 0.653647\n",
      "step 34900 , training  accuracy 1\n",
      "step 34900 , loss : 0.47243\n",
      "step 34900 , validation  accuracy 0.769231\n",
      "step 34900 , validation loss : 0.621939\n",
      "step 34900 , test  accuracy 0.692308\n",
      "step 34900 , test loss : 0.656953\n",
      "step 35000 , training  accuracy 1\n",
      "step 35000 , loss : 0.468196\n",
      "step 35000 , validation  accuracy 0.769231\n",
      "step 35000 , validation loss : 0.621658\n",
      "step 35000 , test  accuracy 0.692308\n",
      "step 35000 , test loss : 0.658586\n",
      "step 35100 , training  accuracy 1\n",
      "step 35100 , loss : 0.470644\n",
      "step 35100 , validation  accuracy 0.769231\n",
      "step 35100 , validation loss : 0.62194\n",
      "step 35100 , test  accuracy 0.692308\n",
      "step 35100 , test loss : 0.66044\n",
      "step 35200 , training  accuracy 1\n",
      "step 35200 , loss : 0.472314\n",
      "step 35200 , validation  accuracy 0.769231\n",
      "step 35200 , validation loss : 0.621955\n",
      "step 35200 , test  accuracy 0.692308\n",
      "step 35200 , test loss : 0.660313\n",
      "step 35300 , training  accuracy 1\n",
      "step 35300 , loss : 0.469313\n",
      "step 35300 , validation  accuracy 0.769231\n",
      "step 35300 , validation loss : 0.62207\n",
      "step 35300 , test  accuracy 0.692308\n",
      "step 35300 , test loss : 0.660577\n",
      "step 35400 , training  accuracy 1\n",
      "step 35400 , loss : 0.472927\n",
      "step 35400 , validation  accuracy 0.769231\n",
      "step 35400 , validation loss : 0.621966\n",
      "step 35400 , test  accuracy 0.666667\n",
      "step 35400 , test loss : 0.660433\n",
      "step 35500 , training  accuracy 1\n",
      "step 35500 , loss : 0.470459\n",
      "step 35500 , validation  accuracy 0.769231\n",
      "step 35500 , validation loss : 0.620939\n",
      "step 35500 , test  accuracy 0.692308\n",
      "step 35500 , test loss : 0.657854\n",
      "step 35600 , training  accuracy 1\n",
      "step 35600 , loss : 0.473138\n",
      "step 35600 , validation  accuracy 0.794872\n",
      "step 35600 , validation loss : 0.621132\n",
      "step 35600 , test  accuracy 0.692308\n",
      "step 35600 , test loss : 0.656486\n",
      "step 35700 , training  accuracy 1\n",
      "step 35700 , loss : 0.472538\n",
      "step 35700 , validation  accuracy 0.794872\n",
      "step 35700 , validation loss : 0.621634\n",
      "step 35700 , test  accuracy 0.769231\n",
      "step 35700 , test loss : 0.656144\n",
      "step 35800 , training  accuracy 1\n",
      "step 35800 , loss : 0.472351\n",
      "step 35800 , validation  accuracy 0.769231\n",
      "step 35800 , validation loss : 0.622189\n",
      "step 35800 , test  accuracy 0.74359\n",
      "step 35800 , test loss : 0.65657\n",
      "step 35900 , training  accuracy 1\n",
      "step 35900 , loss : 0.477037\n",
      "step 35900 , validation  accuracy 0.769231\n",
      "step 35900 , validation loss : 0.621182\n",
      "step 35900 , test  accuracy 0.717949\n",
      "step 35900 , test loss : 0.656645\n",
      "step 36000 , training  accuracy 1\n",
      "step 36000 , loss : 0.471036\n",
      "step 36000 , validation  accuracy 0.769231\n",
      "step 36000 , validation loss : 0.619909\n",
      "step 36000 , test  accuracy 0.717949\n",
      "step 36000 , test loss : 0.656463\n",
      "step 36100 , training  accuracy 1\n",
      "step 36100 , loss : 0.47272\n",
      "step 36100 , validation  accuracy 0.769231\n",
      "step 36100 , validation loss : 0.619437\n",
      "step 36100 , test  accuracy 0.717949\n",
      "step 36100 , test loss : 0.65694\n",
      "step 36200 , training  accuracy 1\n",
      "step 36200 , loss : 0.475548\n",
      "step 36200 , validation  accuracy 0.74359\n",
      "step 36200 , validation loss : 0.619227\n",
      "step 36200 , test  accuracy 0.692308\n",
      "step 36200 , test loss : 0.656745\n",
      "step 36300 , training  accuracy 1\n",
      "step 36300 , loss : 0.47391\n",
      "step 36300 , validation  accuracy 0.769231\n",
      "step 36300 , validation loss : 0.618393\n",
      "step 36300 , test  accuracy 0.692308\n",
      "step 36300 , test loss : 0.655462\n",
      "step 36400 , training  accuracy 1\n",
      "step 36400 , loss : 0.469506\n",
      "step 36400 , validation  accuracy 0.769231\n",
      "step 36400 , validation loss : 0.618972\n",
      "step 36400 , test  accuracy 0.717949\n",
      "step 36400 , test loss : 0.655299\n",
      "step 36500 , training  accuracy 1\n",
      "step 36500 , loss : 0.468976\n",
      "step 36500 , validation  accuracy 0.769231\n",
      "step 36500 , validation loss : 0.620735\n",
      "step 36500 , test  accuracy 0.692308\n",
      "step 36500 , test loss : 0.656832\n",
      "step 36600 , training  accuracy 1\n",
      "step 36600 , loss : 0.472333\n",
      "step 36600 , validation  accuracy 0.769231\n",
      "step 36600 , validation loss : 0.623437\n",
      "step 36600 , test  accuracy 0.692308\n",
      "step 36600 , test loss : 0.660337\n",
      "step 36700 , training  accuracy 1\n",
      "step 36700 , loss : 0.47527\n",
      "step 36700 , validation  accuracy 0.769231\n",
      "step 36700 , validation loss : 0.625864\n",
      "step 36700 , test  accuracy 0.692308\n",
      "step 36700 , test loss : 0.663468\n",
      "step 36800 , training  accuracy 1\n",
      "step 36800 , loss : 0.472087\n",
      "step 36800 , validation  accuracy 0.769231\n",
      "step 36800 , validation loss : 0.627162\n",
      "step 36800 , test  accuracy 0.692308\n",
      "step 36800 , test loss : 0.663507\n",
      "step 36900 , training  accuracy 1\n",
      "step 36900 , loss : 0.470743\n",
      "step 36900 , validation  accuracy 0.74359\n",
      "step 36900 , validation loss : 0.627594\n",
      "step 36900 , test  accuracy 0.692308\n",
      "step 36900 , test loss : 0.6626\n",
      "step 37000 , training  accuracy 1\n",
      "step 37000 , loss : 0.475666\n",
      "step 37000 , validation  accuracy 0.74359\n",
      "step 37000 , validation loss : 0.627058\n",
      "step 37000 , test  accuracy 0.692308\n",
      "step 37000 , test loss : 0.660814\n",
      "step 37100 , training  accuracy 1\n",
      "step 37100 , loss : 0.472011\n",
      "step 37100 , validation  accuracy 0.794872\n",
      "step 37100 , validation loss : 0.626175\n",
      "step 37100 , test  accuracy 0.641026\n",
      "step 37100 , test loss : 0.6587\n",
      "step 37200 , training  accuracy 1\n",
      "step 37200 , loss : 0.470302\n",
      "step 37200 , validation  accuracy 0.794872\n",
      "step 37200 , validation loss : 0.625091\n",
      "step 37200 , test  accuracy 0.641026\n",
      "step 37200 , test loss : 0.655556\n",
      "step 37300 , training  accuracy 1\n",
      "step 37300 , loss : 0.471882\n",
      "step 37300 , validation  accuracy 0.820513\n",
      "step 37300 , validation loss : 0.624355\n",
      "step 37300 , test  accuracy 0.717949\n",
      "step 37300 , test loss : 0.652588\n",
      "step 37400 , training  accuracy 1\n",
      "step 37400 , loss : 0.47016\n",
      "step 37400 , validation  accuracy 0.846154\n",
      "step 37400 , validation loss : 0.625481\n",
      "step 37400 , test  accuracy 0.717949\n",
      "step 37400 , test loss : 0.650914\n",
      "step 37500 , training  accuracy 1\n",
      "step 37500 , loss : 0.471457\n",
      "step 37500 , validation  accuracy 0.794872\n",
      "step 37500 , validation loss : 0.628464\n",
      "step 37500 , test  accuracy 0.692308\n",
      "step 37500 , test loss : 0.650481\n",
      "step 37600 , training  accuracy 1\n",
      "step 37600 , loss : 0.471805\n",
      "step 37600 , validation  accuracy 0.820513\n",
      "step 37600 , validation loss : 0.630945\n",
      "step 37600 , test  accuracy 0.717949\n",
      "step 37600 , test loss : 0.650053\n",
      "step 37700 , training  accuracy 1\n",
      "step 37700 , loss : 0.472526\n",
      "step 37700 , validation  accuracy 0.820513\n",
      "step 37700 , validation loss : 0.631514\n",
      "step 37700 , test  accuracy 0.692308\n",
      "step 37700 , test loss : 0.648913\n",
      "step 37800 , training  accuracy 0.966667\n",
      "step 37800 , loss : 0.508359\n",
      "step 37800 , validation  accuracy 0.820513\n",
      "step 37800 , validation loss : 0.631246\n",
      "step 37800 , test  accuracy 0.692308\n",
      "step 37800 , test loss : 0.646921\n",
      "step 37900 , training  accuracy 1\n",
      "step 37900 , loss : 0.473076\n",
      "step 37900 , validation  accuracy 0.820513\n",
      "step 37900 , validation loss : 0.628774\n",
      "step 37900 , test  accuracy 0.692308\n",
      "step 37900 , test loss : 0.644921\n",
      "step 38000 , training  accuracy 1\n",
      "step 38000 , loss : 0.469861\n",
      "step 38000 , validation  accuracy 0.794872\n",
      "step 38000 , validation loss : 0.628574\n",
      "step 38000 , test  accuracy 0.717949\n",
      "step 38000 , test loss : 0.643007\n",
      "step 38100 , training  accuracy 1\n",
      "step 38100 , loss : 0.472527\n",
      "step 38100 , validation  accuracy 0.794872\n",
      "step 38100 , validation loss : 0.628803\n",
      "step 38100 , test  accuracy 0.74359\n",
      "step 38100 , test loss : 0.641362\n",
      "step 38200 , training  accuracy 1\n",
      "step 38200 , loss : 0.473919\n",
      "step 38200 , validation  accuracy 0.820513\n",
      "step 38200 , validation loss : 0.625814\n",
      "step 38200 , test  accuracy 0.74359\n",
      "step 38200 , test loss : 0.640226\n",
      "step 38300 , training  accuracy 1\n",
      "step 38300 , loss : 0.473021\n",
      "step 38300 , validation  accuracy 0.820513\n",
      "step 38300 , validation loss : 0.62487\n",
      "step 38300 , test  accuracy 0.74359\n",
      "step 38300 , test loss : 0.639317\n",
      "step 38400 , training  accuracy 1\n",
      "step 38400 , loss : 0.471658\n",
      "step 38400 , validation  accuracy 0.846154\n",
      "step 38400 , validation loss : 0.62513\n",
      "step 38400 , test  accuracy 0.74359\n",
      "step 38400 , test loss : 0.638821\n",
      "step 38500 , training  accuracy 1\n",
      "step 38500 , loss : 0.468508\n",
      "step 38500 , validation  accuracy 0.846154\n",
      "step 38500 , validation loss : 0.624255\n",
      "step 38500 , test  accuracy 0.717949\n",
      "step 38500 , test loss : 0.638527\n",
      "step 38600 , training  accuracy 1\n",
      "step 38600 , loss : 0.469482\n",
      "step 38600 , validation  accuracy 0.820513\n",
      "step 38600 , validation loss : 0.624218\n",
      "step 38600 , test  accuracy 0.717949\n",
      "step 38600 , test loss : 0.639653\n",
      "step 38700 , training  accuracy 1\n",
      "step 38700 , loss : 0.470301\n",
      "step 38700 , validation  accuracy 0.794872\n",
      "step 38700 , validation loss : 0.625105\n",
      "step 38700 , test  accuracy 0.692308\n",
      "step 38700 , test loss : 0.641162\n",
      "step 38800 , training  accuracy 1\n",
      "step 38800 , loss : 0.468467\n",
      "step 38800 , validation  accuracy 0.794872\n",
      "step 38800 , validation loss : 0.625965\n",
      "step 38800 , test  accuracy 0.692308\n",
      "step 38800 , test loss : 0.641631\n",
      "step 38900 , training  accuracy 1\n",
      "step 38900 , loss : 0.475933\n",
      "step 38900 , validation  accuracy 0.794872\n",
      "step 38900 , validation loss : 0.626991\n",
      "step 38900 , test  accuracy 0.692308\n",
      "step 38900 , test loss : 0.642674\n",
      "step 39000 , training  accuracy 1\n",
      "step 39000 , loss : 0.471906\n",
      "step 39000 , validation  accuracy 0.794872\n",
      "step 39000 , validation loss : 0.627247\n",
      "step 39000 , test  accuracy 0.717949\n",
      "step 39000 , test loss : 0.64353\n",
      "step 39100 , training  accuracy 1\n",
      "step 39100 , loss : 0.469704\n",
      "step 39100 , validation  accuracy 0.794872\n",
      "step 39100 , validation loss : 0.627355\n",
      "step 39100 , test  accuracy 0.692308\n",
      "step 39100 , test loss : 0.643995\n",
      "step 39200 , training  accuracy 1\n",
      "step 39200 , loss : 0.467416\n",
      "step 39200 , validation  accuracy 0.794872\n",
      "step 39200 , validation loss : 0.627631\n",
      "step 39200 , test  accuracy 0.692308\n",
      "step 39200 , test loss : 0.644457\n",
      "step 39300 , training  accuracy 1\n",
      "step 39300 , loss : 0.466294\n",
      "step 39300 , validation  accuracy 0.794872\n",
      "step 39300 , validation loss : 0.627399\n",
      "step 39300 , test  accuracy 0.692308\n",
      "step 39300 , test loss : 0.64496\n",
      "step 39400 , training  accuracy 1\n",
      "step 39400 , loss : 0.468159\n",
      "step 39400 , validation  accuracy 0.794872\n",
      "step 39400 , validation loss : 0.626792\n",
      "step 39400 , test  accuracy 0.692308\n",
      "step 39400 , test loss : 0.644265\n",
      "step 39500 , training  accuracy 1\n",
      "step 39500 , loss : 0.467466\n",
      "step 39500 , validation  accuracy 0.794872\n",
      "step 39500 , validation loss : 0.626901\n",
      "step 39500 , test  accuracy 0.692308\n",
      "step 39500 , test loss : 0.643187\n",
      "step 39600 , training  accuracy 1\n",
      "step 39600 , loss : 0.468958\n",
      "step 39600 , validation  accuracy 0.794872\n",
      "step 39600 , validation loss : 0.627458\n",
      "step 39600 , test  accuracy 0.666667\n",
      "step 39600 , test loss : 0.643088\n",
      "step 39700 , training  accuracy 1\n",
      "step 39700 , loss : 0.470074\n",
      "step 39700 , validation  accuracy 0.769231\n",
      "step 39700 , validation loss : 0.627284\n",
      "step 39700 , test  accuracy 0.692308\n",
      "step 39700 , test loss : 0.642638\n",
      "step 39800 , training  accuracy 1\n",
      "step 39800 , loss : 0.469225\n",
      "step 39800 , validation  accuracy 0.769231\n",
      "step 39800 , validation loss : 0.627176\n",
      "step 39800 , test  accuracy 0.692308\n",
      "step 39800 , test loss : 0.643035\n",
      "step 39900 , training  accuracy 1\n",
      "step 39900 , loss : 0.469123\n",
      "step 39900 , validation  accuracy 0.769231\n",
      "step 39900 , validation loss : 0.626193\n",
      "step 39900 , test  accuracy 0.692308\n",
      "step 39900 , test loss : 0.643949\n",
      "step 40000 , training  accuracy 1\n",
      "step 40000 , loss : 0.471166\n",
      "step 40000 , validation  accuracy 0.769231\n",
      "step 40000 , validation loss : 0.624927\n",
      "step 40000 , test  accuracy 0.717949\n",
      "step 40000 , test loss : 0.645415\n",
      "step 40100 , training  accuracy 1\n",
      "step 40100 , loss : 0.470094\n",
      "step 40100 , validation  accuracy 0.769231\n",
      "step 40100 , validation loss : 0.624474\n",
      "step 40100 , test  accuracy 0.717949\n",
      "step 40100 , test loss : 0.646479\n",
      "step 40200 , training  accuracy 1\n",
      "step 40200 , loss : 0.471019\n",
      "step 40200 , validation  accuracy 0.794872\n",
      "step 40200 , validation loss : 0.624324\n",
      "step 40200 , test  accuracy 0.717949\n",
      "step 40200 , test loss : 0.646892\n",
      "step 40300 , training  accuracy 1\n",
      "step 40300 , loss : 0.475125\n",
      "step 40300 , validation  accuracy 0.794872\n",
      "step 40300 , validation loss : 0.625407\n",
      "step 40300 , test  accuracy 0.74359\n",
      "step 40300 , test loss : 0.648331\n",
      "step 40400 , training  accuracy 1\n",
      "step 40400 , loss : 0.475796\n",
      "step 40400 , validation  accuracy 0.794872\n",
      "step 40400 , validation loss : 0.626333\n",
      "step 40400 , test  accuracy 0.769231\n",
      "step 40400 , test loss : 0.649413\n",
      "step 40500 , training  accuracy 1\n",
      "step 40500 , loss : 0.47162\n",
      "step 40500 , validation  accuracy 0.794872\n",
      "step 40500 , validation loss : 0.626638\n",
      "step 40500 , test  accuracy 0.769231\n",
      "step 40500 , test loss : 0.649574\n",
      "step 40600 , training  accuracy 1\n",
      "step 40600 , loss : 0.478416\n",
      "step 40600 , validation  accuracy 0.794872\n",
      "step 40600 , validation loss : 0.62745\n",
      "step 40600 , test  accuracy 0.769231\n",
      "step 40600 , test loss : 0.650028\n",
      "step 40700 , training  accuracy 1\n",
      "step 40700 , loss : 0.474938\n",
      "step 40700 , validation  accuracy 0.794872\n",
      "step 40700 , validation loss : 0.628091\n",
      "step 40700 , test  accuracy 0.769231\n",
      "step 40700 , test loss : 0.649884\n",
      "step 40800 , training  accuracy 1\n",
      "step 40800 , loss : 0.470922\n",
      "step 40800 , validation  accuracy 0.794872\n",
      "step 40800 , validation loss : 0.628193\n",
      "step 40800 , test  accuracy 0.769231\n",
      "step 40800 , test loss : 0.649099\n",
      "step 40900 , training  accuracy 1\n",
      "step 40900 , loss : 0.472376\n",
      "step 40900 , validation  accuracy 0.794872\n",
      "step 40900 , validation loss : 0.62981\n",
      "step 40900 , test  accuracy 0.769231\n",
      "step 40900 , test loss : 0.64861\n",
      "step 41000 , training  accuracy 1\n",
      "step 41000 , loss : 0.471469\n",
      "step 41000 , validation  accuracy 0.769231\n",
      "step 41000 , validation loss : 0.630888\n",
      "step 41000 , test  accuracy 0.769231\n",
      "step 41000 , test loss : 0.647182\n",
      "step 41100 , training  accuracy 1\n",
      "step 41100 , loss : 0.470733\n",
      "step 41100 , validation  accuracy 0.769231\n",
      "step 41100 , validation loss : 0.631603\n",
      "step 41100 , test  accuracy 0.769231\n",
      "step 41100 , test loss : 0.645209\n",
      "step 41200 , training  accuracy 1\n",
      "step 41200 , loss : 0.470697\n",
      "step 41200 , validation  accuracy 0.769231\n",
      "step 41200 , validation loss : 0.632845\n",
      "step 41200 , test  accuracy 0.769231\n",
      "step 41200 , test loss : 0.644123\n",
      "step 41300 , training  accuracy 1\n",
      "step 41300 , loss : 0.475102\n",
      "step 41300 , validation  accuracy 0.74359\n",
      "step 41300 , validation loss : 0.633427\n",
      "step 41300 , test  accuracy 0.769231\n",
      "step 41300 , test loss : 0.643267\n",
      "step 41400 , training  accuracy 1\n",
      "step 41400 , loss : 0.474031\n",
      "step 41400 , validation  accuracy 0.74359\n",
      "step 41400 , validation loss : 0.634452\n",
      "step 41400 , test  accuracy 0.769231\n",
      "step 41400 , test loss : 0.643225\n",
      "step 41500 , training  accuracy 1\n",
      "step 41500 , loss : 0.470272\n",
      "step 41500 , validation  accuracy 0.74359\n",
      "step 41500 , validation loss : 0.637847\n",
      "step 41500 , test  accuracy 0.717949\n",
      "step 41500 , test loss : 0.647868\n",
      "step 41600 , training  accuracy 1\n",
      "step 41600 , loss : 0.472164\n",
      "step 41600 , validation  accuracy 0.74359\n",
      "step 41600 , validation loss : 0.640293\n",
      "step 41600 , test  accuracy 0.692308\n",
      "step 41600 , test loss : 0.650851\n",
      "step 41700 , training  accuracy 1\n",
      "step 41700 , loss : 0.476882\n",
      "step 41700 , validation  accuracy 0.74359\n",
      "step 41700 , validation loss : 0.640073\n",
      "step 41700 , test  accuracy 0.692308\n",
      "step 41700 , test loss : 0.648632\n",
      "step 41800 , training  accuracy 1\n",
      "step 41800 , loss : 0.471775\n",
      "step 41800 , validation  accuracy 0.74359\n",
      "step 41800 , validation loss : 0.637817\n",
      "step 41800 , test  accuracy 0.74359\n",
      "step 41800 , test loss : 0.644489\n",
      "step 41900 , training  accuracy 1\n",
      "step 41900 , loss : 0.470572\n",
      "step 41900 , validation  accuracy 0.717949\n",
      "step 41900 , validation loss : 0.63428\n",
      "step 41900 , test  accuracy 0.794872\n",
      "step 41900 , test loss : 0.63998\n",
      "step 42000 , training  accuracy 1\n",
      "step 42000 , loss : 0.47144\n",
      "step 42000 , validation  accuracy 0.74359\n",
      "step 42000 , validation loss : 0.6329\n",
      "step 42000 , test  accuracy 0.794872\n",
      "step 42000 , test loss : 0.637517\n",
      "step 42100 , training  accuracy 1\n",
      "step 42100 , loss : 0.470124\n",
      "step 42100 , validation  accuracy 0.74359\n",
      "step 42100 , validation loss : 0.632405\n",
      "step 42100 , test  accuracy 0.794872\n",
      "step 42100 , test loss : 0.636394\n",
      "step 42200 , training  accuracy 1\n",
      "step 42200 , loss : 0.474219\n",
      "step 42200 , validation  accuracy 0.74359\n",
      "step 42200 , validation loss : 0.635077\n",
      "step 42200 , test  accuracy 0.769231\n",
      "step 42200 , test loss : 0.638444\n",
      "step 42300 , training  accuracy 1\n",
      "step 42300 , loss : 0.472832\n",
      "step 42300 , validation  accuracy 0.692308\n",
      "step 42300 , validation loss : 0.638914\n",
      "step 42300 , test  accuracy 0.717949\n",
      "step 42300 , test loss : 0.642289\n",
      "step 42400 , training  accuracy 1\n",
      "step 42400 , loss : 0.478997\n",
      "step 42400 , validation  accuracy 0.74359\n",
      "step 42400 , validation loss : 0.644203\n",
      "step 42400 , test  accuracy 0.717949\n",
      "step 42400 , test loss : 0.64782\n",
      "step 42500 , training  accuracy 1\n",
      "step 42500 , loss : 0.481875\n",
      "step 42500 , validation  accuracy 0.74359\n",
      "step 42500 , validation loss : 0.645948\n",
      "step 42500 , test  accuracy 0.717949\n",
      "step 42500 , test loss : 0.650924\n",
      "step 42600 , training  accuracy 1\n",
      "step 42600 , loss : 0.481711\n",
      "step 42600 , validation  accuracy 0.74359\n",
      "step 42600 , validation loss : 0.646405\n",
      "step 42600 , test  accuracy 0.717949\n",
      "step 42600 , test loss : 0.652344\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    train_ind=0\n",
    "    for i in range(iterate):    \n",
    "        if divide_flag ==True:\n",
    "            if batch_count >= n_batch:\n",
    "                batch_count =0\n",
    "            train_img =np.load(file_locate+train_images[batch_count])\n",
    "            train_lab =np.load(file_locate+train_labels[batch_count])\n",
    "        batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)\n",
    "        #batch_val_xs  , batch_val_ys = next_batch(20 , val_img , val_lab)\n",
    "        if i%100 ==0: # in here add to validation \n",
    "\n",
    "            try:\n",
    "                if aug_flag==True:\n",
    "                    print 'aug'\n",
    "                    aug_val_acc_list=[]\n",
    "                    aug_val_loss_list=[]\n",
    "                    aug_test_acc_list=[]\n",
    "                    aug_test_loss_list=[]\n",
    "\n",
    "                    for k in range(len(val_img)):\n",
    "                        aug_val_img , aug_val_lab=test_aug(val_img[k] , val_lab[k] , 64,64, 1 , 2)\n",
    "                        aug_test_img , aug_test_lab=test_aug(test_img[k] , test_lab[k] , 64,64, 1 , 2)                    \n",
    "                        val_accuracy ,val_loss = sess.run( [accuracy,cost] , feed_dict={x:aug_val_img , y_:aug_val_lab , keep_prob: 1.0})        \n",
    "                        test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:aug_test_img , y_:aug_test_lab , keep_prob: 1.0})\n",
    "                        aug_val_acc_list.append(val_accuracy);aug_val_loss_list.append(val_loss);\n",
    "                        aug_test_acc_list.append(test_accuracy);aug_test_loss_list.append(test_loss);\n",
    "                    val_accuracy=np.mean(np.asarray(aug_val_acc_list));val_loss=np.mean(np.asarray(aug_val_loss_list))\n",
    "                    test_accuracy=np.mean(np.asarray(aug_test_acc_list));test_loss=np.mean(np.asarray(aug_test_loss_list))\n",
    "                    print 'a'\n",
    "                    print i\n",
    "                    if i==0:\n",
    "                        print 'a'\n",
    "                        train_accuracy=0.0\n",
    "                        train_loss=0.0\n",
    "                else:\n",
    "                    val_accuracy ,val_loss = sess.run( [accuracy,cost] , feed_dict={x:val_img , y_:val_lab , keep_prob: 1.0})        \n",
    "                    train_accuracy ,train_loss= sess.run([accuracy,cost] , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "                    test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})\n",
    "\n",
    "\n",
    "                if (val_accuracy+test_accuracy)/2 > max_acc:\n",
    "                    print 'model_was_saved'\n",
    "                    if save_flag == True:\n",
    "                        save_numpy_weight(model_save_path)\n",
    "                    max_acc=(val_accuracy+test_accuracy)/2\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                if show_Exception_flag:\n",
    "                    print str(e)\n",
    "                    show_Exception_flag=False\n",
    "\n",
    "                list_acc=[]\n",
    "                list_loss=[]\n",
    "                n_divide=len(val_img)/batch_size\n",
    "                j=0\n",
    "\n",
    "                #validation \n",
    "                for j in range(n_divide):\n",
    "                    # j*batch_size :(j+1)*batch_size\n",
    "                    val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :(j+1)*batch_size] , y_:val_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                    list_acc.append(float(val_accuracy));list_loss.append(float(val_loss))\n",
    "                val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "                list_acc=np.asarray(list_acc);list_loss= np.asarray(list_loss);\n",
    "                val_accuracy=np.mean(list_acc);val_loss = np.mean(list_loss); \n",
    "                val_acc_list.append(val_accuracy)\n",
    "                val_loss_list.append(val_loss)\n",
    "\n",
    "                if (val_accuracy+test_accuracy)/2 > max_acc:\n",
    "                    print 'model_was_saved'\n",
    "                    max_acc=(val_accuracy+test_accuracy)/2\n",
    "                    if save_flag == True:\n",
    "                        print 'model_was_upgraded'\n",
    "                        save_numpy_weight(model_save_path)\n",
    "\n",
    "\n",
    "                #testing    \n",
    "                test_list_acc=[]\n",
    "                test_list_loss=[]        \n",
    "                for j in range(n_divide):    \n",
    "                    # j*batch_size :(j+1)*batch_size\n",
    "                    test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                    test_list_acc.append(float(test_accuracy));test_list_loss.append(float(test_loss))\n",
    "                #right above code have to modify\n",
    "                test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "                test_list_acc.append(test_accuracy);test_list_loss.append(test_loss)\n",
    "                #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "                train_accuracy ,train_loss = sess.run( [accuracy ,cost], feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "\n",
    "            ###record val_acc , loss  and train acc ,and loss\n",
    "            val_acc_list.append(val_accuracy);val_loss_list.append(val_loss)\n",
    "            train_acc_list.append(train_accuracy);train_loss_list.append(train_loss)                \n",
    "            ###record train_acc,loss to file\n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "            ###record val_acc,loss to file\n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "            ###record val_acc,loss to file\n",
    "            print(\"step %d , test  accuracy %g\" %(i,test_accuracy))\n",
    "            print(\"step %d , test loss : %g\" %(i,test_loss))           \n",
    "\n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            if divide_flag ==True:\n",
    "                batch_count+=1\n",
    "            ####training####\n",
    "            if aug_flag==True:\n",
    "                if train_ind == len(train_img):\n",
    "                    train_ind=0\n",
    "                aug_imgs , aug_labs=aug(train_img[train_ind:train_ind+1] ,64,64,train_lab[train_ind:train_ind+1])\n",
    "                try:\n",
    "                    sess.run(train_step ,feed_dict={x:aug_imgs , y_:aug_labs , keep_prob : 0.7})\n",
    "                    train_ind+=1\n",
    "                except Exception as e:\n",
    "\n",
    "                    if show_Exception_flag:\n",
    "                        print str(e)\n",
    "                        show_Exception_flag=False\n",
    "                    acc_=[]\n",
    "                    loss_=[]\n",
    "                    divide=len(aug_imgs)/batch_size\n",
    "                    for d in range(divide):\n",
    "                        _,acc,loss=sess.run([train_step,accuracy,cost] ,feed_dict={x:aug_imgs[d*batch_size:(d+1)*batch_size] ,\\\n",
    "                                                        y_:aug_labs[d*batch_size:(d+1)*batch_size] , keep_prob : 0.7})\n",
    "                        acc_.append(acc);loss_.append(loss);\n",
    "                    _,acc,loss=sess.run([train_step,accuracy,cost],feed_dict={x:aug_imgs[d*batch_size:] , y_:aug_labs[d*batch_size:] , keep_prob : 0.7})\n",
    "                    acc_.append(acc);loss_.append(loss)\n",
    "                    train_accuracy=np.mean(np.asarray(acc_))\n",
    "                    train_loss=np.mean(np.asarray(loss_))\n",
    "                    train_ind+=1\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                sess.run(train_step ,feed_dict={x:batch_xs , y_:batch_ys , keep_prob : 0.7})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    np.save(model_save_path+'val_acc',np.asarray(val_acc_list))\n",
    "    np.save(model_save_path+'val_loss',np.asarray(val_loss_list))\n",
    "    np.save(model_save_path+'train_acc',np.asarray(train_acc_list))\n",
    "    np.save(model_save_path+'train_loss',np.asarray(train_loss_list))\n",
    "    softmax_=sess.run( pred , feed_dict={x:test_img  ,y_:test_lab, keep_prob: 1.0})\n",
    "    test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    f.write(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print softmax_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img=np.load('/home/seongjung/save_numpy/1.npy')\n",
    "print np.shape(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    softmax_=sess.run( accuracy , feed_dict={x:test_img  , keep_prob: 1.0})\n",
    "    test_accuracy = sess.run( accuracy , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})        \n",
    "    test_loss = sess.run(cost , feed_dict = {x:test_img , y_: test_lab , keep_prob: 1.0})\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n",
    "except :\n",
    "    list_acc=[]\n",
    "    list_loss=[]\n",
    "    n_divide=len(test_img)/batch_size\n",
    "    for j in range(n_divide):\n",
    "\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "        list_acc.append(float(test_accuracy))\n",
    "        list_loss.append(float(test_loss))\n",
    "    test_accuracy , test_loss=sess.run([accuracy,cost] , feed_dict={x:test_img[(j+1)*batch_size : ] , y_:test_lab[(j+1)*(batch_size) : ] , keep_prob : 1.0})\n",
    "    #right above code have to modify\n",
    "\n",
    "    list_acc.append(test_accuracy)\n",
    "    list_loss.append(test_loss)\n",
    "    list_acc=np.asarray(list_acc)\n",
    "    list_loss= np.asarray(list_loss)\n",
    "\n",
    "    test_accuracy=np.mean(list_acc)\n",
    "    test_loss = np.mean(list_loss)\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_img[8])\n",
    "train_lab[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
