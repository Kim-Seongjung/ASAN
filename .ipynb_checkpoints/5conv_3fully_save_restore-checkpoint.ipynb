{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 100, 100, 3)\n",
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "file_locate='/home/seongjung/바탕화면/Numpy_ASAN/Mal_vs_Benign/100_100/4/3/'\n",
    "file_locate='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/0_0'\n",
    "sess = tf.InteractiveSession()\n",
    "test_img=np.load(file_locate+'test_img.npy');\n",
    "try:\n",
    "    print np.shape(test_img)\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "except:\n",
    "    np.shape(test_img)\n",
    "    test_img=np.reshape(test_img , newshape = [np.shape(test_img)[0] , 32, 32 ,3] )\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "\n",
    "    \n",
    "divide_flag= False\n",
    "restore_flag =True\n",
    "save_flag=False\n",
    "#odel_save_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/3_0/'\n",
    "model_save_path='/home/seongjung/바탕화면/4_3/'\n",
    "if restore_flag ==True:\n",
    "#   restore_path='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/ASAN_weight_bias/3_0/'\n",
    "    restore_path='/home/seongjung/바탕화면/4_3/'\n",
    "batch_size=30\n",
    "print img_row ,img_col\n",
    "n_classes =2\n",
    "in_ch =3\n",
    "out_ch1=200\n",
    "out_ch2=200\n",
    "out_ch3=200\n",
    "out_ch4=200\n",
    "out_ch5=200\n",
    "\n",
    "\n",
    "fully_ch1=1024\n",
    "fully_ch2 =1024\n",
    "fully_ch3 =1024\n",
    "\n",
    "\n",
    "\n",
    "strides_1=[1,2,2,1]\n",
    "strides_2=[1,1,1,1]\n",
    "strides_3=[1,1,1,1]\n",
    "strides_4=[1,1,1,1]\n",
    "strides_5=[1,1,1,1]\n",
    "\n",
    "\n",
    "x= tf.placeholder(\"float\",shape=[None,img_col , img_row , 3],  name = 'x-input')\n",
    "y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,3])\n",
    "\n",
    "iterate=100000\n",
    "\n",
    "\n",
    "\n",
    "weight_row =3 ; weight_col=3\n",
    "\n",
    "\n",
    "pooling_row_size1=int(img_row/2)\n",
    "pooling_row_size2=int(pooling_row_size1/2)\n",
    "pooling_row_size3=int(pooling_row_size2/2)\n",
    "pooling_row_size4=int(pooling_row_size3/2)\n",
    "pooling_row_size5=int(pooling_row_size4/2)\n",
    "pooling_col_size1=int(img_col/2)\n",
    "pooling_col_size2=int(pooling_col_size1/2)\n",
    "pooling_col_size3=int(pooling_col_size2/2)\n",
    "pooling_col_size4=int(pooling_col_size3/2)\n",
    "pooling_col_size5=int(pooling_col_size4/2)\n",
    "\n",
    "print img_col , img_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-115-b13b87c38836>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-115-b13b87c38836>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    y_true = # ground truth labels\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import scikitplot.plotters as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = # ground truth labels\n",
    "y_probas = # predicted probabilities generated by sklearn classifier\n",
    "skplt.plot_roc_curve(y_true, y_probas)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Weight and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/seongjung/jupyter'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (306, 100, 100, 3)\n",
      "Training Data Label (306, 2)\n",
      "Test Data Label (39, 2)\n",
      "val Data Label (38, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#with tf.device('/gpu:0'):\n",
    "\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img_1.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab_1.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "with tf.device('/gpu:0'):\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1 , shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    def conv2d(x,w,strides_):\n",
    "        return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            b_conv1 = bias_variable([out_ch1])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv1 = bias_variable([out_ch1])\n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        try:\n",
    "            w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        try:\n",
    "            b_conv2= bias_variable([out_ch2])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv2= bias_variable([out_ch2])\n",
    "\n",
    "    with tf.variable_scope('layer3') as scope:\n",
    "        try:\n",
    "            w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer3') as scope:\n",
    "        try:\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "\n",
    "    with tf.variable_scope('layer4') as scope:\n",
    "        try:\n",
    "            w_conv4 =tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer4') as scope:\n",
    "        try:\n",
    "            b_conv4 = bias_variable([out_ch4])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n",
    "\n",
    "    with tf.variable_scope('layer5') as scope:\n",
    "        try:\n",
    "            w_conv5 = tf.get_variable(\"W5\",[weight_row,weight_col,out_ch4,out_ch5] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.get_variable(\"W5\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    with tf.variable_scope('layer5') as scope:\n",
    "        try:\n",
    "            b_conv5 = bias_variable([out_ch5])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 = bias_variable([out_ch3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==True:\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv1 = tf.Variable(np.load(restore_path+'/w_conv1.npy'),name=\"W1\")\n",
    "    with tf.variable_scope(\"layer1\") as scope:\n",
    "        try:\n",
    "            b_conv1 = tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv1 =tf.Variable(np.load(restore_path+'/b_conv1.npy'),name=\"B1\")\n",
    "    with tf.variable_scope(\"layer2\") as scope:\n",
    "        try:\n",
    "            w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv2 = tf.Variable(np.load(restore_path+'/w_conv2.npy'),name=\"W2\")\n",
    "    with tf.variable_scope(\"layer2\") as scope:\n",
    "        try:\n",
    "            b_conv2 = tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv2 =tf.Variable(np.load(restore_path+'/b_conv2.npy'),name=\"B2\")\n",
    "    with tf.variable_scope(\"layer3\") as scope:\n",
    "        try:\n",
    "            w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv3 = tf.Variable(np.load(restore_path+'/w_conv3.npy'),name=\"W3\")\n",
    "    with tf.variable_scope(\"layer3\") as scope:\n",
    "        try:\n",
    "            b_conv3 = tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv3 =tf.Variable(np.load(restore_path+'/b_conv3.npy'),name=\"B3\")\n",
    "    with tf.variable_scope(\"layer4\") as scope:\n",
    "        try:\n",
    "            w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv4 = tf.Variable(np.load(restore_path+'/w_conv4.npy'),name=\"W4\")\n",
    "    with tf.variable_scope(\"layer4\") as scope:\n",
    "        try:\n",
    "            b_conv4 = tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv4 =tf.Variable(np.load(restore_path+'/b_conv4.npy'),name=\"B4\")\n",
    "    with tf.variable_scope(\"layer5\") as scope:\n",
    "        try:\n",
    "            w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_conv5 = tf.Variable(np.load(restore_path+'/w_conv5.npy'),name=\"W5\")\n",
    "    with tf.variable_scope(\"layer5\") as scope:\n",
    "        try:\n",
    "            b_conv5 = tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_conv5 =tf.Variable(np.load(restore_path+'/b_conv5.npy'),name=\"B5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_24:0\", shape=(?, 50, 50, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool_9:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_26:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_27:0\", shape=(?, 25, 25, 200), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool_11:0\", shape=(?, 13, 13, 200), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "#conncect hidden layer \n",
    "with tf.device('/gpu:0'):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image , w_conv1 ,strides_1)+b_conv1)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1 , w_conv2 ,strides_2)+b_conv2)\n",
    "    h_conv2 = max_pool_2x2(h_conv2)#pooling\n",
    "    \n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2 , w_conv3,strides_3)+b_conv3)\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3 , w_conv4,strides_4)+b_conv4)\n",
    "    h_pool4 = max_pool_2x2(h_conv4) #pooling \n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, w_conv5,strides_5)+b_conv5)\n",
    "    h_conv5= max_pool_2x2(h_conv5) #pooling \n",
    "\n",
    "    print h_conv1\n",
    "    print h_conv2\n",
    "    print h_conv3\n",
    "    print h_conv4\n",
    "    print h_conv5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_conv = h_conv5\n",
    "#print conv2d(h_pool1 , w_conv2).get_shape()\n",
    "end_conv_row=int(h_conv5.get_shape()[1])\n",
    "end_conv_col=int(h_conv5.get_shape()[2])\n",
    "end_conv_ch=int(h_conv5.get_shape()[3])\n",
    "#connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1 = bias_variable([fully_ch1])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            try:\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc1=tf.Variable(np.load(restore_path+'/w_fc1.npy'),name=\"fc1_W\")\n",
    "            try:\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc1=tf.Variable(np.load(restore_path+'/b_fc1.npy'),name=\"fc1_B\")\n",
    "\n",
    "        \n",
    "with tf.device('/gpu:0'): # flat conv layer \n",
    "    end_flat_conv =tf.reshape(end_conv, [-1,end_conv_col*end_conv_row*end_conv_ch])\n",
    "   \n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc1 = tf.nn.relu(tf.matmul(end_flat_conv , w_fc1)+ b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 1024)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.load('/home/seongjung/variable_save/w_fc1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.get_variable(\"fc2_W\",[fully_ch1,fully_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2 = bias_variable([fully_ch2])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            try:\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc2=tf.Variable(np.load(restore_path+'/w_fc2.npy'),name=\"fc2_W\")\n",
    "            try:\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc2=tf.Variable(np.load(restore_path+'/b_fc2.npy'),name=\"fc2_B\")\n",
    "\n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1 , w_fc2)+ b_fc2)\n",
    "    h_fc2 = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect fully connected layer \n",
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.get_variable(\"fc3_W\",[fully_ch2,fully_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3 = bias_variable([fully_ch3])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_fc3=tf.Variable(np.load(restore_path+'/w_fc3.npy'),name=\"fc3_W\")\n",
    "            try:\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy'),name=\"fc3_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_fc3=tf.Variable(np.load(restore_path+'/b_fc3.npy',name=\"fc3_B\"))\n",
    "\n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2 , w_fc3)+ b_fc3)\n",
    "    h_fc3 = tf.nn.dropout(h_fc3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_fc=h_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag==False:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope('fc3') as scope:\n",
    "            try:\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes ],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end =tf.get_variable(\"end_W\",[fully_ch3 , n_classes],initializer = tf.contrib.layers.xavier_initializer())\n",
    "            try:\n",
    "                b_end = bias_variable([n_classes])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end = bias_variable([n_classes])\n",
    "elif restore_flag==True:\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"fc3\") as scope:\n",
    "            try:\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_end=tf.Variable(np.load(restore_path+'/w_end.npy'),name=\"end_W\")\n",
    "            try:\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_end=tf.Variable(np.load(restore_path+'/b_end.npy'),name=\"end_B\")\n",
    "\n",
    "with tf.device('/gpu:0'):  # join flat layer with fully  connnected layer \n",
    "    y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recorded at :20\n"
     ]
    }
   ],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "\n",
    "dirname='/media/seongjung/Seagate Backup Plus Drive/data/ASAN/result/'\n",
    "dirname='/home/seongjung/바탕화면/result_temp/'    \n",
    "count=0\n",
    "while(True):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    elif not os.path.isdir(dirname + str(count)):\n",
    "        dirname=dirname+str(count)\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    else:\n",
    "        count+=1\n",
    "print 'it is recorded at :'+str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open(dirname+\"/log.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    print list_files\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_lab.npy', 'test_lab.npy', 'train_lab.npy', 'val_img.npy', 'test_img.npy', 'train_img.npy']\n"
     ]
    }
   ],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img.npy']\n",
      "['train_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_numpy_weight( model_save_path ):\n",
    "    \n",
    "    np_w_conv1,np_w_conv2,np_w_conv3,np_w_conv4,np_w_conv5=sess.run([w_conv1,w_conv2,w_conv3,w_conv4,w_conv5])\n",
    "    np_b_conv1,np_b_conv2,np_b_conv3,np_b_conv4,np_b_conv5=sess.run([b_conv1,b_conv2,b_conv3,b_conv4,b_conv5])\n",
    "    np_w_fc1 , np_w_fc2,np_w_fc3,np_w_end=sess.run([w_fc1 , w_fc2,w_fc3 ,w_end])\n",
    "    np_b_fc1 , np_b_fc2,np_b_fc3,np_b_end=sess.run([b_fc1 , b_fc2,b_fc3,b_end])\n",
    "    \n",
    "    np_w_conv1=np.asarray(np_w_conv1)\n",
    "    np_w_conv2=np.asarray(np_w_conv2)\n",
    "    np_w_conv3=np.asarray(np_w_conv3)\n",
    "    np_w_conv4=np.asarray(np_w_conv4)\n",
    "    np_w_conv5=np.asarray(np_w_conv5)\n",
    "    \n",
    "    np_b_conv1=np.asarray(np_b_conv1)\n",
    "    np_b_conv2=np.asarray(np_b_conv2)\n",
    "    np_b_conv3=np.asarray(np_b_conv3)\n",
    "    np_b_conv4=np.asarray(np_b_conv4)\n",
    "    np_b_conv5=np.asarray(np_b_conv5)\n",
    "    \n",
    "    np_w_fc1=np.asarray(np_w_fc1)\n",
    "    np_w_fc2=np.asarray(np_w_fc2)\n",
    "    np_w_fc3=np.asarray(np_w_fc3)\n",
    "    np_w_end=np.asarray(np_w_end)\n",
    "    \n",
    "    np_b_fc1=np.asarray(np_b_fc1)\n",
    "    np_b_fc2=np.asarray(np_b_fc2)\n",
    "    np_b_fc3=np.asarray(np_b_fc3)\n",
    "    np_b_end=np.asarray(np_b_end)\n",
    "    \n",
    "    \n",
    "    np.save(model_save_path +'w_conv1' , np_w_conv1)\n",
    "    np.save(model_save_path +'w_conv2' , np_w_conv2)\n",
    "    np.save(model_save_path +'w_conv3' , np_w_conv3)\n",
    "    np.save(model_save_path +'w_conv4' , np_w_conv4)\n",
    "    np.save(model_save_path +'w_conv5' , np_w_conv5)\n",
    "    \n",
    "    np.save(model_save_path +'b_conv1' , np_b_conv1)\n",
    "    np.save(model_save_path +'b_conv2' , np_b_conv2)\n",
    "    np.save(model_save_path +'b_conv3' , np_b_conv3)\n",
    "    np.save(model_save_path +'b_conv4' , np_b_conv4)\n",
    "    np.save(model_save_path +'b_conv5' , np_b_conv5)\n",
    "\n",
    "    np.save(model_save_path +'w_fc1' , np_w_fc1)\n",
    "    np.save(model_save_path +'w_fc2' , np_w_fc2)\n",
    "    np.save(model_save_path +'w_fc3' , np_w_fc3)\n",
    "    np.save(model_save_path +'w_end' , np_w_end)\n",
    "    \n",
    "    np.save(model_save_path +'b_fc1' , np_b_fc1)\n",
    "    np.save(model_save_path +'b_fc2' , np_b_fc2)\n",
    "    np.save(model_save_path +'b_fc3' , np_b_fc3)\n",
    "    np.save(model_save_path +'b_end' , np_b_end)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-110-7bef9d9333bc>:19 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "a\n",
      "step 0 , training  accuracy 1\n",
      "step 0 , loss : 0.482536\n",
      "step 0 , validation  accuracy 0.842105\n",
      "step 0 , validation loss : 0.656329\n",
      "step 0 , test  accuracy 0.820513\n",
      "step 0 , test loss : 0.659696\n",
      "step 100 , training  accuracy 0.966667\n",
      "step 100 , loss : 0.527408\n",
      "step 100 , validation  accuracy 0.684211\n",
      "step 100 , validation loss : 0.68257\n",
      "step 100 , test  accuracy 0.564103\n",
      "step 100 , test loss : 0.708311\n",
      "step 200 , training  accuracy 0.966667\n",
      "step 200 , loss : 0.512168\n",
      "step 200 , validation  accuracy 0.631579\n",
      "step 200 , validation loss : 0.693589\n",
      "step 200 , test  accuracy 0.589744\n",
      "step 200 , test loss : 0.701979\n",
      "step 300 , training  accuracy 0.833333\n",
      "step 300 , loss : 0.570353\n",
      "step 300 , validation  accuracy 0.526316\n",
      "step 300 , validation loss : 0.764559\n",
      "step 300 , test  accuracy 0.641026\n",
      "step 300 , test loss : 0.739231\n",
      "step 400 , training  accuracy 0.966667\n",
      "step 400 , loss : 0.491134\n",
      "step 400 , validation  accuracy 0.736842\n",
      "step 400 , validation loss : 0.685962\n",
      "step 400 , test  accuracy 0.641026\n",
      "step 400 , test loss : 0.680209\n",
      "step 500 , training  accuracy 1\n",
      "step 500 , loss : 0.502792\n",
      "step 500 , validation  accuracy 0.710526\n",
      "step 500 , validation loss : 0.66435\n",
      "step 500 , test  accuracy 0.692308\n",
      "step 500 , test loss : 0.687052\n",
      "step 600 , training  accuracy 1\n",
      "step 600 , loss : 0.498727\n",
      "step 600 , validation  accuracy 0.710526\n",
      "step 600 , validation loss : 0.685692\n",
      "step 600 , test  accuracy 0.74359\n",
      "step 600 , test loss : 0.728082\n",
      "step 700 , training  accuracy 1\n",
      "step 700 , loss : 0.50827\n",
      "step 700 , validation  accuracy 0.789474\n",
      "step 700 , validation loss : 0.657953\n",
      "step 700 , test  accuracy 0.615385\n",
      "step 700 , test loss : 0.724644\n",
      "step 800 , training  accuracy 0.933333\n",
      "step 800 , loss : 0.526387\n",
      "step 800 , validation  accuracy 0.815789\n",
      "step 800 , validation loss : 0.651389\n",
      "step 800 , test  accuracy 0.589744\n",
      "step 800 , test loss : 0.734691\n",
      "step 900 , training  accuracy 1\n",
      "step 900 , loss : 0.497056\n",
      "step 900 , validation  accuracy 0.789474\n",
      "step 900 , validation loss : 0.643308\n",
      "step 900 , test  accuracy 0.564103\n",
      "step 900 , test loss : 0.71752\n",
      "step 1000 , training  accuracy 1\n",
      "step 1000 , loss : 0.503087\n",
      "step 1000 , validation  accuracy 0.736842\n",
      "step 1000 , validation loss : 0.692574\n",
      "step 1000 , test  accuracy 0.641026\n",
      "step 1000 , test loss : 0.730665\n",
      "step 1100 , training  accuracy 0.9\n",
      "step 1100 , loss : 0.55694\n",
      "step 1100 , validation  accuracy 0.657895\n",
      "step 1100 , validation loss : 0.701448\n",
      "step 1100 , test  accuracy 0.538462\n",
      "step 1100 , test loss : 0.726782\n",
      "step 1200 , training  accuracy 0.966667\n",
      "step 1200 , loss : 0.542547\n",
      "step 1200 , validation  accuracy 0.631579\n",
      "step 1200 , validation loss : 0.723663\n",
      "step 1200 , test  accuracy 0.589744\n",
      "step 1200 , test loss : 0.759136\n",
      "step 1300 , training  accuracy 1\n",
      "step 1300 , loss : 0.490355\n",
      "step 1300 , validation  accuracy 0.736842\n",
      "step 1300 , validation loss : 0.660822\n",
      "step 1300 , test  accuracy 0.564103\n",
      "step 1300 , test loss : 0.730324\n",
      "step 1400 , training  accuracy 0.966667\n",
      "step 1400 , loss : 0.499603\n",
      "step 1400 , validation  accuracy 0.789474\n",
      "step 1400 , validation loss : 0.644085\n",
      "step 1400 , test  accuracy 0.589744\n",
      "step 1400 , test loss : 0.717988\n",
      "step 1500 , training  accuracy 1\n",
      "step 1500 , loss : 0.487008\n",
      "step 1500 , validation  accuracy 0.763158\n",
      "step 1500 , validation loss : 0.647505\n",
      "step 1500 , test  accuracy 0.589744\n",
      "step 1500 , test loss : 0.716594\n",
      "step 1600 , training  accuracy 0.966667\n",
      "step 1600 , loss : 0.509775\n",
      "step 1600 , validation  accuracy 0.789474\n",
      "step 1600 , validation loss : 0.688479\n",
      "step 1600 , test  accuracy 0.692308\n",
      "step 1600 , test loss : 0.7396\n",
      "step 1700 , training  accuracy 0.9\n",
      "step 1700 , loss : 0.526647\n",
      "step 1700 , validation  accuracy 0.815789\n",
      "step 1700 , validation loss : 0.669342\n",
      "step 1700 , test  accuracy 0.717949\n",
      "step 1700 , test loss : 0.717597\n",
      "step 1800 , training  accuracy 0.9\n",
      "step 1800 , loss : 0.570854\n",
      "step 1800 , validation  accuracy 0.789474\n",
      "step 1800 , validation loss : 0.631717\n",
      "step 1800 , test  accuracy 0.666667\n",
      "step 1800 , test loss : 0.687039\n",
      "step 1900 , training  accuracy 1\n",
      "step 1900 , loss : 0.499614\n",
      "step 1900 , validation  accuracy 0.789474\n",
      "step 1900 , validation loss : 0.628438\n",
      "step 1900 , test  accuracy 0.666667\n",
      "step 1900 , test loss : 0.682688\n",
      "step 2000 , training  accuracy 1\n",
      "step 2000 , loss : 0.503328\n",
      "step 2000 , validation  accuracy 0.815789\n",
      "step 2000 , validation loss : 0.635849\n",
      "step 2000 , test  accuracy 0.615385\n",
      "step 2000 , test loss : 0.698038\n",
      "step 2100 , training  accuracy 1\n",
      "step 2100 , loss : 0.507687\n",
      "step 2100 , validation  accuracy 0.842105\n",
      "step 2100 , validation loss : 0.645115\n",
      "step 2100 , test  accuracy 0.692308\n",
      "step 2100 , test loss : 0.702308\n",
      "step 2200 , training  accuracy 0.966667\n",
      "step 2200 , loss : 0.507563\n",
      "step 2200 , validation  accuracy 0.81579\n",
      "step 2200 , validation loss : 0.651609\n",
      "step 2200 , test  accuracy 0.692308\n",
      "step 2200 , test loss : 0.706396\n",
      "step 2300 , training  accuracy 1\n",
      "step 2300 , loss : 0.487211\n",
      "step 2300 , validation  accuracy 0.81579\n",
      "step 2300 , validation loss : 0.646031\n",
      "step 2300 , test  accuracy 0.666667\n",
      "step 2300 , test loss : 0.683173\n",
      "step 2400 , training  accuracy 0.9\n",
      "step 2400 , loss : 0.532083\n",
      "step 2400 , validation  accuracy 0.789474\n",
      "step 2400 , validation loss : 0.640311\n",
      "step 2400 , test  accuracy 0.666667\n",
      "step 2400 , test loss : 0.659325\n",
      "step 2500 , training  accuracy 1\n",
      "step 2500 , loss : 0.532542\n",
      "step 2500 , validation  accuracy 0.736842\n",
      "step 2500 , validation loss : 0.706873\n",
      "step 2500 , test  accuracy 0.666667\n",
      "step 2500 , test loss : 0.723275\n",
      "step 2600 , training  accuracy 0.9\n",
      "step 2600 , loss : 0.539822\n",
      "step 2600 , validation  accuracy 0.710526\n",
      "step 2600 , validation loss : 0.71797\n",
      "step 2600 , test  accuracy 0.641026\n",
      "step 2600 , test loss : 0.739058\n",
      "step 2700 , training  accuracy 1\n",
      "step 2700 , loss : 0.50915\n",
      "step 2700 , validation  accuracy 0.736842\n",
      "step 2700 , validation loss : 0.663728\n",
      "step 2700 , test  accuracy 0.666667\n",
      "step 2700 , test loss : 0.684251\n",
      "step 2800 , training  accuracy 1\n",
      "step 2800 , loss : 0.494137\n",
      "step 2800 , validation  accuracy 0.763158\n",
      "step 2800 , validation loss : 0.624524\n",
      "step 2800 , test  accuracy 0.717949\n",
      "step 2800 , test loss : 0.641965\n",
      "step 2900 , training  accuracy 1\n",
      "step 2900 , loss : 0.51151\n",
      "step 2900 , validation  accuracy 0.763158\n",
      "step 2900 , validation loss : 0.620297\n",
      "step 2900 , test  accuracy 0.692308\n",
      "step 2900 , test loss : 0.636755\n",
      "step 3000 , training  accuracy 1\n",
      "step 3000 , loss : 0.497873\n",
      "step 3000 , validation  accuracy 0.789474\n",
      "step 3000 , validation loss : 0.607045\n",
      "step 3000 , test  accuracy 0.717949\n",
      "step 3000 , test loss : 0.632512\n",
      "step 3100 , training  accuracy 0.966667\n",
      "step 3100 , loss : 0.502106\n",
      "step 3100 , validation  accuracy 0.789474\n",
      "step 3100 , validation loss : 0.613621\n",
      "step 3100 , test  accuracy 0.74359\n",
      "step 3100 , test loss : 0.643567\n",
      "step 3200 , training  accuracy 1\n",
      "step 3200 , loss : 0.484\n",
      "step 3200 , validation  accuracy 0.815789\n",
      "step 3200 , validation loss : 0.621825\n",
      "step 3200 , test  accuracy 0.769231\n",
      "step 3200 , test loss : 0.646596\n",
      "step 3300 , training  accuracy 1\n",
      "step 3300 , loss : 0.496357\n",
      "step 3300 , validation  accuracy 0.815789\n",
      "step 3300 , validation loss : 0.634205\n",
      "step 3300 , test  accuracy 0.74359\n",
      "step 3300 , test loss : 0.656632\n",
      "step 3400 , training  accuracy 1\n",
      "step 3400 , loss : 0.499048\n",
      "step 3400 , validation  accuracy 0.842105\n",
      "step 3400 , validation loss : 0.620268\n",
      "step 3400 , test  accuracy 0.74359\n",
      "step 3400 , test loss : 0.64792\n",
      "step 3500 , training  accuracy 1\n",
      "step 3500 , loss : 0.477435\n",
      "step 3500 , validation  accuracy 0.842105\n",
      "step 3500 , validation loss : 0.626589\n",
      "step 3500 , test  accuracy 0.769231\n",
      "step 3500 , test loss : 0.651751\n",
      "step 3600 , training  accuracy 1\n",
      "step 3600 , loss : 0.480993\n",
      "step 3600 , validation  accuracy 0.815789\n",
      "step 3600 , validation loss : 0.625946\n",
      "step 3600 , test  accuracy 0.769231\n",
      "step 3600 , test loss : 0.653451\n",
      "step 3700 , training  accuracy 1\n",
      "step 3700 , loss : 0.484648\n",
      "step 3700 , validation  accuracy 0.815789\n",
      "step 3700 , validation loss : 0.627662\n",
      "step 3700 , test  accuracy 0.717949\n",
      "step 3700 , test loss : 0.658129\n",
      "step 3800 , training  accuracy 0.966667\n",
      "step 3800 , loss : 0.506293\n",
      "step 3800 , validation  accuracy 0.815789\n",
      "step 3800 , validation loss : 0.632317\n",
      "step 3800 , test  accuracy 0.74359\n",
      "step 3800 , test loss : 0.663255\n",
      "step 3900 , training  accuracy 1\n",
      "step 3900 , loss : 0.479178\n",
      "step 3900 , validation  accuracy 0.842105\n",
      "step 3900 , validation loss : 0.625927\n",
      "step 3900 , test  accuracy 0.717949\n",
      "step 3900 , test loss : 0.661091\n",
      "step 4000 , training  accuracy 1\n",
      "step 4000 , loss : 0.496205\n",
      "step 4000 , validation  accuracy 0.815789\n",
      "step 4000 , validation loss : 0.620455\n",
      "step 4000 , test  accuracy 0.692308\n",
      "step 4000 , test loss : 0.663175\n",
      "step 4100 , training  accuracy 1\n",
      "step 4100 , loss : 0.483205\n",
      "step 4100 , validation  accuracy 0.789474\n",
      "step 4100 , validation loss : 0.619062\n",
      "step 4100 , test  accuracy 0.74359\n",
      "step 4100 , test loss : 0.668988\n",
      "step 4200 , training  accuracy 1\n",
      "step 4200 , loss : 0.519988\n",
      "step 4200 , validation  accuracy 0.736842\n",
      "step 4200 , validation loss : 0.649737\n",
      "step 4200 , test  accuracy 0.717949\n",
      "step 4200 , test loss : 0.688648\n",
      "step 4300 , training  accuracy 1\n",
      "step 4300 , loss : 0.499959\n",
      "step 4300 , validation  accuracy 0.763158\n",
      "step 4300 , validation loss : 0.635597\n",
      "step 4300 , test  accuracy 0.717949\n",
      "step 4300 , test loss : 0.674906\n",
      "step 4400 , training  accuracy 1\n",
      "step 4400 , loss : 0.475842\n",
      "step 4400 , validation  accuracy 0.763158\n",
      "step 4400 , validation loss : 0.614321\n",
      "step 4400 , test  accuracy 0.692308\n",
      "step 4400 , test loss : 0.65621\n",
      "step 4500 , training  accuracy 1\n",
      "step 4500 , loss : 0.484985\n",
      "step 4500 , validation  accuracy 0.789474\n",
      "step 4500 , validation loss : 0.618364\n",
      "step 4500 , test  accuracy 0.666667\n",
      "step 4500 , test loss : 0.655246\n",
      "step 4600 , training  accuracy 0.933333\n",
      "step 4600 , loss : 0.51526\n",
      "step 4600 , validation  accuracy 0.789474\n",
      "step 4600 , validation loss : 0.626317\n",
      "step 4600 , test  accuracy 0.717949\n",
      "step 4600 , test loss : 0.653664\n",
      "step 4700 , training  accuracy 1\n",
      "step 4700 , loss : 0.505871\n",
      "step 4700 , validation  accuracy 0.736842\n",
      "step 4700 , validation loss : 0.648797\n",
      "step 4700 , test  accuracy 0.74359\n",
      "step 4700 , test loss : 0.66237\n",
      "step 4800 , training  accuracy 0.966667\n",
      "step 4800 , loss : 0.518458\n",
      "step 4800 , validation  accuracy 0.736842\n",
      "step 4800 , validation loss : 0.677555\n",
      "step 4800 , test  accuracy 0.666667\n",
      "step 4800 , test loss : 0.685456\n",
      "step 4900 , training  accuracy 0.966667\n",
      "step 4900 , loss : 0.497585\n",
      "step 4900 , validation  accuracy 0.736842\n",
      "step 4900 , validation loss : 0.653604\n",
      "step 4900 , test  accuracy 0.692308\n",
      "step 4900 , test loss : 0.667835\n",
      "step 5000 , training  accuracy 1\n",
      "step 5000 , loss : 0.48581\n",
      "step 5000 , validation  accuracy 0.842105\n",
      "step 5000 , validation loss : 0.645923\n",
      "step 5000 , test  accuracy 0.74359\n",
      "step 5000 , test loss : 0.662714\n",
      "step 5100 , training  accuracy 1\n",
      "step 5100 , loss : 0.487864\n",
      "step 5100 , validation  accuracy 0.815789\n",
      "step 5100 , validation loss : 0.656767\n",
      "step 5100 , test  accuracy 0.769231\n",
      "step 5100 , test loss : 0.6719\n",
      "step 5200 , training  accuracy 0.966667\n",
      "step 5200 , loss : 0.498873\n",
      "step 5200 , validation  accuracy 0.842105\n",
      "step 5200 , validation loss : 0.647556\n",
      "step 5200 , test  accuracy 0.74359\n",
      "step 5200 , test loss : 0.66968\n",
      "step 5300 , training  accuracy 0.966667\n",
      "step 5300 , loss : 0.512805\n",
      "step 5300 , validation  accuracy 0.815789\n",
      "step 5300 , validation loss : 0.654621\n",
      "step 5300 , test  accuracy 0.692308\n",
      "step 5300 , test loss : 0.680024\n",
      "step 5400 , training  accuracy 1\n",
      "step 5400 , loss : 0.500708\n",
      "step 5400 , validation  accuracy 0.789474\n",
      "step 5400 , validation loss : 0.671874\n",
      "step 5400 , test  accuracy 0.717949\n",
      "step 5400 , test loss : 0.697243\n",
      "step 5500 , training  accuracy 1\n",
      "step 5500 , loss : 0.488618\n",
      "step 5500 , validation  accuracy 0.789474\n",
      "step 5500 , validation loss : 0.677227\n",
      "step 5500 , test  accuracy 0.74359\n",
      "step 5500 , test loss : 0.70043\n",
      "step 5600 , training  accuracy 1\n",
      "step 5600 , loss : 0.480445\n",
      "step 5600 , validation  accuracy 0.789474\n",
      "step 5600 , validation loss : 0.677382\n",
      "step 5600 , test  accuracy 0.692308\n",
      "step 5600 , test loss : 0.700626\n",
      "step 5700 , training  accuracy 1\n",
      "step 5700 , loss : 0.504313\n",
      "step 5700 , validation  accuracy 0.815789\n",
      "step 5700 , validation loss : 0.676877\n",
      "step 5700 , test  accuracy 0.692308\n",
      "step 5700 , test loss : 0.693322\n",
      "step 5800 , training  accuracy 1\n",
      "step 5800 , loss : 0.479089\n",
      "step 5800 , validation  accuracy 0.763158\n",
      "step 5800 , validation loss : 0.660432\n",
      "step 5800 , test  accuracy 0.717949\n",
      "step 5800 , test loss : 0.677358\n",
      "step 5900 , training  accuracy 1\n",
      "step 5900 , loss : 0.478079\n",
      "step 5900 , validation  accuracy 0.736842\n",
      "step 5900 , validation loss : 0.654229\n",
      "step 5900 , test  accuracy 0.666667\n",
      "step 5900 , test loss : 0.666991\n",
      "step 6000 , training  accuracy 1\n",
      "step 6000 , loss : 0.474526\n",
      "step 6000 , validation  accuracy 0.736842\n",
      "step 6000 , validation loss : 0.655809\n",
      "step 6000 , test  accuracy 0.692308\n",
      "step 6000 , test loss : 0.663307\n",
      "step 6100 , training  accuracy 1\n",
      "step 6100 , loss : 0.477984\n",
      "step 6100 , validation  accuracy 0.736842\n",
      "step 6100 , validation loss : 0.668974\n",
      "step 6100 , test  accuracy 0.666667\n",
      "step 6100 , test loss : 0.668102\n",
      "step 6200 , training  accuracy 1\n",
      "step 6200 , loss : 0.477879\n",
      "step 6200 , validation  accuracy 0.710526\n",
      "step 6200 , validation loss : 0.667864\n",
      "step 6200 , test  accuracy 0.666667\n",
      "step 6200 , test loss : 0.665412\n",
      "step 6300 , training  accuracy 1\n",
      "step 6300 , loss : 0.485562\n",
      "step 6300 , validation  accuracy 0.710526\n",
      "step 6300 , validation loss : 0.668341\n",
      "step 6300 , test  accuracy 0.666667\n",
      "step 6300 , test loss : 0.668957\n",
      "step 6400 , training  accuracy 1\n",
      "step 6400 , loss : 0.473677\n",
      "step 6400 , validation  accuracy 0.710526\n",
      "step 6400 , validation loss : 0.658816\n",
      "step 6400 , test  accuracy 0.641026\n",
      "step 6400 , test loss : 0.666336\n",
      "step 6500 , training  accuracy 0.966667\n",
      "step 6500 , loss : 0.486733\n",
      "step 6500 , validation  accuracy 0.736842\n",
      "step 6500 , validation loss : 0.651299\n",
      "step 6500 , test  accuracy 0.692308\n",
      "step 6500 , test loss : 0.667364\n",
      "step 6600 , training  accuracy 1\n",
      "step 6600 , loss : 0.481893\n",
      "step 6600 , validation  accuracy 0.710526\n",
      "step 6600 , validation loss : 0.644486\n",
      "step 6600 , test  accuracy 0.692308\n",
      "step 6600 , test loss : 0.669132\n",
      "step 6700 , training  accuracy 1\n",
      "step 6700 , loss : 0.474929\n",
      "step 6700 , validation  accuracy 0.736842\n",
      "step 6700 , validation loss : 0.648014\n",
      "step 6700 , test  accuracy 0.717949\n",
      "step 6700 , test loss : 0.668597\n",
      "step 6800 , training  accuracy 1\n",
      "step 6800 , loss : 0.486329\n",
      "step 6800 , validation  accuracy 0.736842\n",
      "step 6800 , validation loss : 0.675275\n",
      "step 6800 , test  accuracy 0.692308\n",
      "step 6800 , test loss : 0.683106\n",
      "step 6900 , training  accuracy 1\n",
      "step 6900 , loss : 0.485974\n",
      "step 6900 , validation  accuracy 0.736842\n",
      "step 6900 , validation loss : 0.679599\n",
      "step 6900 , test  accuracy 0.666667\n",
      "step 6900 , test loss : 0.685869\n",
      "step 7000 , training  accuracy 1\n",
      "step 7000 , loss : 0.485392\n",
      "step 7000 , validation  accuracy 0.736842\n",
      "step 7000 , validation loss : 0.670715\n",
      "step 7000 , test  accuracy 0.74359\n",
      "step 7000 , test loss : 0.681888\n",
      "step 7100 , training  accuracy 1\n",
      "step 7100 , loss : 0.491813\n",
      "step 7100 , validation  accuracy 0.789474\n",
      "step 7100 , validation loss : 0.655765\n",
      "step 7100 , test  accuracy 0.769231\n",
      "step 7100 , test loss : 0.682105\n",
      "step 7200 , training  accuracy 1\n",
      "step 7200 , loss : 0.49593\n",
      "step 7200 , validation  accuracy 0.763158\n",
      "step 7200 , validation loss : 0.65811\n",
      "step 7200 , test  accuracy 0.769231\n",
      "step 7200 , test loss : 0.683593\n",
      "step 7300 , training  accuracy 1\n",
      "step 7300 , loss : 0.476537\n",
      "step 7300 , validation  accuracy 0.736842\n",
      "step 7300 , validation loss : 0.653704\n",
      "step 7300 , test  accuracy 0.794872\n",
      "step 7300 , test loss : 0.665758\n",
      "step 7400 , training  accuracy 1\n",
      "step 7400 , loss : 0.479738\n",
      "step 7400 , validation  accuracy 0.684211\n",
      "step 7400 , validation loss : 0.681856\n",
      "step 7400 , test  accuracy 0.666667\n",
      "step 7400 , test loss : 0.670356\n",
      "step 7500 , training  accuracy 1\n",
      "step 7500 , loss : 0.4885\n",
      "step 7500 , validation  accuracy 0.684211\n",
      "step 7500 , validation loss : 0.695683\n",
      "step 7500 , test  accuracy 0.692308\n",
      "step 7500 , test loss : 0.683879\n",
      "step 7600 , training  accuracy 1\n",
      "step 7600 , loss : 0.485943\n",
      "step 7600 , validation  accuracy 0.763158\n",
      "step 7600 , validation loss : 0.668951\n",
      "step 7600 , test  accuracy 0.692308\n",
      "step 7600 , test loss : 0.668629\n",
      "step 7700 , training  accuracy 0.966667\n",
      "step 7700 , loss : 0.507425\n",
      "step 7700 , validation  accuracy 0.736842\n",
      "step 7700 , validation loss : 0.654807\n",
      "step 7700 , test  accuracy 0.74359\n",
      "step 7700 , test loss : 0.668342\n",
      "step 7800 , training  accuracy 1\n",
      "step 7800 , loss : 0.480695\n",
      "step 7800 , validation  accuracy 0.789474\n",
      "step 7800 , validation loss : 0.651633\n",
      "step 7800 , test  accuracy 0.74359\n",
      "step 7800 , test loss : 0.665209\n",
      "step 7900 , training  accuracy 0.966667\n",
      "step 7900 , loss : 0.501897\n",
      "step 7900 , validation  accuracy 0.736842\n",
      "step 7900 , validation loss : 0.651363\n",
      "step 7900 , test  accuracy 0.74359\n",
      "step 7900 , test loss : 0.662273\n",
      "step 8000 , training  accuracy 1\n",
      "step 8000 , loss : 0.474088\n",
      "step 8000 , validation  accuracy 0.763158\n",
      "step 8000 , validation loss : 0.64575\n",
      "step 8000 , test  accuracy 0.717949\n",
      "step 8000 , test loss : 0.66191\n",
      "step 8100 , training  accuracy 1\n",
      "step 8100 , loss : 0.481584\n",
      "step 8100 , validation  accuracy 0.736842\n",
      "step 8100 , validation loss : 0.644186\n",
      "step 8100 , test  accuracy 0.74359\n",
      "step 8100 , test loss : 0.662552\n",
      "step 8200 , training  accuracy 1\n",
      "step 8200 , loss : 0.484772\n",
      "step 8200 , validation  accuracy 0.763158\n",
      "step 8200 , validation loss : 0.655695\n",
      "step 8200 , test  accuracy 0.692308\n",
      "step 8200 , test loss : 0.666572\n",
      "step 8300 , training  accuracy 1\n",
      "step 8300 , loss : 0.478617\n",
      "step 8300 , validation  accuracy 0.789474\n",
      "step 8300 , validation loss : 0.658489\n",
      "step 8300 , test  accuracy 0.641026\n",
      "step 8300 , test loss : 0.670382\n",
      "step 8400 , training  accuracy 1\n",
      "step 8400 , loss : 0.485475\n",
      "step 8400 , validation  accuracy 0.763158\n",
      "step 8400 , validation loss : 0.655977\n",
      "step 8400 , test  accuracy 0.666667\n",
      "step 8400 , test loss : 0.665922\n",
      "step 8500 , training  accuracy 1\n",
      "step 8500 , loss : 0.495921\n",
      "step 8500 , validation  accuracy 0.763158\n",
      "step 8500 , validation loss : 0.651689\n",
      "step 8500 , test  accuracy 0.692308\n",
      "step 8500 , test loss : 0.662148\n",
      "step 8600 , training  accuracy 1\n",
      "step 8600 , loss : 0.471721\n",
      "step 8600 , validation  accuracy 0.763158\n",
      "step 8600 , validation loss : 0.643648\n",
      "step 8600 , test  accuracy 0.717949\n",
      "step 8600 , test loss : 0.660264\n",
      "step 8700 , training  accuracy 1\n",
      "step 8700 , loss : 0.469823\n",
      "step 8700 , validation  accuracy 0.763158\n",
      "step 8700 , validation loss : 0.641309\n",
      "step 8700 , test  accuracy 0.717949\n",
      "step 8700 , test loss : 0.662022\n",
      "step 8800 , training  accuracy 1\n",
      "step 8800 , loss : 0.483735\n",
      "step 8800 , validation  accuracy 0.736842\n",
      "step 8800 , validation loss : 0.642178\n",
      "step 8800 , test  accuracy 0.769231\n",
      "step 8800 , test loss : 0.670018\n",
      "step 8900 , training  accuracy 1\n",
      "step 8900 , loss : 0.479178\n",
      "step 8900 , validation  accuracy 0.763158\n",
      "step 8900 , validation loss : 0.648204\n",
      "step 8900 , test  accuracy 0.641026\n",
      "step 8900 , test loss : 0.68132\n",
      "step 9000 , training  accuracy 1\n",
      "step 9000 , loss : 0.480274\n",
      "step 9000 , validation  accuracy 0.763158\n",
      "step 9000 , validation loss : 0.666081\n",
      "step 9000 , test  accuracy 0.615385\n",
      "step 9000 , test loss : 0.695201\n",
      "step 9100 , training  accuracy 1\n",
      "step 9100 , loss : 0.479038\n",
      "step 9100 , validation  accuracy 0.736842\n",
      "step 9100 , validation loss : 0.671291\n",
      "step 9100 , test  accuracy 0.615385\n",
      "step 9100 , test loss : 0.697541\n",
      "step 9200 , training  accuracy 1\n",
      "step 9200 , loss : 0.47823\n",
      "step 9200 , validation  accuracy 0.736842\n",
      "step 9200 , validation loss : 0.667163\n",
      "step 9200 , test  accuracy 0.641026\n",
      "step 9200 , test loss : 0.690555\n",
      "step 9300 , training  accuracy 1\n",
      "step 9300 , loss : 0.476195\n",
      "step 9300 , validation  accuracy 0.736842\n",
      "step 9300 , validation loss : 0.663056\n",
      "step 9300 , test  accuracy 0.641026\n",
      "step 9300 , test loss : 0.679389\n",
      "step 9400 , training  accuracy 1\n",
      "step 9400 , loss : 0.471108\n",
      "step 9400 , validation  accuracy 0.736842\n",
      "step 9400 , validation loss : 0.65627\n",
      "step 9400 , test  accuracy 0.717949\n",
      "step 9400 , test loss : 0.672197\n",
      "step 9500 , training  accuracy 1\n",
      "step 9500 , loss : 0.484347\n",
      "step 9500 , validation  accuracy 0.789474\n",
      "step 9500 , validation loss : 0.651899\n",
      "step 9500 , test  accuracy 0.74359\n",
      "step 9500 , test loss : 0.672329\n",
      "step 9600 , training  accuracy 1\n",
      "step 9600 , loss : 0.477938\n",
      "step 9600 , validation  accuracy 0.815789\n",
      "step 9600 , validation loss : 0.651942\n",
      "step 9600 , test  accuracy 0.769231\n",
      "step 9600 , test loss : 0.678573\n",
      "step 9700 , training  accuracy 1\n",
      "step 9700 , loss : 0.490182\n",
      "step 9700 , validation  accuracy 0.815789\n",
      "step 9700 , validation loss : 0.654554\n",
      "step 9700 , test  accuracy 0.74359\n",
      "step 9700 , test loss : 0.685238\n",
      "step 9800 , training  accuracy 1\n",
      "step 9800 , loss : 0.493818\n",
      "step 9800 , validation  accuracy 0.789474\n",
      "step 9800 , validation loss : 0.663418\n",
      "step 9800 , test  accuracy 0.666667\n",
      "step 9800 , test loss : 0.702397\n",
      "step 9900 , training  accuracy 1\n",
      "step 9900 , loss : 0.477835\n",
      "step 9900 , validation  accuracy 0.815789\n",
      "step 9900 , validation loss : 0.662382\n",
      "step 9900 , test  accuracy 0.769231\n",
      "step 9900 , test loss : 0.683138\n",
      "step 10000 , training  accuracy 1\n",
      "step 10000 , loss : 0.486181\n",
      "step 10000 , validation  accuracy 0.736842\n",
      "step 10000 , validation loss : 0.678883\n",
      "step 10000 , test  accuracy 0.717949\n",
      "step 10000 , test loss : 0.672357\n",
      "step 10100 , training  accuracy 1\n",
      "step 10100 , loss : 0.494479\n",
      "step 10100 , validation  accuracy 0.710526\n",
      "step 10100 , validation loss : 0.711448\n",
      "step 10100 , test  accuracy 0.666667\n",
      "step 10100 , test loss : 0.688532\n",
      "step 10200 , training  accuracy 0.966667\n",
      "step 10200 , loss : 0.50084\n",
      "step 10200 , validation  accuracy 0.710526\n",
      "step 10200 , validation loss : 0.702812\n",
      "step 10200 , test  accuracy 0.641026\n",
      "step 10200 , test loss : 0.686838\n",
      "step 10300 , training  accuracy 1\n",
      "step 10300 , loss : 0.486513\n",
      "step 10300 , validation  accuracy 0.736842\n",
      "step 10300 , validation loss : 0.657912\n",
      "step 10300 , test  accuracy 0.74359\n",
      "step 10300 , test loss : 0.662856\n",
      "step 10400 , training  accuracy 0.966667\n",
      "step 10400 , loss : 0.514922\n",
      "step 10400 , validation  accuracy 0.763158\n",
      "step 10400 , validation loss : 0.68486\n",
      "step 10400 , test  accuracy 0.769231\n",
      "step 10400 , test loss : 0.704867\n",
      "step 10500 , training  accuracy 0.966667\n",
      "step 10500 , loss : 0.519511\n",
      "step 10500 , validation  accuracy 0.763158\n",
      "step 10500 , validation loss : 0.673046\n",
      "step 10500 , test  accuracy 0.74359\n",
      "step 10500 , test loss : 0.702674\n",
      "step 10600 , training  accuracy 1\n",
      "step 10600 , loss : 0.477947\n",
      "step 10600 , validation  accuracy 0.736842\n",
      "step 10600 , validation loss : 0.649319\n",
      "step 10600 , test  accuracy 0.641026\n",
      "step 10600 , test loss : 0.682505\n",
      "step 10700 , training  accuracy 0.9\n",
      "step 10700 , loss : 0.552881\n",
      "step 10700 , validation  accuracy 0.736842\n",
      "step 10700 , validation loss : 0.690015\n",
      "step 10700 , test  accuracy 0.641026\n",
      "step 10700 , test loss : 0.705766\n",
      "step 10800 , training  accuracy 1\n",
      "step 10800 , loss : 0.478806\n",
      "step 10800 , validation  accuracy 0.763158\n",
      "step 10800 , validation loss : 0.670778\n",
      "step 10800 , test  accuracy 0.641026\n",
      "step 10800 , test loss : 0.694585\n",
      "step 10900 , training  accuracy 1\n",
      "step 10900 , loss : 0.486933\n",
      "step 10900 , validation  accuracy 0.789474\n",
      "step 10900 , validation loss : 0.653745\n",
      "step 10900 , test  accuracy 0.74359\n",
      "step 10900 , test loss : 0.685549\n",
      "step 11000 , training  accuracy 1\n",
      "step 11000 , loss : 0.48185\n",
      "step 11000 , validation  accuracy 0.842105\n",
      "step 11000 , validation loss : 0.644483\n",
      "step 11000 , test  accuracy 0.717949\n",
      "step 11000 , test loss : 0.686323\n",
      "step 11100 , training  accuracy 0.933333\n",
      "step 11100 , loss : 0.520022\n",
      "step 11100 , validation  accuracy 0.789474\n",
      "step 11100 , validation loss : 0.656047\n",
      "step 11100 , test  accuracy 0.641026\n",
      "step 11100 , test loss : 0.703611\n",
      "step 11200 , training  accuracy 0.966667\n",
      "step 11200 , loss : 0.492742\n",
      "step 11200 , validation  accuracy 0.763158\n",
      "step 11200 , validation loss : 0.644351\n",
      "step 11200 , test  accuracy 0.641026\n",
      "step 11200 , test loss : 0.69815\n",
      "step 11300 , training  accuracy 1\n",
      "step 11300 , loss : 0.479232\n",
      "step 11300 , validation  accuracy 0.763158\n",
      "step 11300 , validation loss : 0.635652\n",
      "step 11300 , test  accuracy 0.692308\n",
      "step 11300 , test loss : 0.690776\n",
      "step 11400 , training  accuracy 1\n",
      "step 11400 , loss : 0.473106\n",
      "step 11400 , validation  accuracy 0.815789\n",
      "step 11400 , validation loss : 0.62934\n",
      "step 11400 , test  accuracy 0.692308\n",
      "step 11400 , test loss : 0.685887\n",
      "step 11500 , training  accuracy 1\n",
      "step 11500 , loss : 0.469543\n",
      "step 11500 , validation  accuracy 0.842105\n",
      "step 11500 , validation loss : 0.628112\n",
      "step 11500 , test  accuracy 0.769231\n",
      "step 11500 , test loss : 0.684279\n",
      "step 11600 , training  accuracy 1\n",
      "step 11600 , loss : 0.478081\n",
      "step 11600 , validation  accuracy 0.815789\n",
      "step 11600 , validation loss : 0.628127\n",
      "step 11600 , test  accuracy 0.769231\n",
      "step 11600 , test loss : 0.681921\n",
      "step 11700 , training  accuracy 1\n",
      "step 11700 , loss : 0.487814\n",
      "step 11700 , validation  accuracy 0.842105\n",
      "step 11700 , validation loss : 0.6288\n",
      "step 11700 , test  accuracy 0.794872\n",
      "step 11700 , test loss : 0.675214\n",
      "step 11800 , training  accuracy 1\n",
      "step 11800 , loss : 0.473459\n",
      "step 11800 , validation  accuracy 0.815789\n",
      "step 11800 , validation loss : 0.628618\n",
      "step 11800 , test  accuracy 0.794872\n",
      "step 11800 , test loss : 0.669625\n",
      "step 11900 , training  accuracy 1\n",
      "step 11900 , loss : 0.484726\n",
      "step 11900 , validation  accuracy 0.815789\n",
      "step 11900 , validation loss : 0.626297\n",
      "step 11900 , test  accuracy 0.769231\n",
      "step 11900 , test loss : 0.663787\n",
      "step 12000 , training  accuracy 1\n",
      "step 12000 , loss : 0.485957\n",
      "step 12000 , validation  accuracy 0.815789\n",
      "step 12000 , validation loss : 0.622001\n",
      "step 12000 , test  accuracy 0.74359\n",
      "step 12000 , test loss : 0.660586\n",
      "step 12100 , training  accuracy 1\n",
      "step 12100 , loss : 0.479002\n",
      "step 12100 , validation  accuracy 0.815789\n",
      "step 12100 , validation loss : 0.614217\n",
      "step 12100 , test  accuracy 0.717949\n",
      "step 12100 , test loss : 0.660741\n",
      "step 12200 , training  accuracy 1\n",
      "step 12200 , loss : 0.487251\n",
      "step 12200 , validation  accuracy 0.815789\n",
      "step 12200 , validation loss : 0.611439\n",
      "step 12200 , test  accuracy 0.717949\n",
      "step 12200 , test loss : 0.669737\n",
      "step 12300 , training  accuracy 1\n",
      "step 12300 , loss : 0.475124\n",
      "step 12300 , validation  accuracy 0.815789\n",
      "step 12300 , validation loss : 0.610456\n",
      "step 12300 , test  accuracy 0.717949\n",
      "step 12300 , test loss : 0.669936\n",
      "step 12400 , training  accuracy 1\n",
      "step 12400 , loss : 0.478578\n",
      "step 12400 , validation  accuracy 0.815789\n",
      "step 12400 , validation loss : 0.610431\n",
      "step 12400 , test  accuracy 0.692308\n",
      "step 12400 , test loss : 0.667417\n",
      "step 12500 , training  accuracy 1\n",
      "step 12500 , loss : 0.474035\n",
      "step 12500 , validation  accuracy 0.815789\n",
      "step 12500 , validation loss : 0.613717\n",
      "step 12500 , test  accuracy 0.692308\n",
      "step 12500 , test loss : 0.663553\n",
      "step 12600 , training  accuracy 1\n",
      "step 12600 , loss : 0.481399\n",
      "step 12600 , validation  accuracy 0.815789\n",
      "step 12600 , validation loss : 0.624127\n",
      "step 12600 , test  accuracy 0.717949\n",
      "step 12600 , test loss : 0.667514\n",
      "step 12700 , training  accuracy 1\n",
      "step 12700 , loss : 0.472552\n",
      "step 12700 , validation  accuracy 0.815789\n",
      "step 12700 , validation loss : 0.632371\n",
      "step 12700 , test  accuracy 0.74359\n",
      "step 12700 , test loss : 0.673855\n",
      "step 12800 , training  accuracy 1\n",
      "step 12800 , loss : 0.478979\n",
      "step 12800 , validation  accuracy 0.789474\n",
      "step 12800 , validation loss : 0.634891\n",
      "step 12800 , test  accuracy 0.717949\n",
      "step 12800 , test loss : 0.675712\n",
      "step 12900 , training  accuracy 1\n",
      "step 12900 , loss : 0.485178\n",
      "step 12900 , validation  accuracy 0.815789\n",
      "step 12900 , validation loss : 0.636933\n",
      "step 12900 , test  accuracy 0.666667\n",
      "step 12900 , test loss : 0.678923\n",
      "step 13000 , training  accuracy 1\n",
      "step 13000 , loss : 0.494934\n",
      "step 13000 , validation  accuracy 0.789474\n",
      "step 13000 , validation loss : 0.646389\n",
      "step 13000 , test  accuracy 0.666667\n",
      "step 13000 , test loss : 0.689069\n",
      "step 13100 , training  accuracy 1\n",
      "step 13100 , loss : 0.484322\n",
      "step 13100 , validation  accuracy 0.815789\n",
      "step 13100 , validation loss : 0.6398\n",
      "step 13100 , test  accuracy 0.717949\n",
      "step 13100 , test loss : 0.673444\n",
      "step 13200 , training  accuracy 1\n",
      "step 13200 , loss : 0.477251\n",
      "step 13200 , validation  accuracy 0.815789\n",
      "step 13200 , validation loss : 0.642817\n",
      "step 13200 , test  accuracy 0.74359\n",
      "step 13200 , test loss : 0.671151\n",
      "step 13300 , training  accuracy 1\n",
      "step 13300 , loss : 0.504325\n",
      "step 13300 , validation  accuracy 0.763158\n",
      "step 13300 , validation loss : 0.654441\n",
      "step 13300 , test  accuracy 0.769231\n",
      "step 13300 , test loss : 0.685608\n",
      "step 13400 , training  accuracy 1\n",
      "step 13400 , loss : 0.497552\n",
      "step 13400 , validation  accuracy 0.842105\n",
      "step 13400 , validation loss : 0.636021\n",
      "step 13400 , test  accuracy 0.74359\n",
      "step 13400 , test loss : 0.672013\n",
      "step 13500 , training  accuracy 1\n",
      "step 13500 , loss : 0.489199\n",
      "step 13500 , validation  accuracy 0.789474\n",
      "step 13500 , validation loss : 0.642102\n",
      "step 13500 , test  accuracy 0.717949\n",
      "step 13500 , test loss : 0.678771\n",
      "step 13600 , training  accuracy 1\n",
      "step 13600 , loss : 0.479706\n",
      "step 13600 , validation  accuracy 0.763158\n",
      "step 13600 , validation loss : 0.649413\n",
      "step 13600 , test  accuracy 0.692308\n",
      "step 13600 , test loss : 0.681517\n",
      "step 13700 , training  accuracy 1\n",
      "step 13700 , loss : 0.486992\n",
      "step 13700 , validation  accuracy 0.763158\n",
      "step 13700 , validation loss : 0.654321\n",
      "step 13700 , test  accuracy 0.692308\n",
      "step 13700 , test loss : 0.674422\n",
      "step 13800 , training  accuracy 1\n",
      "step 13800 , loss : 0.480504\n",
      "step 13800 , validation  accuracy 0.763158\n",
      "step 13800 , validation loss : 0.646471\n",
      "step 13800 , test  accuracy 0.666667\n",
      "step 13800 , test loss : 0.662559\n",
      "step 13900 , training  accuracy 1\n",
      "step 13900 , loss : 0.478634\n",
      "step 13900 , validation  accuracy 0.763158\n",
      "step 13900 , validation loss : 0.63115\n",
      "step 13900 , test  accuracy 0.717949\n",
      "step 13900 , test loss : 0.653432\n",
      "step 14000 , training  accuracy 1\n",
      "step 14000 , loss : 0.474473\n",
      "step 14000 , validation  accuracy 0.789474\n",
      "step 14000 , validation loss : 0.626508\n",
      "step 14000 , test  accuracy 0.717949\n",
      "step 14000 , test loss : 0.654784\n",
      "step 14100 , training  accuracy 1\n",
      "step 14100 , loss : 0.478564\n",
      "step 14100 , validation  accuracy 0.789474\n",
      "step 14100 , validation loss : 0.62993\n",
      "step 14100 , test  accuracy 0.717949\n",
      "step 14100 , test loss : 0.657786\n",
      "step 14200 , training  accuracy 1\n",
      "step 14200 , loss : 0.474308\n",
      "step 14200 , validation  accuracy 0.789474\n",
      "step 14200 , validation loss : 0.631872\n",
      "step 14200 , test  accuracy 0.692308\n",
      "step 14200 , test loss : 0.659991\n",
      "step 14300 , training  accuracy 1\n",
      "step 14300 , loss : 0.472015\n",
      "step 14300 , validation  accuracy 0.763158\n",
      "step 14300 , validation loss : 0.638317\n",
      "step 14300 , test  accuracy 0.717949\n",
      "step 14300 , test loss : 0.665229\n",
      "step 14400 , training  accuracy 1\n",
      "step 14400 , loss : 0.477164\n",
      "step 14400 , validation  accuracy 0.736842\n",
      "step 14400 , validation loss : 0.656212\n",
      "step 14400 , test  accuracy 0.666667\n",
      "step 14400 , test loss : 0.683404\n",
      "step 14500 , training  accuracy 1\n",
      "step 14500 , loss : 0.479409\n",
      "step 14500 , validation  accuracy 0.736842\n",
      "step 14500 , validation loss : 0.651965\n",
      "step 14500 , test  accuracy 0.74359\n",
      "step 14500 , test loss : 0.680767\n",
      "step 14600 , training  accuracy 1\n",
      "step 14600 , loss : 0.469607\n",
      "step 14600 , validation  accuracy 0.763158\n",
      "step 14600 , validation loss : 0.640318\n",
      "step 14600 , test  accuracy 0.692308\n",
      "step 14600 , test loss : 0.668177\n",
      "step 14700 , training  accuracy 1\n",
      "step 14700 , loss : 0.468923\n",
      "step 14700 , validation  accuracy 0.763158\n",
      "step 14700 , validation loss : 0.636219\n",
      "step 14700 , test  accuracy 0.692308\n",
      "step 14700 , test loss : 0.661616\n",
      "step 14800 , training  accuracy 1\n",
      "step 14800 , loss : 0.470034\n",
      "step 14800 , validation  accuracy 0.736842\n",
      "step 14800 , validation loss : 0.639822\n",
      "step 14800 , test  accuracy 0.717949\n",
      "step 14800 , test loss : 0.658686\n",
      "step 14900 , training  accuracy 1\n",
      "step 14900 , loss : 0.470293\n",
      "step 14900 , validation  accuracy 0.763158\n",
      "step 14900 , validation loss : 0.644857\n",
      "step 14900 , test  accuracy 0.74359\n",
      "step 14900 , test loss : 0.663573\n",
      "step 15000 , training  accuracy 1\n",
      "step 15000 , loss : 0.469667\n",
      "step 15000 , validation  accuracy 0.763158\n",
      "step 15000 , validation loss : 0.642674\n",
      "step 15000 , test  accuracy 0.769231\n",
      "step 15000 , test loss : 0.662416\n",
      "step 15100 , training  accuracy 1\n",
      "step 15100 , loss : 0.472189\n",
      "step 15100 , validation  accuracy 0.736842\n",
      "step 15100 , validation loss : 0.641786\n",
      "step 15100 , test  accuracy 0.769231\n",
      "step 15100 , test loss : 0.657144\n",
      "step 15200 , training  accuracy 1\n",
      "step 15200 , loss : 0.470352\n",
      "step 15200 , validation  accuracy 0.763158\n",
      "step 15200 , validation loss : 0.642044\n",
      "step 15200 , test  accuracy 0.769231\n",
      "step 15200 , test loss : 0.653913\n",
      "step 15300 , training  accuracy 1\n",
      "step 15300 , loss : 0.467368\n",
      "step 15300 , validation  accuracy 0.763158\n",
      "step 15300 , validation loss : 0.642617\n",
      "step 15300 , test  accuracy 0.794872\n",
      "step 15300 , test loss : 0.655232\n",
      "step 15400 , training  accuracy 1\n",
      "step 15400 , loss : 0.469414\n",
      "step 15400 , validation  accuracy 0.736842\n",
      "step 15400 , validation loss : 0.642746\n",
      "step 15400 , test  accuracy 0.769231\n",
      "step 15400 , test loss : 0.656275\n",
      "step 15500 , training  accuracy 1\n",
      "step 15500 , loss : 0.471983\n",
      "step 15500 , validation  accuracy 0.763158\n",
      "step 15500 , validation loss : 0.644663\n",
      "step 15500 , test  accuracy 0.769231\n",
      "step 15500 , test loss : 0.659324\n",
      "step 15600 , training  accuracy 1\n",
      "step 15600 , loss : 0.473096\n",
      "step 15600 , validation  accuracy 0.763158\n",
      "step 15600 , validation loss : 0.643374\n",
      "step 15600 , test  accuracy 0.769231\n",
      "step 15600 , test loss : 0.660253\n",
      "step 15700 , training  accuracy 1\n",
      "step 15700 , loss : 0.471227\n",
      "step 15700 , validation  accuracy 0.763158\n",
      "step 15700 , validation loss : 0.637891\n",
      "step 15700 , test  accuracy 0.74359\n",
      "step 15700 , test loss : 0.660461\n",
      "step 15800 , training  accuracy 1\n",
      "step 15800 , loss : 0.470384\n",
      "step 15800 , validation  accuracy 0.763158\n",
      "step 15800 , validation loss : 0.632314\n",
      "step 15800 , test  accuracy 0.717949\n",
      "step 15800 , test loss : 0.663239\n",
      "step 15900 , training  accuracy 0.966667\n",
      "step 15900 , loss : 0.480241\n",
      "step 15900 , validation  accuracy 0.763158\n",
      "step 15900 , validation loss : 0.629029\n",
      "step 15900 , test  accuracy 0.717949\n",
      "step 15900 , test loss : 0.667091\n",
      "step 16000 , training  accuracy 1\n",
      "step 16000 , loss : 0.477676\n",
      "step 16000 , validation  accuracy 0.763158\n",
      "step 16000 , validation loss : 0.628778\n",
      "step 16000 , test  accuracy 0.717949\n",
      "step 16000 , test loss : 0.670455\n",
      "step 16100 , training  accuracy 1\n",
      "step 16100 , loss : 0.472254\n",
      "step 16100 , validation  accuracy 0.763158\n",
      "step 16100 , validation loss : 0.631559\n",
      "step 16100 , test  accuracy 0.717949\n",
      "step 16100 , test loss : 0.671508\n",
      "step 16200 , training  accuracy 1\n",
      "step 16200 , loss : 0.476116\n",
      "step 16200 , validation  accuracy 0.763158\n",
      "step 16200 , validation loss : 0.636512\n",
      "step 16200 , test  accuracy 0.74359\n",
      "step 16200 , test loss : 0.671537\n",
      "step 16300 , training  accuracy 1\n",
      "step 16300 , loss : 0.474387\n",
      "step 16300 , validation  accuracy 0.789474\n",
      "step 16300 , validation loss : 0.647858\n",
      "step 16300 , test  accuracy 0.769231\n",
      "step 16300 , test loss : 0.674146\n",
      "step 16400 , training  accuracy 1\n",
      "step 16400 , loss : 0.475515\n",
      "step 16400 , validation  accuracy 0.763158\n",
      "step 16400 , validation loss : 0.658639\n",
      "step 16400 , test  accuracy 0.769231\n",
      "step 16400 , test loss : 0.677188\n",
      "step 16500 , training  accuracy 1\n",
      "step 16500 , loss : 0.482949\n",
      "step 16500 , validation  accuracy 0.763158\n",
      "step 16500 , validation loss : 0.664837\n",
      "step 16500 , test  accuracy 0.769231\n",
      "step 16500 , test loss : 0.6815\n",
      "step 16600 , training  accuracy 1\n",
      "step 16600 , loss : 0.487185\n",
      "step 16600 , validation  accuracy 0.736842\n",
      "step 16600 , validation loss : 0.663027\n",
      "step 16600 , test  accuracy 0.794872\n",
      "step 16600 , test loss : 0.681144\n",
      "step 16700 , training  accuracy 1\n",
      "step 16700 , loss : 0.474924\n",
      "step 16700 , validation  accuracy 0.710526\n",
      "step 16700 , validation loss : 0.655183\n",
      "step 16700 , test  accuracy 0.769231\n",
      "step 16700 , test loss : 0.677643\n",
      "step 16800 , training  accuracy 1\n",
      "step 16800 , loss : 0.473788\n",
      "step 16800 , validation  accuracy 0.736842\n",
      "step 16800 , validation loss : 0.646537\n",
      "step 16800 , test  accuracy 0.769231\n",
      "step 16800 , test loss : 0.674505\n",
      "step 16900 , training  accuracy 1\n",
      "step 16900 , loss : 0.469856\n",
      "step 16900 , validation  accuracy 0.789474\n",
      "step 16900 , validation loss : 0.64061\n",
      "step 16900 , test  accuracy 0.74359\n",
      "step 16900 , test loss : 0.672101\n",
      "step 17000 , training  accuracy 1\n",
      "step 17000 , loss : 0.473836\n",
      "step 17000 , validation  accuracy 0.763158\n",
      "step 17000 , validation loss : 0.635335\n",
      "step 17000 , test  accuracy 0.717949\n",
      "step 17000 , test loss : 0.671077\n",
      "step 17100 , training  accuracy 1\n",
      "step 17100 , loss : 0.47213\n",
      "step 17100 , validation  accuracy 0.789474\n",
      "step 17100 , validation loss : 0.631939\n",
      "step 17100 , test  accuracy 0.74359\n",
      "step 17100 , test loss : 0.665579\n",
      "step 17200 , training  accuracy 1\n",
      "step 17200 , loss : 0.472449\n",
      "step 17200 , validation  accuracy 0.789474\n",
      "step 17200 , validation loss : 0.634054\n",
      "step 17200 , test  accuracy 0.74359\n",
      "step 17200 , test loss : 0.656672\n",
      "step 17300 , training  accuracy 1\n",
      "step 17300 , loss : 0.468216\n",
      "step 17300 , validation  accuracy 0.763158\n",
      "step 17300 , validation loss : 0.639149\n",
      "step 17300 , test  accuracy 0.769231\n",
      "step 17300 , test loss : 0.652584\n",
      "step 17400 , training  accuracy 1\n",
      "step 17400 , loss : 0.476061\n",
      "step 17400 , validation  accuracy 0.736842\n",
      "step 17400 , validation loss : 0.644594\n",
      "step 17400 , test  accuracy 0.769231\n",
      "step 17400 , test loss : 0.650559\n",
      "step 17500 , training  accuracy 1\n",
      "step 17500 , loss : 0.475957\n",
      "step 17500 , validation  accuracy 0.736842\n",
      "step 17500 , validation loss : 0.643119\n",
      "step 17500 , test  accuracy 0.769231\n",
      "step 17500 , test loss : 0.648059\n",
      "step 17600 , training  accuracy 1\n",
      "step 17600 , loss : 0.475954\n",
      "step 17600 , validation  accuracy 0.736842\n",
      "step 17600 , validation loss : 0.635093\n",
      "step 17600 , test  accuracy 0.769231\n",
      "step 17600 , test loss : 0.643304\n",
      "step 17700 , training  accuracy 1\n",
      "step 17700 , loss : 0.470625\n",
      "step 17700 , validation  accuracy 0.736842\n",
      "step 17700 , validation loss : 0.628328\n",
      "step 17700 , test  accuracy 0.794872\n",
      "step 17700 , test loss : 0.640775\n",
      "step 17800 , training  accuracy 1\n",
      "step 17800 , loss : 0.477163\n",
      "step 17800 , validation  accuracy 0.736842\n",
      "step 17800 , validation loss : 0.62573\n",
      "step 17800 , test  accuracy 0.794872\n",
      "step 17800 , test loss : 0.64377\n",
      "step 17900 , training  accuracy 1\n",
      "step 17900 , loss : 0.477104\n",
      "step 17900 , validation  accuracy 0.763158\n",
      "step 17900 , validation loss : 0.624947\n",
      "step 17900 , test  accuracy 0.769231\n",
      "step 17900 , test loss : 0.646269\n",
      "step 18000 , training  accuracy 1\n",
      "step 18000 , loss : 0.478203\n",
      "step 18000 , validation  accuracy 0.789474\n",
      "step 18000 , validation loss : 0.621944\n",
      "step 18000 , test  accuracy 0.794872\n",
      "step 18000 , test loss : 0.649289\n",
      "step 18100 , training  accuracy 1\n",
      "step 18100 , loss : 0.470313\n",
      "step 18100 , validation  accuracy 0.763158\n",
      "step 18100 , validation loss : 0.619807\n",
      "step 18100 , test  accuracy 0.74359\n",
      "step 18100 , test loss : 0.650218\n",
      "step 18200 , training  accuracy 1\n",
      "step 18200 , loss : 0.4748\n",
      "step 18200 , validation  accuracy 0.763158\n",
      "step 18200 , validation loss : 0.622987\n",
      "step 18200 , test  accuracy 0.692308\n",
      "step 18200 , test loss : 0.656337\n",
      "step 18300 , training  accuracy 1\n",
      "step 18300 , loss : 0.472722\n",
      "step 18300 , validation  accuracy 0.789474\n",
      "step 18300 , validation loss : 0.625126\n",
      "step 18300 , test  accuracy 0.717949\n",
      "step 18300 , test loss : 0.659336\n",
      "step 18400 , training  accuracy 1\n",
      "step 18400 , loss : 0.470801\n",
      "step 18400 , validation  accuracy 0.789474\n",
      "step 18400 , validation loss : 0.622381\n",
      "step 18400 , test  accuracy 0.692308\n",
      "step 18400 , test loss : 0.654002\n",
      "step 18500 , training  accuracy 1\n",
      "step 18500 , loss : 0.466959\n",
      "step 18500 , validation  accuracy 0.789474\n",
      "step 18500 , validation loss : 0.619297\n",
      "step 18500 , test  accuracy 0.74359\n",
      "step 18500 , test loss : 0.648154\n",
      "step 18600 , training  accuracy 1\n",
      "step 18600 , loss : 0.470809\n",
      "step 18600 , validation  accuracy 0.842105\n",
      "step 18600 , validation loss : 0.617656\n",
      "step 18600 , test  accuracy 0.717949\n",
      "step 18600 , test loss : 0.646188\n",
      "step 18700 , training  accuracy 1\n",
      "step 18700 , loss : 0.46733\n",
      "step 18700 , validation  accuracy 0.842105\n",
      "step 18700 , validation loss : 0.617029\n",
      "step 18700 , test  accuracy 0.717949\n",
      "step 18700 , test loss : 0.64544\n",
      "step 18800 , training  accuracy 1\n",
      "step 18800 , loss : 0.474459\n",
      "step 18800 , validation  accuracy 0.789474\n",
      "step 18800 , validation loss : 0.6169\n",
      "step 18800 , test  accuracy 0.717949\n",
      "step 18800 , test loss : 0.641284\n",
      "step 18900 , training  accuracy 1\n",
      "step 18900 , loss : 0.469261\n",
      "step 18900 , validation  accuracy 0.789474\n",
      "step 18900 , validation loss : 0.619306\n",
      "step 18900 , test  accuracy 0.74359\n",
      "step 18900 , test loss : 0.640825\n",
      "step 19000 , training  accuracy 1\n",
      "step 19000 , loss : 0.469851\n",
      "step 19000 , validation  accuracy 0.763158\n",
      "step 19000 , validation loss : 0.625989\n",
      "step 19000 , test  accuracy 0.74359\n",
      "step 19000 , test loss : 0.643247\n",
      "step 19100 , training  accuracy 1\n",
      "step 19100 , loss : 0.476515\n",
      "step 19100 , validation  accuracy 0.763158\n",
      "step 19100 , validation loss : 0.634961\n",
      "step 19100 , test  accuracy 0.769231\n",
      "step 19100 , test loss : 0.648428\n",
      "step 19200 , training  accuracy 1\n",
      "step 19200 , loss : 0.473267\n",
      "step 19200 , validation  accuracy 0.763158\n",
      "step 19200 , validation loss : 0.635006\n",
      "step 19200 , test  accuracy 0.769231\n",
      "step 19200 , test loss : 0.649037\n",
      "step 19300 , training  accuracy 1\n",
      "step 19300 , loss : 0.470534\n",
      "step 19300 , validation  accuracy 0.763158\n",
      "step 19300 , validation loss : 0.628012\n",
      "step 19300 , test  accuracy 0.794872\n",
      "step 19300 , test loss : 0.646926\n",
      "step 19400 , training  accuracy 1\n",
      "step 19400 , loss : 0.47078\n",
      "step 19400 , validation  accuracy 0.763158\n",
      "step 19400 , validation loss : 0.623087\n",
      "step 19400 , test  accuracy 0.794872\n",
      "step 19400 , test loss : 0.649418\n",
      "step 19500 , training  accuracy 1\n",
      "step 19500 , loss : 0.469385\n",
      "step 19500 , validation  accuracy 0.736842\n",
      "step 19500 , validation loss : 0.620913\n",
      "step 19500 , test  accuracy 0.74359\n",
      "step 19500 , test loss : 0.652492\n",
      "step 19600 , training  accuracy 1\n",
      "step 19600 , loss : 0.46957\n",
      "step 19600 , validation  accuracy 0.736842\n",
      "step 19600 , validation loss : 0.62144\n",
      "step 19600 , test  accuracy 0.74359\n",
      "step 19600 , test loss : 0.652191\n",
      "step 19700 , training  accuracy 1\n",
      "step 19700 , loss : 0.468723\n",
      "step 19700 , validation  accuracy 0.736842\n",
      "step 19700 , validation loss : 0.618625\n",
      "step 19700 , test  accuracy 0.692308\n",
      "step 19700 , test loss : 0.647625\n",
      "step 19800 , training  accuracy 1\n",
      "step 19800 , loss : 0.46687\n",
      "step 19800 , validation  accuracy 0.763158\n",
      "step 19800 , validation loss : 0.614656\n",
      "step 19800 , test  accuracy 0.692308\n",
      "step 19800 , test loss : 0.643044\n",
      "step 19900 , training  accuracy 1\n",
      "step 19900 , loss : 0.469304\n",
      "step 19900 , validation  accuracy 0.763158\n",
      "step 19900 , validation loss : 0.611105\n",
      "step 19900 , test  accuracy 0.692308\n",
      "step 19900 , test loss : 0.640559\n",
      "step 20000 , training  accuracy 1\n",
      "step 20000 , loss : 0.468793\n",
      "step 20000 , validation  accuracy 0.763158\n",
      "step 20000 , validation loss : 0.610439\n",
      "step 20000 , test  accuracy 0.717949\n",
      "step 20000 , test loss : 0.641328\n",
      "step 20100 , training  accuracy 1\n",
      "step 20100 , loss : 0.468784\n",
      "step 20100 , validation  accuracy 0.763158\n",
      "step 20100 , validation loss : 0.609722\n",
      "step 20100 , test  accuracy 0.74359\n",
      "step 20100 , test loss : 0.640927\n",
      "step 20200 , training  accuracy 1\n",
      "step 20200 , loss : 0.484699\n",
      "step 20200 , validation  accuracy 0.789474\n",
      "step 20200 , validation loss : 0.60984\n",
      "step 20200 , test  accuracy 0.74359\n",
      "step 20200 , test loss : 0.640315\n",
      "step 20300 , training  accuracy 1\n",
      "step 20300 , loss : 0.469419\n",
      "step 20300 , validation  accuracy 0.789474\n",
      "step 20300 , validation loss : 0.613659\n",
      "step 20300 , test  accuracy 0.74359\n",
      "step 20300 , test loss : 0.644149\n",
      "step 20400 , training  accuracy 1\n",
      "step 20400 , loss : 0.472237\n",
      "step 20400 , validation  accuracy 0.789474\n",
      "step 20400 , validation loss : 0.618877\n",
      "step 20400 , test  accuracy 0.769231\n",
      "step 20400 , test loss : 0.646896\n",
      "step 20500 , training  accuracy 1\n",
      "step 20500 , loss : 0.472081\n",
      "step 20500 , validation  accuracy 0.789474\n",
      "step 20500 , validation loss : 0.623873\n",
      "step 20500 , test  accuracy 0.769231\n",
      "step 20500 , test loss : 0.647554\n",
      "step 20600 , training  accuracy 1\n",
      "step 20600 , loss : 0.470759\n",
      "step 20600 , validation  accuracy 0.789474\n",
      "step 20600 , validation loss : 0.629513\n",
      "step 20600 , test  accuracy 0.769231\n",
      "step 20600 , test loss : 0.64663\n",
      "step 20700 , training  accuracy 1\n",
      "step 20700 , loss : 0.472073\n",
      "step 20700 , validation  accuracy 0.789474\n",
      "step 20700 , validation loss : 0.630612\n",
      "step 20700 , test  accuracy 0.794872\n",
      "step 20700 , test loss : 0.646135\n",
      "step 20800 , training  accuracy 1\n",
      "step 20800 , loss : 0.469446\n",
      "step 20800 , validation  accuracy 0.815789\n",
      "step 20800 , validation loss : 0.638338\n",
      "step 20800 , test  accuracy 0.769231\n",
      "step 20800 , test loss : 0.648022\n",
      "step 20900 , training  accuracy 1\n",
      "step 20900 , loss : 0.472373\n",
      "step 20900 , validation  accuracy 0.789474\n",
      "step 20900 , validation loss : 0.645141\n",
      "step 20900 , test  accuracy 0.769231\n",
      "step 20900 , test loss : 0.649993\n",
      "step 21000 , training  accuracy 1\n",
      "step 21000 , loss : 0.472162\n",
      "step 21000 , validation  accuracy 0.789474\n",
      "step 21000 , validation loss : 0.647881\n",
      "step 21000 , test  accuracy 0.769231\n",
      "step 21000 , test loss : 0.649058\n",
      "step 21100 , training  accuracy 1\n",
      "step 21100 , loss : 0.469258\n",
      "step 21100 , validation  accuracy 0.789474\n",
      "step 21100 , validation loss : 0.648445\n",
      "step 21100 , test  accuracy 0.74359\n",
      "step 21100 , test loss : 0.648288\n",
      "step 21200 , training  accuracy 1\n",
      "step 21200 , loss : 0.469016\n",
      "step 21200 , validation  accuracy 0.789474\n",
      "step 21200 , validation loss : 0.649384\n",
      "step 21200 , test  accuracy 0.769231\n",
      "step 21200 , test loss : 0.651638\n",
      "step 21300 , training  accuracy 1\n",
      "step 21300 , loss : 0.473177\n",
      "step 21300 , validation  accuracy 0.763158\n",
      "step 21300 , validation loss : 0.650623\n",
      "step 21300 , test  accuracy 0.74359\n",
      "step 21300 , test loss : 0.65602\n",
      "step 21400 , training  accuracy 1\n",
      "step 21400 , loss : 0.470294\n",
      "step 21400 , validation  accuracy 0.763158\n",
      "step 21400 , validation loss : 0.650002\n",
      "step 21400 , test  accuracy 0.74359\n",
      "step 21400 , test loss : 0.656988\n",
      "step 21500 , training  accuracy 1\n",
      "step 21500 , loss : 0.477212\n",
      "step 21500 , validation  accuracy 0.763158\n",
      "step 21500 , validation loss : 0.646023\n",
      "step 21500 , test  accuracy 0.717949\n",
      "step 21500 , test loss : 0.654826\n",
      "step 21600 , training  accuracy 1\n",
      "step 21600 , loss : 0.46653\n",
      "step 21600 , validation  accuracy 0.815789\n",
      "step 21600 , validation loss : 0.638509\n",
      "step 21600 , test  accuracy 0.74359\n",
      "step 21600 , test loss : 0.643058\n",
      "step 21700 , training  accuracy 1\n",
      "step 21700 , loss : 0.468417\n",
      "step 21700 , validation  accuracy 0.789474\n",
      "step 21700 , validation loss : 0.640513\n",
      "step 21700 , test  accuracy 0.74359\n",
      "step 21700 , test loss : 0.642692\n",
      "step 21800 , training  accuracy 1\n",
      "step 21800 , loss : 0.472876\n",
      "step 21800 , validation  accuracy 0.763158\n",
      "step 21800 , validation loss : 0.645411\n",
      "step 21800 , test  accuracy 0.717949\n",
      "step 21800 , test loss : 0.648074\n",
      "step 21900 , training  accuracy 1\n",
      "step 21900 , loss : 0.471487\n",
      "step 21900 , validation  accuracy 0.789474\n",
      "step 21900 , validation loss : 0.640103\n",
      "step 21900 , test  accuracy 0.74359\n",
      "step 21900 , test loss : 0.64821\n",
      "step 22000 , training  accuracy 1\n",
      "step 22000 , loss : 0.472017\n",
      "step 22000 , validation  accuracy 0.789474\n",
      "step 22000 , validation loss : 0.640151\n",
      "step 22000 , test  accuracy 0.717949\n",
      "step 22000 , test loss : 0.65353\n",
      "step 22100 , training  accuracy 1\n",
      "step 22100 , loss : 0.472295\n",
      "step 22100 , validation  accuracy 0.789474\n",
      "step 22100 , validation loss : 0.641873\n",
      "step 22100 , test  accuracy 0.717949\n",
      "step 22100 , test loss : 0.651705\n",
      "step 22200 , training  accuracy 1\n",
      "step 22200 , loss : 0.470989\n",
      "step 22200 , validation  accuracy 0.789474\n",
      "step 22200 , validation loss : 0.642562\n",
      "step 22200 , test  accuracy 0.74359\n",
      "step 22200 , test loss : 0.65049\n",
      "step 22300 , training  accuracy 1\n",
      "step 22300 , loss : 0.471532\n",
      "step 22300 , validation  accuracy 0.789474\n",
      "step 22300 , validation loss : 0.641128\n",
      "step 22300 , test  accuracy 0.769231\n",
      "step 22300 , test loss : 0.648262\n",
      "step 22400 , training  accuracy 1\n",
      "step 22400 , loss : 0.469891\n",
      "step 22400 , validation  accuracy 0.789474\n",
      "step 22400 , validation loss : 0.641385\n",
      "step 22400 , test  accuracy 0.74359\n",
      "step 22400 , test loss : 0.646101\n",
      "step 22500 , training  accuracy 1\n",
      "step 22500 , loss : 0.472091\n",
      "step 22500 , validation  accuracy 0.789474\n",
      "step 22500 , validation loss : 0.641518\n",
      "step 22500 , test  accuracy 0.74359\n",
      "step 22500 , test loss : 0.644587\n",
      "step 22600 , training  accuracy 1\n",
      "step 22600 , loss : 0.46968\n",
      "step 22600 , validation  accuracy 0.789474\n",
      "step 22600 , validation loss : 0.642211\n",
      "step 22600 , test  accuracy 0.74359\n",
      "step 22600 , test loss : 0.643486\n",
      "step 22700 , training  accuracy 1\n",
      "step 22700 , loss : 0.467848\n",
      "step 22700 , validation  accuracy 0.789474\n",
      "step 22700 , validation loss : 0.645358\n",
      "step 22700 , test  accuracy 0.769231\n",
      "step 22700 , test loss : 0.642945\n",
      "step 22800 , training  accuracy 1\n",
      "step 22800 , loss : 0.468842\n",
      "step 22800 , validation  accuracy 0.789474\n",
      "step 22800 , validation loss : 0.64929\n",
      "step 22800 , test  accuracy 0.769231\n",
      "step 22800 , test loss : 0.644975\n",
      "step 22900 , training  accuracy 1\n",
      "step 22900 , loss : 0.468773\n",
      "step 22900 , validation  accuracy 0.763158\n",
      "step 22900 , validation loss : 0.650131\n",
      "step 22900 , test  accuracy 0.769231\n",
      "step 22900 , test loss : 0.646611\n",
      "step 23000 , training  accuracy 1\n",
      "step 23000 , loss : 0.468456\n",
      "step 23000 , validation  accuracy 0.789474\n",
      "step 23000 , validation loss : 0.649201\n",
      "step 23000 , test  accuracy 0.769231\n",
      "step 23000 , test loss : 0.646894\n",
      "step 23100 , training  accuracy 1\n",
      "step 23100 , loss : 0.46921\n",
      "step 23100 , validation  accuracy 0.789474\n",
      "step 23100 , validation loss : 0.647707\n",
      "step 23100 , test  accuracy 0.769231\n",
      "step 23100 , test loss : 0.645722\n",
      "step 23200 , training  accuracy 1\n",
      "step 23200 , loss : 0.468991\n",
      "step 23200 , validation  accuracy 0.789474\n",
      "step 23200 , validation loss : 0.646801\n",
      "step 23200 , test  accuracy 0.769231\n",
      "step 23200 , test loss : 0.645216\n",
      "step 23300 , training  accuracy 1\n",
      "step 23300 , loss : 0.469126\n",
      "step 23300 , validation  accuracy 0.789474\n",
      "step 23300 , validation loss : 0.643637\n",
      "step 23300 , test  accuracy 0.769231\n",
      "step 23300 , test loss : 0.643109\n",
      "step 23400 , training  accuracy 1\n",
      "step 23400 , loss : 0.468811\n",
      "step 23400 , validation  accuracy 0.789474\n",
      "step 23400 , validation loss : 0.64139\n",
      "step 23400 , test  accuracy 0.74359\n",
      "step 23400 , test loss : 0.642326\n",
      "step 23500 , training  accuracy 1\n",
      "step 23500 , loss : 0.467537\n",
      "step 23500 , validation  accuracy 0.789474\n",
      "step 23500 , validation loss : 0.640079\n",
      "step 23500 , test  accuracy 0.717949\n",
      "step 23500 , test loss : 0.643924\n",
      "step 23600 , training  accuracy 1\n",
      "step 23600 , loss : 0.470742\n",
      "step 23600 , validation  accuracy 0.815789\n",
      "step 23600 , validation loss : 0.638818\n",
      "step 23600 , test  accuracy 0.74359\n",
      "step 23600 , test loss : 0.644835\n",
      "step 23700 , training  accuracy 1\n",
      "step 23700 , loss : 0.468793\n",
      "step 23700 , validation  accuracy 0.789474\n",
      "step 23700 , validation loss : 0.641308\n",
      "step 23700 , test  accuracy 0.769231\n",
      "step 23700 , test loss : 0.647112\n",
      "step 23800 , training  accuracy 1\n",
      "step 23800 , loss : 0.469979\n",
      "step 23800 , validation  accuracy 0.763158\n",
      "step 23800 , validation loss : 0.642631\n",
      "step 23800 , test  accuracy 0.769231\n",
      "step 23800 , test loss : 0.649498\n",
      "step 23900 , training  accuracy 1\n",
      "step 23900 , loss : 0.470141\n",
      "step 23900 , validation  accuracy 0.763158\n",
      "step 23900 , validation loss : 0.641721\n",
      "step 23900 , test  accuracy 0.74359\n",
      "step 23900 , test loss : 0.650344\n",
      "step 24000 , training  accuracy 1\n",
      "step 24000 , loss : 0.468309\n",
      "step 24000 , validation  accuracy 0.763158\n",
      "step 24000 , validation loss : 0.641958\n",
      "step 24000 , test  accuracy 0.769231\n",
      "step 24000 , test loss : 0.651647\n",
      "step 24100 , training  accuracy 1\n",
      "step 24100 , loss : 0.470587\n",
      "step 24100 , validation  accuracy 0.763158\n",
      "step 24100 , validation loss : 0.640687\n",
      "step 24100 , test  accuracy 0.794872\n",
      "step 24100 , test loss : 0.652442\n",
      "step 24200 , training  accuracy 1\n",
      "step 24200 , loss : 0.468257\n",
      "step 24200 , validation  accuracy 0.789474\n",
      "step 24200 , validation loss : 0.637242\n",
      "step 24200 , test  accuracy 0.794872\n",
      "step 24200 , test loss : 0.651943\n",
      "step 24300 , training  accuracy 1\n",
      "step 24300 , loss : 0.46997\n",
      "step 24300 , validation  accuracy 0.789474\n",
      "step 24300 , validation loss : 0.63355\n",
      "step 24300 , test  accuracy 0.769231\n",
      "step 24300 , test loss : 0.650493\n",
      "step 24400 , training  accuracy 1\n",
      "step 24400 , loss : 0.467075\n",
      "step 24400 , validation  accuracy 0.789474\n",
      "step 24400 , validation loss : 0.632145\n",
      "step 24400 , test  accuracy 0.769231\n",
      "step 24400 , test loss : 0.649718\n",
      "step 24500 , training  accuracy 1\n",
      "step 24500 , loss : 0.470383\n",
      "step 24500 , validation  accuracy 0.789474\n",
      "step 24500 , validation loss : 0.630811\n",
      "step 24500 , test  accuracy 0.74359\n",
      "step 24500 , test loss : 0.649189\n",
      "step 24600 , training  accuracy 1\n",
      "step 24600 , loss : 0.470545\n",
      "step 24600 , validation  accuracy 0.789474\n",
      "step 24600 , validation loss : 0.63006\n",
      "step 24600 , test  accuracy 0.74359\n",
      "step 24600 , test loss : 0.648111\n",
      "step 24700 , training  accuracy 1\n",
      "step 24700 , loss : 0.469115\n",
      "step 24700 , validation  accuracy 0.789474\n",
      "step 24700 , validation loss : 0.629122\n",
      "step 24700 , test  accuracy 0.74359\n",
      "step 24700 , test loss : 0.645665\n",
      "step 24800 , training  accuracy 1\n",
      "step 24800 , loss : 0.468116\n",
      "step 24800 , validation  accuracy 0.789474\n",
      "step 24800 , validation loss : 0.629808\n",
      "step 24800 , test  accuracy 0.74359\n",
      "step 24800 , test loss : 0.643861\n",
      "step 24900 , training  accuracy 1\n",
      "step 24900 , loss : 0.468094\n",
      "step 24900 , validation  accuracy 0.789474\n",
      "step 24900 , validation loss : 0.631264\n",
      "step 24900 , test  accuracy 0.769231\n",
      "step 24900 , test loss : 0.643028\n",
      "step 25000 , training  accuracy 1\n",
      "step 25000 , loss : 0.467109\n",
      "step 25000 , validation  accuracy 0.789474\n",
      "step 25000 , validation loss : 0.630939\n",
      "step 25000 , test  accuracy 0.794872\n",
      "step 25000 , test loss : 0.642551\n",
      "step 25100 , training  accuracy 1\n",
      "step 25100 , loss : 0.466482\n",
      "step 25100 , validation  accuracy 0.789474\n",
      "step 25100 , validation loss : 0.631235\n",
      "step 25100 , test  accuracy 0.74359\n",
      "step 25100 , test loss : 0.642371\n",
      "step 25200 , training  accuracy 1\n",
      "step 25200 , loss : 0.466433\n",
      "step 25200 , validation  accuracy 0.789474\n",
      "step 25200 , validation loss : 0.632644\n",
      "step 25200 , test  accuracy 0.74359\n",
      "step 25200 , test loss : 0.642804\n",
      "step 25300 , training  accuracy 1\n",
      "step 25300 , loss : 0.466792\n",
      "step 25300 , validation  accuracy 0.763158\n",
      "step 25300 , validation loss : 0.634669\n",
      "step 25300 , test  accuracy 0.74359\n",
      "step 25300 , test loss : 0.646005\n",
      "step 25400 , training  accuracy 1\n",
      "step 25400 , loss : 0.468013\n",
      "step 25400 , validation  accuracy 0.763158\n",
      "step 25400 , validation loss : 0.634369\n",
      "step 25400 , test  accuracy 0.717949\n",
      "step 25400 , test loss : 0.646986\n",
      "step 25500 , training  accuracy 1\n",
      "step 25500 , loss : 0.467281\n",
      "step 25500 , validation  accuracy 0.763158\n",
      "step 25500 , validation loss : 0.629929\n",
      "step 25500 , test  accuracy 0.74359\n",
      "step 25500 , test loss : 0.644518\n",
      "step 25600 , training  accuracy 1\n",
      "step 25600 , loss : 0.468169\n",
      "step 25600 , validation  accuracy 0.815789\n",
      "step 25600 , validation loss : 0.624533\n",
      "step 25600 , test  accuracy 0.74359\n",
      "step 25600 , test loss : 0.644435\n",
      "step 25700 , training  accuracy 1\n",
      "step 25700 , loss : 0.466873\n",
      "step 25700 , validation  accuracy 0.815789\n",
      "step 25700 , validation loss : 0.622593\n",
      "step 25700 , test  accuracy 0.769231\n",
      "step 25700 , test loss : 0.644345\n",
      "step 25800 , training  accuracy 1\n",
      "step 25800 , loss : 0.46767\n",
      "step 25800 , validation  accuracy 0.763158\n",
      "step 25800 , validation loss : 0.622832\n",
      "step 25800 , test  accuracy 0.769231\n",
      "step 25800 , test loss : 0.642405\n",
      "step 25900 , training  accuracy 1\n",
      "step 25900 , loss : 0.467269\n",
      "step 25900 , validation  accuracy 0.763158\n",
      "step 25900 , validation loss : 0.624286\n",
      "step 25900 , test  accuracy 0.769231\n",
      "step 25900 , test loss : 0.640256\n",
      "step 26000 , training  accuracy 1\n",
      "step 26000 , loss : 0.466623\n",
      "step 26000 , validation  accuracy 0.763158\n",
      "step 26000 , validation loss : 0.626164\n",
      "step 26000 , test  accuracy 0.794872\n",
      "step 26000 , test loss : 0.639764\n",
      "step 26100 , training  accuracy 1\n",
      "step 26100 , loss : 0.470205\n",
      "step 26100 , validation  accuracy 0.763158\n",
      "step 26100 , validation loss : 0.628512\n",
      "step 26100 , test  accuracy 0.794872\n",
      "step 26100 , test loss : 0.639421\n",
      "step 26200 , training  accuracy 1\n",
      "step 26200 , loss : 0.465755\n",
      "step 26200 , validation  accuracy 0.763158\n",
      "step 26200 , validation loss : 0.629086\n",
      "step 26200 , test  accuracy 0.769231\n",
      "step 26200 , test loss : 0.638665\n",
      "step 26300 , training  accuracy 1\n",
      "step 26300 , loss : 0.467883\n",
      "step 26300 , validation  accuracy 0.763158\n",
      "step 26300 , validation loss : 0.62968\n",
      "step 26300 , test  accuracy 0.74359\n",
      "step 26300 , test loss : 0.637817\n",
      "step 26400 , training  accuracy 1\n",
      "step 26400 , loss : 0.466713\n",
      "step 26400 , validation  accuracy 0.763158\n",
      "step 26400 , validation loss : 0.631554\n",
      "step 26400 , test  accuracy 0.74359\n",
      "step 26400 , test loss : 0.638308\n",
      "step 26500 , training  accuracy 1\n",
      "step 26500 , loss : 0.466033\n",
      "step 26500 , validation  accuracy 0.763158\n",
      "step 26500 , validation loss : 0.632597\n",
      "step 26500 , test  accuracy 0.74359\n",
      "step 26500 , test loss : 0.638803\n",
      "step 26600 , training  accuracy 1\n",
      "step 26600 , loss : 0.468958\n",
      "step 26600 , validation  accuracy 0.763158\n",
      "step 26600 , validation loss : 0.63275\n",
      "step 26600 , test  accuracy 0.769231\n",
      "step 26600 , test loss : 0.640126\n",
      "step 26700 , training  accuracy 1\n",
      "step 26700 , loss : 0.466722\n",
      "step 26700 , validation  accuracy 0.763158\n",
      "step 26700 , validation loss : 0.628952\n",
      "step 26700 , test  accuracy 0.769231\n",
      "step 26700 , test loss : 0.639941\n",
      "step 26800 , training  accuracy 1\n",
      "step 26800 , loss : 0.465911\n",
      "step 26800 , validation  accuracy 0.763158\n",
      "step 26800 , validation loss : 0.629081\n",
      "step 26800 , test  accuracy 0.794872\n",
      "step 26800 , test loss : 0.641547\n",
      "step 26900 , training  accuracy 1\n",
      "step 26900 , loss : 0.468214\n",
      "step 26900 , validation  accuracy 0.763158\n",
      "step 26900 , validation loss : 0.627012\n",
      "step 26900 , test  accuracy 0.794872\n",
      "step 26900 , test loss : 0.642455\n",
      "step 27000 , training  accuracy 1\n",
      "step 27000 , loss : 0.467534\n",
      "step 27000 , validation  accuracy 0.789474\n",
      "step 27000 , validation loss : 0.627065\n",
      "step 27000 , test  accuracy 0.794872\n",
      "step 27000 , test loss : 0.642647\n",
      "step 27100 , training  accuracy 1\n",
      "step 27100 , loss : 0.465794\n",
      "step 27100 , validation  accuracy 0.789474\n",
      "step 27100 , validation loss : 0.626987\n",
      "step 27100 , test  accuracy 0.820513\n",
      "step 27100 , test loss : 0.640553\n",
      "step 27200 , training  accuracy 1\n",
      "step 27200 , loss : 0.466993\n",
      "step 27200 , validation  accuracy 0.789474\n",
      "step 27200 , validation loss : 0.624812\n",
      "step 27200 , test  accuracy 0.820513\n",
      "step 27200 , test loss : 0.638861\n",
      "step 27300 , training  accuracy 1\n",
      "step 27300 , loss : 0.467598\n",
      "step 27300 , validation  accuracy 0.789474\n",
      "step 27300 , validation loss : 0.622403\n",
      "step 27300 , test  accuracy 0.820513\n",
      "step 27300 , test loss : 0.636262\n",
      "step 27400 , training  accuracy 1\n",
      "step 27400 , loss : 0.469279\n",
      "step 27400 , validation  accuracy 0.789474\n",
      "step 27400 , validation loss : 0.6215\n",
      "step 27400 , test  accuracy 0.820513\n",
      "step 27400 , test loss : 0.634419\n",
      "step 27500 , training  accuracy 1\n",
      "step 27500 , loss : 0.470161\n",
      "step 27500 , validation  accuracy 0.789474\n",
      "step 27500 , validation loss : 0.622132\n",
      "step 27500 , test  accuracy 0.820513\n",
      "step 27500 , test loss : 0.633305\n",
      "step 27600 , training  accuracy 1\n",
      "step 27600 , loss : 0.466825\n",
      "step 27600 , validation  accuracy 0.789474\n",
      "step 27600 , validation loss : 0.622378\n",
      "step 27600 , test  accuracy 0.794872\n",
      "step 27600 , test loss : 0.632877\n",
      "step 27700 , training  accuracy 1\n",
      "step 27700 , loss : 0.466772\n",
      "step 27700 , validation  accuracy 0.789474\n",
      "step 27700 , validation loss : 0.622339\n",
      "step 27700 , test  accuracy 0.794872\n",
      "step 27700 , test loss : 0.632772\n",
      "step 27800 , training  accuracy 1\n",
      "step 27800 , loss : 0.468108\n",
      "step 27800 , validation  accuracy 0.789474\n",
      "step 27800 , validation loss : 0.623095\n",
      "step 27800 , test  accuracy 0.794872\n",
      "step 27800 , test loss : 0.633065\n",
      "step 27900 , training  accuracy 1\n",
      "step 27900 , loss : 0.466542\n",
      "step 27900 , validation  accuracy 0.789474\n",
      "step 27900 , validation loss : 0.624557\n",
      "step 27900 , test  accuracy 0.794872\n",
      "step 27900 , test loss : 0.634774\n",
      "step 28000 , training  accuracy 1\n",
      "step 28000 , loss : 0.466609\n",
      "step 28000 , validation  accuracy 0.789474\n",
      "step 28000 , validation loss : 0.626514\n",
      "step 28000 , test  accuracy 0.769231\n",
      "step 28000 , test loss : 0.638299\n",
      "step 28100 , training  accuracy 1\n",
      "step 28100 , loss : 0.468954\n",
      "step 28100 , validation  accuracy 0.789474\n",
      "step 28100 , validation loss : 0.626475\n",
      "step 28100 , test  accuracy 0.769231\n",
      "step 28100 , test loss : 0.641432\n",
      "step 28200 , training  accuracy 1\n",
      "step 28200 , loss : 0.46877\n",
      "step 28200 , validation  accuracy 0.789474\n",
      "step 28200 , validation loss : 0.621988\n",
      "step 28200 , test  accuracy 0.769231\n",
      "step 28200 , test loss : 0.64432\n",
      "step 28300 , training  accuracy 1\n",
      "step 28300 , loss : 0.467883\n",
      "step 28300 , validation  accuracy 0.789474\n",
      "step 28300 , validation loss : 0.621661\n",
      "step 28300 , test  accuracy 0.769231\n",
      "step 28300 , test loss : 0.64878\n",
      "step 28400 , training  accuracy 1\n",
      "step 28400 , loss : 0.468243\n",
      "step 28400 , validation  accuracy 0.789474\n",
      "step 28400 , validation loss : 0.623191\n",
      "step 28400 , test  accuracy 0.769231\n",
      "step 28400 , test loss : 0.653837\n",
      "step 28500 , training  accuracy 1\n",
      "step 28500 , loss : 0.469327\n",
      "step 28500 , validation  accuracy 0.815789\n",
      "step 28500 , validation loss : 0.626448\n",
      "step 28500 , test  accuracy 0.769231\n",
      "step 28500 , test loss : 0.659663\n",
      "step 28600 , training  accuracy 1\n",
      "step 28600 , loss : 0.468205\n",
      "step 28600 , validation  accuracy 0.789474\n",
      "step 28600 , validation loss : 0.627951\n",
      "step 28600 , test  accuracy 0.769231\n",
      "step 28600 , test loss : 0.662197\n",
      "step 28700 , training  accuracy 1\n",
      "step 28700 , loss : 0.467317\n",
      "step 28700 , validation  accuracy 0.789474\n",
      "step 28700 , validation loss : 0.628199\n",
      "step 28700 , test  accuracy 0.74359\n",
      "step 28700 , test loss : 0.664038\n",
      "step 28800 , training  accuracy 1\n",
      "step 28800 , loss : 0.466372\n",
      "step 28800 , validation  accuracy 0.789474\n",
      "step 28800 , validation loss : 0.62758\n",
      "step 28800 , test  accuracy 0.74359\n",
      "step 28800 , test loss : 0.664123\n",
      "step 28900 , training  accuracy 1\n",
      "step 28900 , loss : 0.468077\n",
      "step 28900 , validation  accuracy 0.763158\n",
      "step 28900 , validation loss : 0.627512\n",
      "step 28900 , test  accuracy 0.769231\n",
      "step 28900 , test loss : 0.660122\n",
      "step 29000 , training  accuracy 1\n",
      "step 29000 , loss : 0.469021\n",
      "step 29000 , validation  accuracy 0.815789\n",
      "step 29000 , validation loss : 0.630148\n",
      "step 29000 , test  accuracy 0.74359\n",
      "step 29000 , test loss : 0.657282\n",
      "step 29100 , training  accuracy 1\n",
      "step 29100 , loss : 0.468132\n",
      "step 29100 , validation  accuracy 0.815789\n",
      "step 29100 , validation loss : 0.632471\n",
      "step 29100 , test  accuracy 0.74359\n",
      "step 29100 , test loss : 0.654165\n",
      "step 29200 , training  accuracy 1\n",
      "step 29200 , loss : 0.468271\n",
      "step 29200 , validation  accuracy 0.815789\n",
      "step 29200 , validation loss : 0.635615\n",
      "step 29200 , test  accuracy 0.74359\n",
      "step 29200 , test loss : 0.651398\n",
      "step 29300 , training  accuracy 1\n",
      "step 29300 , loss : 0.467532\n",
      "step 29300 , validation  accuracy 0.815789\n",
      "step 29300 , validation loss : 0.635212\n",
      "step 29300 , test  accuracy 0.769231\n",
      "step 29300 , test loss : 0.646216\n",
      "step 29400 , training  accuracy 1\n",
      "step 29400 , loss : 0.469171\n",
      "step 29400 , validation  accuracy 0.789474\n",
      "step 29400 , validation loss : 0.634102\n",
      "step 29400 , test  accuracy 0.794872\n",
      "step 29400 , test loss : 0.642692\n",
      "step 29500 , training  accuracy 1\n",
      "step 29500 , loss : 0.466291\n",
      "step 29500 , validation  accuracy 0.789474\n",
      "step 29500 , validation loss : 0.632076\n",
      "step 29500 , test  accuracy 0.794872\n",
      "step 29500 , test loss : 0.641083\n",
      "step 29600 , training  accuracy 0.966667\n",
      "step 29600 , loss : 0.496811\n",
      "step 29600 , validation  accuracy 0.763158\n",
      "step 29600 , validation loss : 0.631529\n",
      "step 29600 , test  accuracy 0.769231\n",
      "step 29600 , test loss : 0.642929\n",
      "step 29700 , training  accuracy 1\n",
      "step 29700 , loss : 0.465305\n",
      "step 29700 , validation  accuracy 0.789474\n",
      "step 29700 , validation loss : 0.627388\n",
      "step 29700 , test  accuracy 0.769231\n",
      "step 29700 , test loss : 0.642058\n",
      "step 29800 , training  accuracy 1\n",
      "step 29800 , loss : 0.466415\n",
      "step 29800 , validation  accuracy 0.815789\n",
      "step 29800 , validation loss : 0.624711\n",
      "step 29800 , test  accuracy 0.769231\n",
      "step 29800 , test loss : 0.638902\n",
      "step 29900 , training  accuracy 1\n",
      "step 29900 , loss : 0.465513\n",
      "step 29900 , validation  accuracy 0.815789\n",
      "step 29900 , validation loss : 0.623488\n",
      "step 29900 , test  accuracy 0.769231\n",
      "step 29900 , test loss : 0.635409\n",
      "step 30000 , training  accuracy 1\n",
      "step 30000 , loss : 0.467067\n",
      "step 30000 , validation  accuracy 0.842105\n",
      "step 30000 , validation loss : 0.623639\n",
      "step 30000 , test  accuracy 0.769231\n",
      "step 30000 , test loss : 0.63214\n",
      "step 30100 , training  accuracy 1\n",
      "step 30100 , loss : 0.467762\n",
      "step 30100 , validation  accuracy 0.815789\n",
      "step 30100 , validation loss : 0.624232\n",
      "step 30100 , test  accuracy 0.769231\n",
      "step 30100 , test loss : 0.630419\n",
      "step 30200 , training  accuracy 1\n",
      "step 30200 , loss : 0.46733\n",
      "step 30200 , validation  accuracy 0.815789\n",
      "step 30200 , validation loss : 0.623402\n",
      "step 30200 , test  accuracy 0.794872\n",
      "step 30200 , test loss : 0.62771\n",
      "step 30300 , training  accuracy 1\n",
      "step 30300 , loss : 0.467487\n",
      "step 30300 , validation  accuracy 0.842105\n",
      "step 30300 , validation loss : 0.623005\n",
      "step 30300 , test  accuracy 0.794872\n",
      "step 30300 , test loss : 0.625394\n",
      "step 30400 , training  accuracy 1\n",
      "step 30400 , loss : 0.467004\n",
      "step 30400 , validation  accuracy 0.842105\n",
      "step 30400 , validation loss : 0.624857\n",
      "step 30400 , test  accuracy 0.794872\n",
      "step 30400 , test loss : 0.628593\n",
      "step 30500 , training  accuracy 1\n",
      "step 30500 , loss : 0.467997\n",
      "step 30500 , validation  accuracy 0.815789\n",
      "step 30500 , validation loss : 0.626993\n",
      "step 30500 , test  accuracy 0.794872\n",
      "step 30500 , test loss : 0.632164\n",
      "step 30600 , training  accuracy 1\n",
      "step 30600 , loss : 0.468496\n",
      "step 30600 , validation  accuracy 0.815789\n",
      "step 30600 , validation loss : 0.626592\n",
      "step 30600 , test  accuracy 0.794872\n",
      "step 30600 , test loss : 0.636383\n",
      "step 30700 , training  accuracy 1\n",
      "step 30700 , loss : 0.466744\n",
      "step 30700 , validation  accuracy 0.815789\n",
      "step 30700 , validation loss : 0.625402\n",
      "step 30700 , test  accuracy 0.794872\n",
      "step 30700 , test loss : 0.638242\n",
      "step 30800 , training  accuracy 1\n",
      "step 30800 , loss : 0.467111\n",
      "step 30800 , validation  accuracy 0.815789\n",
      "step 30800 , validation loss : 0.624682\n",
      "step 30800 , test  accuracy 0.794872\n",
      "step 30800 , test loss : 0.638093\n",
      "step 30900 , training  accuracy 1\n",
      "step 30900 , loss : 0.466326\n",
      "step 30900 , validation  accuracy 0.815789\n",
      "step 30900 , validation loss : 0.622934\n",
      "step 30900 , test  accuracy 0.769231\n",
      "step 30900 , test loss : 0.638124\n",
      "step 31000 , training  accuracy 1\n",
      "step 31000 , loss : 0.467315\n",
      "step 31000 , validation  accuracy 0.815789\n",
      "step 31000 , validation loss : 0.623284\n",
      "step 31000 , test  accuracy 0.769231\n",
      "step 31000 , test loss : 0.638773\n",
      "step 31100 , training  accuracy 1\n",
      "step 31100 , loss : 0.466795\n",
      "step 31100 , validation  accuracy 0.815789\n",
      "step 31100 , validation loss : 0.624585\n",
      "step 31100 , test  accuracy 0.769231\n",
      "step 31100 , test loss : 0.639536\n",
      "step 31200 , training  accuracy 1\n",
      "step 31200 , loss : 0.467004\n",
      "step 31200 , validation  accuracy 0.815789\n",
      "step 31200 , validation loss : 0.623259\n",
      "step 31200 , test  accuracy 0.769231\n",
      "step 31200 , test loss : 0.639\n",
      "step 31300 , training  accuracy 1\n",
      "step 31300 , loss : 0.465077\n",
      "step 31300 , validation  accuracy 0.842105\n",
      "step 31300 , validation loss : 0.62213\n",
      "step 31300 , test  accuracy 0.794872\n",
      "step 31300 , test loss : 0.638691\n",
      "step 31400 , training  accuracy 1\n",
      "step 31400 , loss : 0.46495\n",
      "step 31400 , validation  accuracy 0.842105\n",
      "step 31400 , validation loss : 0.621393\n",
      "step 31400 , test  accuracy 0.74359\n",
      "step 31400 , test loss : 0.639269\n",
      "step 31500 , training  accuracy 1\n",
      "step 31500 , loss : 0.466022\n",
      "step 31500 , validation  accuracy 0.842105\n",
      "step 31500 , validation loss : 0.620536\n",
      "step 31500 , test  accuracy 0.74359\n",
      "step 31500 , test loss : 0.640167\n",
      "step 31600 , training  accuracy 1\n",
      "step 31600 , loss : 0.465236\n",
      "step 31600 , validation  accuracy 0.842105\n",
      "step 31600 , validation loss : 0.620326\n",
      "step 31600 , test  accuracy 0.692308\n",
      "step 31600 , test loss : 0.642778\n",
      "step 31700 , training  accuracy 1\n",
      "step 31700 , loss : 0.466605\n",
      "step 31700 , validation  accuracy 0.842105\n",
      "step 31700 , validation loss : 0.620737\n",
      "step 31700 , test  accuracy 0.692308\n",
      "step 31700 , test loss : 0.645722\n",
      "step 31800 , training  accuracy 1\n",
      "step 31800 , loss : 0.465364\n",
      "step 31800 , validation  accuracy 0.842105\n",
      "step 31800 , validation loss : 0.621945\n",
      "step 31800 , test  accuracy 0.717949\n",
      "step 31800 , test loss : 0.648454\n",
      "step 31900 , training  accuracy 1\n",
      "step 31900 , loss : 0.46637\n",
      "step 31900 , validation  accuracy 0.842105\n",
      "step 31900 , validation loss : 0.624025\n",
      "step 31900 , test  accuracy 0.717949\n",
      "step 31900 , test loss : 0.652142\n",
      "step 32000 , training  accuracy 1\n",
      "step 32000 , loss : 0.466503\n",
      "step 32000 , validation  accuracy 0.842105\n",
      "step 32000 , validation loss : 0.625986\n",
      "step 32000 , test  accuracy 0.769231\n",
      "step 32000 , test loss : 0.654898\n",
      "step 32100 , training  accuracy 1\n",
      "step 32100 , loss : 0.467886\n",
      "step 32100 , validation  accuracy 0.815789\n",
      "step 32100 , validation loss : 0.628561\n",
      "step 32100 , test  accuracy 0.769231\n",
      "step 32100 , test loss : 0.657214\n",
      "step 32200 , training  accuracy 1\n",
      "step 32200 , loss : 0.46955\n",
      "step 32200 , validation  accuracy 0.789474\n",
      "step 32200 , validation loss : 0.62882\n",
      "step 32200 , test  accuracy 0.74359\n",
      "step 32200 , test loss : 0.658007\n",
      "step 32300 , training  accuracy 1\n",
      "step 32300 , loss : 0.471273\n",
      "step 32300 , validation  accuracy 0.789474\n",
      "step 32300 , validation loss : 0.623502\n",
      "step 32300 , test  accuracy 0.74359\n",
      "step 32300 , test loss : 0.656577\n",
      "step 32400 , training  accuracy 1\n",
      "step 32400 , loss : 0.46728\n",
      "step 32400 , validation  accuracy 0.815789\n",
      "step 32400 , validation loss : 0.617619\n",
      "step 32400 , test  accuracy 0.717949\n",
      "step 32400 , test loss : 0.653086\n",
      "step 32500 , training  accuracy 1\n",
      "step 32500 , loss : 0.467697\n",
      "step 32500 , validation  accuracy 0.815789\n",
      "step 32500 , validation loss : 0.613161\n",
      "step 32500 , test  accuracy 0.717949\n",
      "step 32500 , test loss : 0.651735\n",
      "step 32600 , training  accuracy 1\n",
      "step 32600 , loss : 0.465845\n",
      "step 32600 , validation  accuracy 0.815789\n",
      "step 32600 , validation loss : 0.610474\n",
      "step 32600 , test  accuracy 0.74359\n",
      "step 32600 , test loss : 0.651466\n",
      "step 32700 , training  accuracy 1\n",
      "step 32700 , loss : 0.468051\n",
      "step 32700 , validation  accuracy 0.789474\n",
      "step 32700 , validation loss : 0.609254\n",
      "step 32700 , test  accuracy 0.769231\n",
      "step 32700 , test loss : 0.649058\n",
      "step 32800 , training  accuracy 1\n",
      "step 32800 , loss : 0.466034\n",
      "step 32800 , validation  accuracy 0.789474\n",
      "step 32800 , validation loss : 0.610536\n",
      "step 32800 , test  accuracy 0.794872\n",
      "step 32800 , test loss : 0.642492\n",
      "step 32900 , training  accuracy 1\n",
      "step 32900 , loss : 0.467022\n",
      "step 32900 , validation  accuracy 0.763158\n",
      "step 32900 , validation loss : 0.618286\n",
      "step 32900 , test  accuracy 0.794872\n",
      "step 32900 , test loss : 0.639259\n",
      "step 33000 , training  accuracy 1\n",
      "step 33000 , loss : 0.46796\n",
      "step 33000 , validation  accuracy 0.736842\n",
      "step 33000 , validation loss : 0.625515\n",
      "step 33000 , test  accuracy 0.794872\n",
      "step 33000 , test loss : 0.637541\n",
      "step 33100 , training  accuracy 1\n",
      "step 33100 , loss : 0.467363\n",
      "step 33100 , validation  accuracy 0.736842\n",
      "step 33100 , validation loss : 0.626191\n",
      "step 33100 , test  accuracy 0.794872\n",
      "step 33100 , test loss : 0.634083\n",
      "step 33200 , training  accuracy 1\n",
      "step 33200 , loss : 0.46635\n",
      "step 33200 , validation  accuracy 0.763158\n",
      "step 33200 , validation loss : 0.619465\n",
      "step 33200 , test  accuracy 0.794872\n",
      "step 33200 , test loss : 0.63037\n",
      "step 33300 , training  accuracy 1\n",
      "step 33300 , loss : 0.465678\n",
      "step 33300 , validation  accuracy 0.736842\n",
      "step 33300 , validation loss : 0.612769\n",
      "step 33300 , test  accuracy 0.820513\n",
      "step 33300 , test loss : 0.627984\n",
      "step 33400 , training  accuracy 1\n",
      "step 33400 , loss : 0.4659\n",
      "step 33400 , validation  accuracy 0.763158\n",
      "step 33400 , validation loss : 0.609019\n",
      "step 33400 , test  accuracy 0.820513\n",
      "step 33400 , test loss : 0.627068\n",
      "step 33500 , training  accuracy 1\n",
      "step 33500 , loss : 0.467563\n",
      "step 33500 , validation  accuracy 0.763158\n",
      "step 33500 , validation loss : 0.606154\n",
      "step 33500 , test  accuracy 0.820513\n",
      "step 33500 , test loss : 0.627071\n",
      "step 33600 , training  accuracy 1\n",
      "step 33600 , loss : 0.468693\n",
      "step 33600 , validation  accuracy 0.815789\n",
      "step 33600 , validation loss : 0.606037\n",
      "step 33600 , test  accuracy 0.820513\n",
      "step 33600 , test loss : 0.627442\n",
      "step 33700 , training  accuracy 1\n",
      "step 33700 , loss : 0.466027\n",
      "step 33700 , validation  accuracy 0.763158\n",
      "step 33700 , validation loss : 0.61259\n",
      "step 33700 , test  accuracy 0.820513\n",
      "step 33700 , test loss : 0.626133\n",
      "step 33800 , training  accuracy 1\n",
      "step 33800 , loss : 0.466368\n",
      "step 33800 , validation  accuracy 0.763158\n",
      "step 33800 , validation loss : 0.622157\n",
      "step 33800 , test  accuracy 0.794872\n",
      "step 33800 , test loss : 0.629175\n",
      "step 33900 , training  accuracy 1\n",
      "step 33900 , loss : 0.467492\n",
      "step 33900 , validation  accuracy 0.789474\n",
      "step 33900 , validation loss : 0.628998\n",
      "step 33900 , test  accuracy 0.769231\n",
      "step 33900 , test loss : 0.631847\n",
      "step 34000 , training  accuracy 1\n",
      "step 34000 , loss : 0.46927\n",
      "step 34000 , validation  accuracy 0.789474\n",
      "step 34000 , validation loss : 0.632032\n",
      "step 34000 , test  accuracy 0.769231\n",
      "step 34000 , test loss : 0.634146\n",
      "step 34100 , training  accuracy 1\n",
      "step 34100 , loss : 0.468818\n",
      "step 34100 , validation  accuracy 0.789474\n",
      "step 34100 , validation loss : 0.630313\n",
      "step 34100 , test  accuracy 0.769231\n",
      "step 34100 , test loss : 0.63452\n",
      "step 34200 , training  accuracy 1\n",
      "step 34200 , loss : 0.468279\n",
      "step 34200 , validation  accuracy 0.763158\n",
      "step 34200 , validation loss : 0.625901\n",
      "step 34200 , test  accuracy 0.769231\n",
      "step 34200 , test loss : 0.637592\n",
      "step 34300 , training  accuracy 1\n",
      "step 34300 , loss : 0.466297\n",
      "step 34300 , validation  accuracy 0.815789\n",
      "step 34300 , validation loss : 0.623198\n",
      "step 34300 , test  accuracy 0.666667\n",
      "step 34300 , test loss : 0.647842\n",
      "step 34400 , training  accuracy 1\n",
      "step 34400 , loss : 0.464847\n",
      "step 34400 , validation  accuracy 0.789474\n",
      "step 34400 , validation loss : 0.625452\n",
      "step 34400 , test  accuracy 0.641026\n",
      "step 34400 , test loss : 0.656612\n",
      "step 34500 , training  accuracy 1\n",
      "step 34500 , loss : 0.465423\n",
      "step 34500 , validation  accuracy 0.763158\n",
      "step 34500 , validation loss : 0.627524\n",
      "step 34500 , test  accuracy 0.615385\n",
      "step 34500 , test loss : 0.66344\n",
      "step 34600 , training  accuracy 1\n",
      "step 34600 , loss : 0.467953\n",
      "step 34600 , validation  accuracy 0.763158\n",
      "step 34600 , validation loss : 0.627906\n",
      "step 34600 , test  accuracy 0.615385\n",
      "step 34600 , test loss : 0.666531\n",
      "step 34700 , training  accuracy 1\n",
      "step 34700 , loss : 0.467333\n",
      "step 34700 , validation  accuracy 0.789474\n",
      "step 34700 , validation loss : 0.624067\n",
      "step 34700 , test  accuracy 0.641026\n",
      "step 34700 , test loss : 0.662414\n",
      "step 34800 , training  accuracy 1\n",
      "step 34800 , loss : 0.465882\n",
      "step 34800 , validation  accuracy 0.763158\n",
      "step 34800 , validation loss : 0.623645\n",
      "step 34800 , test  accuracy 0.692308\n",
      "step 34800 , test loss : 0.658779\n",
      "step 34900 , training  accuracy 1\n",
      "step 34900 , loss : 0.46857\n",
      "step 34900 , validation  accuracy 0.789474\n",
      "step 34900 , validation loss : 0.627315\n",
      "step 34900 , test  accuracy 0.692308\n",
      "step 34900 , test loss : 0.65732\n",
      "step 35000 , training  accuracy 1\n",
      "step 35000 , loss : 0.467082\n",
      "step 35000 , validation  accuracy 0.789474\n",
      "step 35000 , validation loss : 0.631682\n",
      "step 35000 , test  accuracy 0.717949\n",
      "step 35000 , test loss : 0.656604\n",
      "step 35100 , training  accuracy 1\n",
      "step 35100 , loss : 0.46866\n",
      "step 35100 , validation  accuracy 0.763158\n",
      "step 35100 , validation loss : 0.634653\n",
      "step 35100 , test  accuracy 0.692308\n",
      "step 35100 , test loss : 0.658179\n",
      "step 35200 , training  accuracy 1\n",
      "step 35200 , loss : 0.466157\n",
      "step 35200 , validation  accuracy 0.789474\n",
      "step 35200 , validation loss : 0.63291\n",
      "step 35200 , test  accuracy 0.692308\n",
      "step 35200 , test loss : 0.65834\n",
      "step 35300 , training  accuracy 1\n",
      "step 35300 , loss : 0.467465\n",
      "step 35300 , validation  accuracy 0.789474\n",
      "step 35300 , validation loss : 0.629975\n",
      "step 35300 , test  accuracy 0.692308\n",
      "step 35300 , test loss : 0.658124\n",
      "step 35400 , training  accuracy 1\n",
      "step 35400 , loss : 0.466357\n",
      "step 35400 , validation  accuracy 0.789474\n",
      "step 35400 , validation loss : 0.629056\n",
      "step 35400 , test  accuracy 0.692308\n",
      "step 35400 , test loss : 0.657509\n",
      "step 35500 , training  accuracy 1\n",
      "step 35500 , loss : 0.464731\n",
      "step 35500 , validation  accuracy 0.789474\n",
      "step 35500 , validation loss : 0.628815\n",
      "step 35500 , test  accuracy 0.692308\n",
      "step 35500 , test loss : 0.657105\n",
      "step 35600 , training  accuracy 1\n",
      "step 35600 , loss : 0.467626\n",
      "step 35600 , validation  accuracy 0.789474\n",
      "step 35600 , validation loss : 0.628063\n",
      "step 35600 , test  accuracy 0.692308\n",
      "step 35600 , test loss : 0.657485\n",
      "step 35700 , training  accuracy 1\n",
      "step 35700 , loss : 0.46414\n",
      "step 35700 , validation  accuracy 0.789474\n",
      "step 35700 , validation loss : 0.624535\n",
      "step 35700 , test  accuracy 0.692308\n",
      "step 35700 , test loss : 0.662075\n",
      "step 35800 , training  accuracy 1\n",
      "step 35800 , loss : 0.465042\n",
      "step 35800 , validation  accuracy 0.763158\n",
      "step 35800 , validation loss : 0.621593\n",
      "step 35800 , test  accuracy 0.692308\n",
      "step 35800 , test loss : 0.664133\n",
      "step 35900 , training  accuracy 1\n",
      "step 35900 , loss : 0.465334\n",
      "step 35900 , validation  accuracy 0.789474\n",
      "step 35900 , validation loss : 0.619337\n",
      "step 35900 , test  accuracy 0.692308\n",
      "step 35900 , test loss : 0.665447\n",
      "step 36000 , training  accuracy 1\n",
      "step 36000 , loss : 0.463766\n",
      "step 36000 , validation  accuracy 0.815789\n",
      "step 36000 , validation loss : 0.618709\n",
      "step 36000 , test  accuracy 0.666667\n",
      "step 36000 , test loss : 0.666334\n",
      "step 36100 , training  accuracy 1\n",
      "step 36100 , loss : 0.466724\n",
      "step 36100 , validation  accuracy 0.815789\n",
      "step 36100 , validation loss : 0.617831\n",
      "step 36100 , test  accuracy 0.692308\n",
      "step 36100 , test loss : 0.667275\n",
      "step 36200 , training  accuracy 1\n",
      "step 36200 , loss : 0.466852\n",
      "step 36200 , validation  accuracy 0.815789\n",
      "step 36200 , validation loss : 0.617717\n",
      "step 36200 , test  accuracy 0.666667\n",
      "step 36200 , test loss : 0.669168\n",
      "step 36300 , training  accuracy 1\n",
      "step 36300 , loss : 0.465977\n",
      "step 36300 , validation  accuracy 0.815789\n",
      "step 36300 , validation loss : 0.618449\n",
      "step 36300 , test  accuracy 0.666667\n",
      "step 36300 , test loss : 0.667273\n",
      "step 36400 , training  accuracy 1\n",
      "step 36400 , loss : 0.464622\n",
      "step 36400 , validation  accuracy 0.815789\n",
      "step 36400 , validation loss : 0.620254\n",
      "step 36400 , test  accuracy 0.717949\n",
      "step 36400 , test loss : 0.663559\n",
      "step 36500 , training  accuracy 1\n",
      "step 36500 , loss : 0.466675\n",
      "step 36500 , validation  accuracy 0.815789\n",
      "step 36500 , validation loss : 0.623846\n",
      "step 36500 , test  accuracy 0.74359\n",
      "step 36500 , test loss : 0.660942\n",
      "step 36600 , training  accuracy 1\n",
      "step 36600 , loss : 0.46604\n",
      "step 36600 , validation  accuracy 0.789474\n",
      "step 36600 , validation loss : 0.626965\n",
      "step 36600 , test  accuracy 0.794872\n",
      "step 36600 , test loss : 0.658338\n",
      "step 36700 , training  accuracy 1\n",
      "step 36700 , loss : 0.466091\n",
      "step 36700 , validation  accuracy 0.789474\n",
      "step 36700 , validation loss : 0.628644\n",
      "step 36700 , test  accuracy 0.794872\n",
      "step 36700 , test loss : 0.654543\n",
      "step 36800 , training  accuracy 1\n",
      "step 36800 , loss : 0.466432\n",
      "step 36800 , validation  accuracy 0.789474\n",
      "step 36800 , validation loss : 0.627966\n",
      "step 36800 , test  accuracy 0.794872\n",
      "step 36800 , test loss : 0.652394\n",
      "step 36900 , training  accuracy 1\n",
      "step 36900 , loss : 0.465846\n",
      "step 36900 , validation  accuracy 0.815789\n",
      "step 36900 , validation loss : 0.624826\n",
      "step 36900 , test  accuracy 0.794872\n",
      "step 36900 , test loss : 0.653872\n",
      "step 37000 , training  accuracy 1\n",
      "step 37000 , loss : 0.465888\n",
      "step 37000 , validation  accuracy 0.842105\n",
      "step 37000 , validation loss : 0.624609\n",
      "step 37000 , test  accuracy 0.794872\n",
      "step 37000 , test loss : 0.660305\n",
      "step 37100 , training  accuracy 1\n",
      "step 37100 , loss : 0.46586\n",
      "step 37100 , validation  accuracy 0.815789\n",
      "step 37100 , validation loss : 0.624257\n",
      "step 37100 , test  accuracy 0.717949\n",
      "step 37100 , test loss : 0.664549\n",
      "step 37200 , training  accuracy 1\n",
      "step 37200 , loss : 0.467946\n",
      "step 37200 , validation  accuracy 0.842105\n",
      "step 37200 , validation loss : 0.624142\n",
      "step 37200 , test  accuracy 0.717949\n",
      "step 37200 , test loss : 0.666831\n",
      "step 37300 , training  accuracy 1\n",
      "step 37300 , loss : 0.466024\n",
      "step 37300 , validation  accuracy 0.815789\n",
      "step 37300 , validation loss : 0.623811\n",
      "step 37300 , test  accuracy 0.717949\n",
      "step 37300 , test loss : 0.667736\n",
      "step 37400 , training  accuracy 1\n",
      "step 37400 , loss : 0.466053\n",
      "step 37400 , validation  accuracy 0.815789\n",
      "step 37400 , validation loss : 0.622202\n",
      "step 37400 , test  accuracy 0.717949\n",
      "step 37400 , test loss : 0.665834\n",
      "step 37500 , training  accuracy 1\n",
      "step 37500 , loss : 0.465961\n",
      "step 37500 , validation  accuracy 0.815789\n",
      "step 37500 , validation loss : 0.619272\n",
      "step 37500 , test  accuracy 0.717949\n",
      "step 37500 , test loss : 0.663428\n",
      "step 37600 , training  accuracy 1\n",
      "step 37600 , loss : 0.465927\n",
      "step 37600 , validation  accuracy 0.842105\n",
      "step 37600 , validation loss : 0.616158\n",
      "step 37600 , test  accuracy 0.717949\n",
      "step 37600 , test loss : 0.65874\n",
      "step 37700 , training  accuracy 1\n",
      "step 37700 , loss : 0.467935\n",
      "step 37700 , validation  accuracy 0.842105\n",
      "step 37700 , validation loss : 0.613746\n",
      "step 37700 , test  accuracy 0.717949\n",
      "step 37700 , test loss : 0.651454\n",
      "step 37800 , training  accuracy 1\n",
      "step 37800 , loss : 0.466334\n",
      "step 37800 , validation  accuracy 0.842105\n",
      "step 37800 , validation loss : 0.611844\n",
      "step 37800 , test  accuracy 0.769231\n",
      "step 37800 , test loss : 0.641954\n",
      "step 37900 , training  accuracy 1\n",
      "step 37900 , loss : 0.466833\n",
      "step 37900 , validation  accuracy 0.815789\n",
      "step 37900 , validation loss : 0.608637\n",
      "step 37900 , test  accuracy 0.794872\n",
      "step 37900 , test loss : 0.636908\n",
      "step 38000 , training  accuracy 1\n",
      "step 38000 , loss : 0.465613\n",
      "step 38000 , validation  accuracy 0.815789\n",
      "step 38000 , validation loss : 0.609731\n",
      "step 38000 , test  accuracy 0.794872\n",
      "step 38000 , test loss : 0.636267\n",
      "step 38100 , training  accuracy 1\n",
      "step 38100 , loss : 0.467476\n",
      "step 38100 , validation  accuracy 0.815789\n",
      "step 38100 , validation loss : 0.612801\n",
      "step 38100 , test  accuracy 0.794872\n",
      "step 38100 , test loss : 0.635425\n",
      "step 38200 , training  accuracy 1\n",
      "step 38200 , loss : 0.468216\n",
      "step 38200 , validation  accuracy 0.763158\n",
      "step 38200 , validation loss : 0.616487\n",
      "step 38200 , test  accuracy 0.820513\n",
      "step 38200 , test loss : 0.634873\n",
      "step 38300 , training  accuracy 1\n",
      "step 38300 , loss : 0.466855\n",
      "step 38300 , validation  accuracy 0.763158\n",
      "step 38300 , validation loss : 0.613695\n",
      "step 38300 , test  accuracy 0.820513\n",
      "step 38300 , test loss : 0.634842\n",
      "step 38400 , training  accuracy 1\n",
      "step 38400 , loss : 0.46574\n",
      "step 38400 , validation  accuracy 0.842105\n",
      "step 38400 , validation loss : 0.607292\n",
      "step 38400 , test  accuracy 0.794872\n",
      "step 38400 , test loss : 0.635462\n",
      "step 38500 , training  accuracy 1\n",
      "step 38500 , loss : 0.466318\n",
      "step 38500 , validation  accuracy 0.842105\n",
      "step 38500 , validation loss : 0.603402\n",
      "step 38500 , test  accuracy 0.794872\n",
      "step 38500 , test loss : 0.636068\n",
      "step 38600 , training  accuracy 1\n",
      "step 38600 , loss : 0.466879\n",
      "step 38600 , validation  accuracy 0.842105\n",
      "step 38600 , validation loss : 0.602042\n",
      "step 38600 , test  accuracy 0.794872\n",
      "step 38600 , test loss : 0.635853\n",
      "step 38700 , training  accuracy 1\n",
      "step 38700 , loss : 0.463931\n",
      "step 38700 , validation  accuracy 0.842105\n",
      "step 38700 , validation loss : 0.602358\n",
      "step 38700 , test  accuracy 0.769231\n",
      "step 38700 , test loss : 0.638781\n",
      "step 38800 , training  accuracy 1\n",
      "step 38800 , loss : 0.467486\n",
      "step 38800 , validation  accuracy 0.894737\n",
      "step 38800 , validation loss : 0.603783\n",
      "step 38800 , test  accuracy 0.666667\n",
      "step 38800 , test loss : 0.640468\n",
      "step 38900 , training  accuracy 1\n",
      "step 38900 , loss : 0.46514\n",
      "step 38900 , validation  accuracy 0.868421\n",
      "step 38900 , validation loss : 0.606513\n",
      "step 38900 , test  accuracy 0.666667\n",
      "step 38900 , test loss : 0.639226\n",
      "step 39000 , training  accuracy 1\n",
      "step 39000 , loss : 0.466726\n",
      "step 39000 , validation  accuracy 0.842105\n",
      "step 39000 , validation loss : 0.609985\n",
      "step 39000 , test  accuracy 0.717949\n",
      "step 39000 , test loss : 0.640024\n",
      "step 39100 , training  accuracy 1\n",
      "step 39100 , loss : 0.467304\n",
      "step 39100 , validation  accuracy 0.815789\n",
      "step 39100 , validation loss : 0.614409\n",
      "step 39100 , test  accuracy 0.74359\n",
      "step 39100 , test loss : 0.641472\n",
      "step 39200 , training  accuracy 1\n",
      "step 39200 , loss : 0.468119\n",
      "step 39200 , validation  accuracy 0.815789\n",
      "step 39200 , validation loss : 0.617593\n",
      "step 39200 , test  accuracy 0.717949\n",
      "step 39200 , test loss : 0.643526\n",
      "step 39300 , training  accuracy 1\n",
      "step 39300 , loss : 0.467155\n",
      "step 39300 , validation  accuracy 0.789474\n",
      "step 39300 , validation loss : 0.619614\n",
      "step 39300 , test  accuracy 0.74359\n",
      "step 39300 , test loss : 0.642632\n",
      "step 39400 , training  accuracy 1\n",
      "step 39400 , loss : 0.468049\n",
      "step 39400 , validation  accuracy 0.815789\n",
      "step 39400 , validation loss : 0.620798\n",
      "step 39400 , test  accuracy 0.74359\n",
      "step 39400 , test loss : 0.642621\n",
      "step 39500 , training  accuracy 1\n",
      "step 39500 , loss : 0.466963\n",
      "step 39500 , validation  accuracy 0.789474\n",
      "step 39500 , validation loss : 0.62322\n",
      "step 39500 , test  accuracy 0.769231\n",
      "step 39500 , test loss : 0.643476\n",
      "step 39600 , training  accuracy 1\n",
      "step 39600 , loss : 0.465755\n",
      "step 39600 , validation  accuracy 0.789474\n",
      "step 39600 , validation loss : 0.624993\n",
      "step 39600 , test  accuracy 0.74359\n",
      "step 39600 , test loss : 0.644161\n",
      "step 39700 , training  accuracy 1\n",
      "step 39700 , loss : 0.466214\n",
      "step 39700 , validation  accuracy 0.815789\n",
      "step 39700 , validation loss : 0.625537\n",
      "step 39700 , test  accuracy 0.717949\n",
      "step 39700 , test loss : 0.644226\n",
      "step 39800 , training  accuracy 1\n",
      "step 39800 , loss : 0.465154\n",
      "step 39800 , validation  accuracy 0.789474\n",
      "step 39800 , validation loss : 0.624607\n",
      "step 39800 , test  accuracy 0.769231\n",
      "step 39800 , test loss : 0.644065\n",
      "step 39900 , training  accuracy 1\n",
      "step 39900 , loss : 0.465716\n",
      "step 39900 , validation  accuracy 0.763158\n",
      "step 39900 , validation loss : 0.624032\n",
      "step 39900 , test  accuracy 0.794872\n",
      "step 39900 , test loss : 0.643746\n",
      "step 40000 , training  accuracy 1\n",
      "step 40000 , loss : 0.467188\n",
      "step 40000 , validation  accuracy 0.763158\n",
      "step 40000 , validation loss : 0.622393\n",
      "step 40000 , test  accuracy 0.794872\n",
      "step 40000 , test loss : 0.641829\n",
      "step 40100 , training  accuracy 1\n",
      "step 40100 , loss : 0.465359\n",
      "step 40100 , validation  accuracy 0.815789\n",
      "step 40100 , validation loss : 0.620324\n",
      "step 40100 , test  accuracy 0.769231\n",
      "step 40100 , test loss : 0.635739\n",
      "step 40200 , training  accuracy 1\n",
      "step 40200 , loss : 0.464632\n",
      "step 40200 , validation  accuracy 0.815789\n",
      "step 40200 , validation loss : 0.62072\n",
      "step 40200 , test  accuracy 0.794872\n",
      "step 40200 , test loss : 0.631868\n",
      "step 40300 , training  accuracy 1\n",
      "step 40300 , loss : 0.465355\n",
      "step 40300 , validation  accuracy 0.815789\n",
      "step 40300 , validation loss : 0.620597\n",
      "step 40300 , test  accuracy 0.820513\n",
      "step 40300 , test loss : 0.629233\n",
      "step 40400 , training  accuracy 1\n",
      "step 40400 , loss : 0.464593\n",
      "step 40400 , validation  accuracy 0.815789\n",
      "step 40400 , validation loss : 0.621192\n",
      "step 40400 , test  accuracy 0.820513\n",
      "step 40400 , test loss : 0.628511\n",
      "step 40500 , training  accuracy 1\n",
      "step 40500 , loss : 0.464797\n",
      "step 40500 , validation  accuracy 0.789474\n",
      "step 40500 , validation loss : 0.620778\n",
      "step 40500 , test  accuracy 0.820513\n",
      "step 40500 , test loss : 0.628587\n",
      "step 40600 , training  accuracy 1\n",
      "step 40600 , loss : 0.466074\n",
      "step 40600 , validation  accuracy 0.789474\n",
      "step 40600 , validation loss : 0.620694\n",
      "step 40600 , test  accuracy 0.820513\n",
      "step 40600 , test loss : 0.628962\n",
      "step 40700 , training  accuracy 1\n",
      "step 40700 , loss : 0.464205\n",
      "step 40700 , validation  accuracy 0.789474\n",
      "step 40700 , validation loss : 0.62012\n",
      "step 40700 , test  accuracy 0.820513\n",
      "step 40700 , test loss : 0.631323\n",
      "step 40800 , training  accuracy 1\n",
      "step 40800 , loss : 0.465127\n",
      "step 40800 , validation  accuracy 0.789474\n",
      "step 40800 , validation loss : 0.618684\n",
      "step 40800 , test  accuracy 0.846154\n",
      "step 40800 , test loss : 0.634414\n",
      "step 40900 , training  accuracy 1\n",
      "step 40900 , loss : 0.465532\n",
      "step 40900 , validation  accuracy 0.815789\n",
      "step 40900 , validation loss : 0.619298\n",
      "step 40900 , test  accuracy 0.769231\n",
      "step 40900 , test loss : 0.639377\n",
      "step 41000 , training  accuracy 1\n",
      "step 41000 , loss : 0.464088\n",
      "step 41000 , validation  accuracy 0.763158\n",
      "step 41000 , validation loss : 0.622348\n",
      "step 41000 , test  accuracy 0.74359\n",
      "step 41000 , test loss : 0.644814\n",
      "step 41100 , training  accuracy 1\n",
      "step 41100 , loss : 0.464881\n",
      "step 41100 , validation  accuracy 0.763158\n",
      "step 41100 , validation loss : 0.625462\n",
      "step 41100 , test  accuracy 0.74359\n",
      "step 41100 , test loss : 0.647314\n",
      "step 41200 , training  accuracy 1\n",
      "step 41200 , loss : 0.464218\n",
      "step 41200 , validation  accuracy 0.763158\n",
      "step 41200 , validation loss : 0.627025\n",
      "step 41200 , test  accuracy 0.769231\n",
      "step 41200 , test loss : 0.646846\n",
      "step 41300 , training  accuracy 1\n",
      "step 41300 , loss : 0.464759\n",
      "step 41300 , validation  accuracy 0.763158\n",
      "step 41300 , validation loss : 0.625552\n",
      "step 41300 , test  accuracy 0.769231\n",
      "step 41300 , test loss : 0.644239\n",
      "step 41400 , training  accuracy 1\n",
      "step 41400 , loss : 0.46736\n",
      "step 41400 , validation  accuracy 0.736842\n",
      "step 41400 , validation loss : 0.624107\n",
      "step 41400 , test  accuracy 0.769231\n",
      "step 41400 , test loss : 0.642026\n",
      "step 41500 , training  accuracy 1\n",
      "step 41500 , loss : 0.466601\n",
      "step 41500 , validation  accuracy 0.763158\n",
      "step 41500 , validation loss : 0.62306\n",
      "step 41500 , test  accuracy 0.769231\n",
      "step 41500 , test loss : 0.642884\n",
      "step 41600 , training  accuracy 1\n",
      "step 41600 , loss : 0.466029\n",
      "step 41600 , validation  accuracy 0.763158\n",
      "step 41600 , validation loss : 0.622016\n",
      "step 41600 , test  accuracy 0.717949\n",
      "step 41600 , test loss : 0.643774\n",
      "step 41700 , training  accuracy 1\n",
      "step 41700 , loss : 0.467257\n",
      "step 41700 , validation  accuracy 0.763158\n",
      "step 41700 , validation loss : 0.620274\n",
      "step 41700 , test  accuracy 0.717949\n",
      "step 41700 , test loss : 0.643958\n",
      "step 41800 , training  accuracy 1\n",
      "step 41800 , loss : 0.465314\n",
      "step 41800 , validation  accuracy 0.789474\n",
      "step 41800 , validation loss : 0.61707\n",
      "step 41800 , test  accuracy 0.74359\n",
      "step 41800 , test loss : 0.641568\n",
      "step 41900 , training  accuracy 1\n",
      "step 41900 , loss : 0.465092\n",
      "step 41900 , validation  accuracy 0.789474\n",
      "step 41900 , validation loss : 0.613346\n",
      "step 41900 , test  accuracy 0.820513\n",
      "step 41900 , test loss : 0.638413\n",
      "step 42000 , training  accuracy 1\n",
      "step 42000 , loss : 0.466266\n",
      "step 42000 , validation  accuracy 0.763158\n",
      "step 42000 , validation loss : 0.610555\n",
      "step 42000 , test  accuracy 0.794872\n",
      "step 42000 , test loss : 0.637552\n",
      "step 42100 , training  accuracy 1\n",
      "step 42100 , loss : 0.464999\n",
      "step 42100 , validation  accuracy 0.815789\n",
      "step 42100 , validation loss : 0.607907\n",
      "step 42100 , test  accuracy 0.769231\n",
      "step 42100 , test loss : 0.63866\n",
      "step 42200 , training  accuracy 1\n",
      "step 42200 , loss : 0.465639\n",
      "step 42200 , validation  accuracy 0.789474\n",
      "step 42200 , validation loss : 0.606489\n",
      "step 42200 , test  accuracy 0.794872\n",
      "step 42200 , test loss : 0.637583\n",
      "step 42300 , training  accuracy 1\n",
      "step 42300 , loss : 0.464699\n",
      "step 42300 , validation  accuracy 0.789474\n",
      "step 42300 , validation loss : 0.605324\n",
      "step 42300 , test  accuracy 0.794872\n",
      "step 42300 , test loss : 0.633798\n",
      "step 42400 , training  accuracy 1\n",
      "step 42400 , loss : 0.46445\n",
      "step 42400 , validation  accuracy 0.789474\n",
      "step 42400 , validation loss : 0.605473\n",
      "step 42400 , test  accuracy 0.769231\n",
      "step 42400 , test loss : 0.632071\n",
      "step 42500 , training  accuracy 1\n",
      "step 42500 , loss : 0.464984\n",
      "step 42500 , validation  accuracy 0.789474\n",
      "step 42500 , validation loss : 0.605924\n",
      "step 42500 , test  accuracy 0.74359\n",
      "step 42500 , test loss : 0.631972\n",
      "step 42600 , training  accuracy 1\n",
      "step 42600 , loss : 0.465337\n",
      "step 42600 , validation  accuracy 0.815789\n",
      "step 42600 , validation loss : 0.605994\n",
      "step 42600 , test  accuracy 0.717949\n",
      "step 42600 , test loss : 0.632996\n",
      "step 42700 , training  accuracy 1\n",
      "step 42700 , loss : 0.465167\n",
      "step 42700 , validation  accuracy 0.789474\n",
      "step 42700 , validation loss : 0.605513\n",
      "step 42700 , test  accuracy 0.769231\n",
      "step 42700 , test loss : 0.634745\n",
      "step 42800 , training  accuracy 1\n",
      "step 42800 , loss : 0.465653\n",
      "step 42800 , validation  accuracy 0.789474\n",
      "step 42800 , validation loss : 0.60649\n",
      "step 42800 , test  accuracy 0.717949\n",
      "step 42800 , test loss : 0.637103\n",
      "step 42900 , training  accuracy 1\n",
      "step 42900 , loss : 0.464336\n",
      "step 42900 , validation  accuracy 0.789474\n",
      "step 42900 , validation loss : 0.607483\n",
      "step 42900 , test  accuracy 0.666667\n",
      "step 42900 , test loss : 0.636454\n",
      "step 43000 , training  accuracy 1\n",
      "step 43000 , loss : 0.465093\n",
      "step 43000 , validation  accuracy 0.763158\n",
      "step 43000 , validation loss : 0.60934\n",
      "step 43000 , test  accuracy 0.641026\n",
      "step 43000 , test loss : 0.636369\n",
      "step 43100 , training  accuracy 1\n",
      "step 43100 , loss : 0.464466\n",
      "step 43100 , validation  accuracy 0.789474\n",
      "step 43100 , validation loss : 0.610519\n",
      "step 43100 , test  accuracy 0.641026\n",
      "step 43100 , test loss : 0.636408\n",
      "step 43200 , training  accuracy 1\n",
      "step 43200 , loss : 0.464154\n",
      "step 43200 , validation  accuracy 0.789474\n",
      "step 43200 , validation loss : 0.613003\n",
      "step 43200 , test  accuracy 0.717949\n",
      "step 43200 , test loss : 0.635301\n",
      "step 43300 , training  accuracy 1\n",
      "step 43300 , loss : 0.464366\n",
      "step 43300 , validation  accuracy 0.763158\n",
      "step 43300 , validation loss : 0.618292\n",
      "step 43300 , test  accuracy 0.74359\n",
      "step 43300 , test loss : 0.634376\n",
      "step 43400 , training  accuracy 1\n",
      "step 43400 , loss : 0.463969\n",
      "step 43400 , validation  accuracy 0.763158\n",
      "step 43400 , validation loss : 0.621853\n",
      "step 43400 , test  accuracy 0.74359\n",
      "step 43400 , test loss : 0.634769\n",
      "step 43500 , training  accuracy 1\n",
      "step 43500 , loss : 0.46427\n",
      "step 43500 , validation  accuracy 0.763158\n",
      "step 43500 , validation loss : 0.625775\n",
      "step 43500 , test  accuracy 0.74359\n",
      "step 43500 , test loss : 0.636436\n",
      "step 43600 , training  accuracy 1\n",
      "step 43600 , loss : 0.464549\n",
      "step 43600 , validation  accuracy 0.763158\n",
      "step 43600 , validation loss : 0.629209\n",
      "step 43600 , test  accuracy 0.74359\n",
      "step 43600 , test loss : 0.637491\n",
      "step 43700 , training  accuracy 1\n",
      "step 43700 , loss : 0.464689\n",
      "step 43700 , validation  accuracy 0.763158\n",
      "step 43700 , validation loss : 0.631918\n",
      "step 43700 , test  accuracy 0.717949\n",
      "step 43700 , test loss : 0.639385\n",
      "step 43800 , training  accuracy 1\n",
      "step 43800 , loss : 0.464627\n",
      "step 43800 , validation  accuracy 0.736842\n",
      "step 43800 , validation loss : 0.633811\n",
      "step 43800 , test  accuracy 0.769231\n",
      "step 43800 , test loss : 0.641672\n",
      "step 43900 , training  accuracy 1\n",
      "step 43900 , loss : 0.465261\n",
      "step 43900 , validation  accuracy 0.736842\n",
      "step 43900 , validation loss : 0.636388\n",
      "step 43900 , test  accuracy 0.769231\n",
      "step 43900 , test loss : 0.641297\n",
      "step 44000 , training  accuracy 1\n",
      "step 44000 , loss : 0.46496\n",
      "step 44000 , validation  accuracy 0.736842\n",
      "step 44000 , validation loss : 0.637189\n",
      "step 44000 , test  accuracy 0.769231\n",
      "step 44000 , test loss : 0.639787\n",
      "step 44100 , training  accuracy 1\n",
      "step 44100 , loss : 0.465229\n",
      "step 44100 , validation  accuracy 0.736842\n",
      "step 44100 , validation loss : 0.63669\n",
      "step 44100 , test  accuracy 0.74359\n",
      "step 44100 , test loss : 0.638422\n",
      "step 44200 , training  accuracy 1\n",
      "step 44200 , loss : 0.465398\n",
      "step 44200 , validation  accuracy 0.763158\n",
      "step 44200 , validation loss : 0.633944\n",
      "step 44200 , test  accuracy 0.794872\n",
      "step 44200 , test loss : 0.634537\n",
      "step 44300 , training  accuracy 1\n",
      "step 44300 , loss : 0.464045\n",
      "step 44300 , validation  accuracy 0.789474\n",
      "step 44300 , validation loss : 0.631005\n",
      "step 44300 , test  accuracy 0.820513\n",
      "step 44300 , test loss : 0.631972\n",
      "step 44400 , training  accuracy 1\n",
      "step 44400 , loss : 0.464711\n",
      "step 44400 , validation  accuracy 0.789474\n",
      "step 44400 , validation loss : 0.628664\n",
      "step 44400 , test  accuracy 0.794872\n",
      "step 44400 , test loss : 0.631964\n",
      "step 44500 , training  accuracy 1\n",
      "step 44500 , loss : 0.466224\n",
      "step 44500 , validation  accuracy 0.815789\n",
      "step 44500 , validation loss : 0.626243\n",
      "step 44500 , test  accuracy 0.794872\n",
      "step 44500 , test loss : 0.632903\n",
      "step 44600 , training  accuracy 1\n",
      "step 44600 , loss : 0.465105\n",
      "step 44600 , validation  accuracy 0.815789\n",
      "step 44600 , validation loss : 0.624056\n",
      "step 44600 , test  accuracy 0.769231\n",
      "step 44600 , test loss : 0.633935\n",
      "step 44700 , training  accuracy 1\n",
      "step 44700 , loss : 0.46577\n",
      "step 44700 , validation  accuracy 0.815789\n",
      "step 44700 , validation loss : 0.621758\n",
      "step 44700 , test  accuracy 0.74359\n",
      "step 44700 , test loss : 0.633392\n",
      "step 44800 , training  accuracy 1\n",
      "step 44800 , loss : 0.465547\n",
      "step 44800 , validation  accuracy 0.815789\n",
      "step 44800 , validation loss : 0.620281\n",
      "step 44800 , test  accuracy 0.74359\n",
      "step 44800 , test loss : 0.632743\n",
      "step 44900 , training  accuracy 1\n",
      "step 44900 , loss : 0.46516\n",
      "step 44900 , validation  accuracy 0.815789\n",
      "step 44900 , validation loss : 0.62051\n",
      "step 44900 , test  accuracy 0.820513\n",
      "step 44900 , test loss : 0.630648\n",
      "step 45000 , training  accuracy 1\n",
      "step 45000 , loss : 0.464788\n",
      "step 45000 , validation  accuracy 0.815789\n",
      "step 45000 , validation loss : 0.620713\n",
      "step 45000 , test  accuracy 0.820513\n",
      "step 45000 , test loss : 0.627933\n",
      "step 45100 , training  accuracy 1\n",
      "step 45100 , loss : 0.464182\n",
      "step 45100 , validation  accuracy 0.815789\n",
      "step 45100 , validation loss : 0.620515\n",
      "step 45100 , test  accuracy 0.820513\n",
      "step 45100 , test loss : 0.626914\n",
      "step 45200 , training  accuracy 1\n",
      "step 45200 , loss : 0.463921\n",
      "step 45200 , validation  accuracy 0.815789\n",
      "step 45200 , validation loss : 0.621408\n",
      "step 45200 , test  accuracy 0.794872\n",
      "step 45200 , test loss : 0.626948\n",
      "step 45300 , training  accuracy 1\n",
      "step 45300 , loss : 0.463481\n",
      "step 45300 , validation  accuracy 0.815789\n",
      "step 45300 , validation loss : 0.621588\n",
      "step 45300 , test  accuracy 0.769231\n",
      "step 45300 , test loss : 0.626823\n",
      "step 45400 , training  accuracy 1\n",
      "step 45400 , loss : 0.465324\n",
      "step 45400 , validation  accuracy 0.815789\n",
      "step 45400 , validation loss : 0.621301\n",
      "step 45400 , test  accuracy 0.769231\n",
      "step 45400 , test loss : 0.627314\n",
      "step 45500 , training  accuracy 1\n",
      "step 45500 , loss : 0.464341\n",
      "step 45500 , validation  accuracy 0.815789\n",
      "step 45500 , validation loss : 0.619602\n",
      "step 45500 , test  accuracy 0.769231\n",
      "step 45500 , test loss : 0.627726\n",
      "step 45600 , training  accuracy 1\n",
      "step 45600 , loss : 0.464234\n",
      "step 45600 , validation  accuracy 0.815789\n",
      "step 45600 , validation loss : 0.617616\n",
      "step 45600 , test  accuracy 0.769231\n",
      "step 45600 , test loss : 0.628211\n",
      "step 45700 , training  accuracy 1\n",
      "step 45700 , loss : 0.463604\n",
      "step 45700 , validation  accuracy 0.815789\n",
      "step 45700 , validation loss : 0.616513\n",
      "step 45700 , test  accuracy 0.74359\n",
      "step 45700 , test loss : 0.629185\n",
      "step 45800 , training  accuracy 1\n",
      "step 45800 , loss : 0.464827\n",
      "step 45800 , validation  accuracy 0.815789\n",
      "step 45800 , validation loss : 0.616647\n",
      "step 45800 , test  accuracy 0.74359\n",
      "step 45800 , test loss : 0.630099\n",
      "step 45900 , training  accuracy 1\n",
      "step 45900 , loss : 0.463418\n",
      "step 45900 , validation  accuracy 0.815789\n",
      "step 45900 , validation loss : 0.617164\n",
      "step 45900 , test  accuracy 0.74359\n",
      "step 45900 , test loss : 0.629891\n",
      "step 46000 , training  accuracy 1\n",
      "step 46000 , loss : 0.464154\n",
      "step 46000 , validation  accuracy 0.815789\n",
      "step 46000 , validation loss : 0.618029\n",
      "step 46000 , test  accuracy 0.769231\n",
      "step 46000 , test loss : 0.628266\n",
      "step 46100 , training  accuracy 1\n",
      "step 46100 , loss : 0.465518\n",
      "step 46100 , validation  accuracy 0.815789\n",
      "step 46100 , validation loss : 0.620113\n",
      "step 46100 , test  accuracy 0.769231\n",
      "step 46100 , test loss : 0.627886\n",
      "step 46200 , training  accuracy 1\n",
      "step 46200 , loss : 0.463915\n",
      "step 46200 , validation  accuracy 0.789474\n",
      "step 46200 , validation loss : 0.620756\n",
      "step 46200 , test  accuracy 0.769231\n",
      "step 46200 , test loss : 0.627593\n",
      "step 46300 , training  accuracy 1\n",
      "step 46300 , loss : 0.463562\n",
      "step 46300 , validation  accuracy 0.763158\n",
      "step 46300 , validation loss : 0.62037\n",
      "step 46300 , test  accuracy 0.794872\n",
      "step 46300 , test loss : 0.627815\n",
      "step 46400 , training  accuracy 0.966667\n",
      "step 46400 , loss : 0.477367\n",
      "step 46400 , validation  accuracy 0.789474\n",
      "step 46400 , validation loss : 0.61967\n",
      "step 46400 , test  accuracy 0.794872\n",
      "step 46400 , test loss : 0.628614\n",
      "step 46500 , training  accuracy 1\n",
      "step 46500 , loss : 0.463934\n",
      "step 46500 , validation  accuracy 0.763158\n",
      "step 46500 , validation loss : 0.6186\n",
      "step 46500 , test  accuracy 0.794872\n",
      "step 46500 , test loss : 0.627329\n",
      "step 46600 , training  accuracy 1\n",
      "step 46600 , loss : 0.464603\n",
      "step 46600 , validation  accuracy 0.763158\n",
      "step 46600 , validation loss : 0.616968\n",
      "step 46600 , test  accuracy 0.794872\n",
      "step 46600 , test loss : 0.626161\n",
      "step 46700 , training  accuracy 1\n",
      "step 46700 , loss : 0.463876\n",
      "step 46700 , validation  accuracy 0.789474\n",
      "step 46700 , validation loss : 0.615654\n",
      "step 46700 , test  accuracy 0.794872\n",
      "step 46700 , test loss : 0.62455\n",
      "step 46800 , training  accuracy 1\n",
      "step 46800 , loss : 0.463835\n",
      "step 46800 , validation  accuracy 0.789474\n",
      "step 46800 , validation loss : 0.615949\n",
      "step 46800 , test  accuracy 0.820513\n",
      "step 46800 , test loss : 0.623173\n",
      "step 46900 , training  accuracy 1\n",
      "step 46900 , loss : 0.463745\n",
      "step 46900 , validation  accuracy 0.789474\n",
      "step 46900 , validation loss : 0.614878\n",
      "step 46900 , test  accuracy 0.820513\n",
      "step 46900 , test loss : 0.622895\n",
      "step 47000 , training  accuracy 1\n",
      "step 47000 , loss : 0.465102\n",
      "step 47000 , validation  accuracy 0.789474\n",
      "step 47000 , validation loss : 0.613065\n",
      "step 47000 , test  accuracy 0.820513\n",
      "step 47000 , test loss : 0.623881\n",
      "step 47100 , training  accuracy 1\n",
      "step 47100 , loss : 0.463973\n",
      "step 47100 , validation  accuracy 0.789474\n",
      "step 47100 , validation loss : 0.611445\n",
      "step 47100 , test  accuracy 0.820513\n",
      "step 47100 , test loss : 0.624796\n",
      "step 47200 , training  accuracy 1\n",
      "step 47200 , loss : 0.464868\n",
      "step 47200 , validation  accuracy 0.789474\n",
      "step 47200 , validation loss : 0.611431\n",
      "step 47200 , test  accuracy 0.794872\n",
      "step 47200 , test loss : 0.625042\n",
      "step 47300 , training  accuracy 1\n",
      "step 47300 , loss : 0.466441\n",
      "step 47300 , validation  accuracy 0.789474\n",
      "step 47300 , validation loss : 0.612577\n",
      "step 47300 , test  accuracy 0.794872\n",
      "step 47300 , test loss : 0.624453\n",
      "step 47400 , training  accuracy 1\n",
      "step 47400 , loss : 0.46515\n",
      "step 47400 , validation  accuracy 0.789474\n",
      "step 47400 , validation loss : 0.614026\n",
      "step 47400 , test  accuracy 0.794872\n",
      "step 47400 , test loss : 0.62428\n",
      "step 47500 , training  accuracy 1\n",
      "step 47500 , loss : 0.464499\n",
      "step 47500 , validation  accuracy 0.789474\n",
      "step 47500 , validation loss : 0.616022\n",
      "step 47500 , test  accuracy 0.820513\n",
      "step 47500 , test loss : 0.62508\n",
      "step 47600 , training  accuracy 1\n",
      "step 47600 , loss : 0.464858\n",
      "step 47600 , validation  accuracy 0.789474\n",
      "step 47600 , validation loss : 0.617973\n",
      "step 47600 , test  accuracy 0.794872\n",
      "step 47600 , test loss : 0.625969\n",
      "step 47700 , training  accuracy 1\n",
      "step 47700 , loss : 0.465799\n",
      "step 47700 , validation  accuracy 0.789474\n",
      "step 47700 , validation loss : 0.618356\n",
      "step 47700 , test  accuracy 0.794872\n",
      "step 47700 , test loss : 0.628879\n",
      "step 47800 , training  accuracy 1\n",
      "step 47800 , loss : 0.465382\n",
      "step 47800 , validation  accuracy 0.789474\n",
      "step 47800 , validation loss : 0.617116\n",
      "step 47800 , test  accuracy 0.794872\n",
      "step 47800 , test loss : 0.630923\n",
      "step 47900 , training  accuracy 1\n",
      "step 47900 , loss : 0.464166\n",
      "step 47900 , validation  accuracy 0.815789\n",
      "step 47900 , validation loss : 0.615642\n",
      "step 47900 , test  accuracy 0.769231\n",
      "step 47900 , test loss : 0.631946\n",
      "step 48000 , training  accuracy 1\n",
      "step 48000 , loss : 0.463908\n",
      "step 48000 , validation  accuracy 0.815789\n",
      "step 48000 , validation loss : 0.614828\n",
      "step 48000 , test  accuracy 0.794872\n",
      "step 48000 , test loss : 0.632389\n",
      "step 48100 , training  accuracy 1\n",
      "step 48100 , loss : 0.463792\n",
      "step 48100 , validation  accuracy 0.815789\n",
      "step 48100 , validation loss : 0.614994\n",
      "step 48100 , test  accuracy 0.794872\n",
      "step 48100 , test loss : 0.633728\n",
      "step 48200 , training  accuracy 1\n",
      "step 48200 , loss : 0.464372\n",
      "step 48200 , validation  accuracy 0.789474\n",
      "step 48200 , validation loss : 0.616163\n",
      "step 48200 , test  accuracy 0.794872\n",
      "step 48200 , test loss : 0.635783\n",
      "step 48300 , training  accuracy 1\n",
      "step 48300 , loss : 0.463601\n",
      "step 48300 , validation  accuracy 0.789474\n",
      "step 48300 , validation loss : 0.616904\n",
      "step 48300 , test  accuracy 0.794872\n",
      "step 48300 , test loss : 0.636266\n",
      "step 48400 , training  accuracy 1\n",
      "step 48400 , loss : 0.46446\n",
      "step 48400 , validation  accuracy 0.789474\n",
      "step 48400 , validation loss : 0.617504\n",
      "step 48400 , test  accuracy 0.794872\n",
      "step 48400 , test loss : 0.63707\n",
      "step 48500 , training  accuracy 1\n",
      "step 48500 , loss : 0.463539\n",
      "step 48500 , validation  accuracy 0.789474\n",
      "step 48500 , validation loss : 0.617934\n",
      "step 48500 , test  accuracy 0.794872\n",
      "step 48500 , test loss : 0.638037\n",
      "step 48600 , training  accuracy 1\n",
      "step 48600 , loss : 0.464236\n",
      "step 48600 , validation  accuracy 0.789474\n",
      "step 48600 , validation loss : 0.618088\n",
      "step 48600 , test  accuracy 0.794872\n",
      "step 48600 , test loss : 0.637664\n",
      "step 48700 , training  accuracy 1\n",
      "step 48700 , loss : 0.463379\n",
      "step 48700 , validation  accuracy 0.789474\n",
      "step 48700 , validation loss : 0.617499\n",
      "step 48700 , test  accuracy 0.769231\n",
      "step 48700 , test loss : 0.634929\n",
      "step 48800 , training  accuracy 1\n",
      "step 48800 , loss : 0.463812\n",
      "step 48800 , validation  accuracy 0.789474\n",
      "step 48800 , validation loss : 0.617901\n",
      "step 48800 , test  accuracy 0.794872\n",
      "step 48800 , test loss : 0.632837\n",
      "step 48900 , training  accuracy 1\n",
      "step 48900 , loss : 0.464989\n",
      "step 48900 , validation  accuracy 0.789474\n",
      "step 48900 , validation loss : 0.617971\n",
      "step 48900 , test  accuracy 0.794872\n",
      "step 48900 , test loss : 0.632429\n",
      "step 49000 , training  accuracy 1\n",
      "step 49000 , loss : 0.463353\n",
      "step 49000 , validation  accuracy 0.789474\n",
      "step 49000 , validation loss : 0.618258\n",
      "step 49000 , test  accuracy 0.794872\n",
      "step 49000 , test loss : 0.632911\n",
      "step 49100 , training  accuracy 1\n",
      "step 49100 , loss : 0.464159\n",
      "step 49100 , validation  accuracy 0.789474\n",
      "step 49100 , validation loss : 0.617603\n",
      "step 49100 , test  accuracy 0.794872\n",
      "step 49100 , test loss : 0.633358\n",
      "step 49200 , training  accuracy 1\n",
      "step 49200 , loss : 0.463492\n",
      "step 49200 , validation  accuracy 0.789474\n",
      "step 49200 , validation loss : 0.616617\n",
      "step 49200 , test  accuracy 0.794872\n",
      "step 49200 , test loss : 0.633404\n",
      "step 49300 , training  accuracy 1\n",
      "step 49300 , loss : 0.464484\n",
      "step 49300 , validation  accuracy 0.789474\n",
      "step 49300 , validation loss : 0.615722\n",
      "step 49300 , test  accuracy 0.794872\n",
      "step 49300 , test loss : 0.632893\n",
      "step 49400 , training  accuracy 1\n",
      "step 49400 , loss : 0.463831\n",
      "step 49400 , validation  accuracy 0.789474\n",
      "step 49400 , validation loss : 0.613991\n",
      "step 49400 , test  accuracy 0.794872\n",
      "step 49400 , test loss : 0.631455\n",
      "step 49500 , training  accuracy 1\n",
      "step 49500 , loss : 0.464051\n",
      "step 49500 , validation  accuracy 0.789474\n",
      "step 49500 , validation loss : 0.613245\n",
      "step 49500 , test  accuracy 0.794872\n",
      "step 49500 , test loss : 0.62939\n",
      "step 49600 , training  accuracy 1\n",
      "step 49600 , loss : 0.465731\n",
      "step 49600 , validation  accuracy 0.789474\n",
      "step 49600 , validation loss : 0.612841\n",
      "step 49600 , test  accuracy 0.769231\n",
      "step 49600 , test loss : 0.628183\n",
      "step 49700 , training  accuracy 1\n",
      "step 49700 , loss : 0.465456\n",
      "step 49700 , validation  accuracy 0.789474\n",
      "step 49700 , validation loss : 0.612455\n",
      "step 49700 , test  accuracy 0.794872\n",
      "step 49700 , test loss : 0.625631\n",
      "step 49800 , training  accuracy 1\n",
      "step 49800 , loss : 0.463442\n",
      "step 49800 , validation  accuracy 0.815789\n",
      "step 49800 , validation loss : 0.612695\n",
      "step 49800 , test  accuracy 0.820513\n",
      "step 49800 , test loss : 0.622481\n",
      "step 49900 , training  accuracy 1\n",
      "step 49900 , loss : 0.464016\n",
      "step 49900 , validation  accuracy 0.815789\n",
      "step 49900 , validation loss : 0.612958\n",
      "step 49900 , test  accuracy 0.820513\n",
      "step 49900 , test loss : 0.620731\n",
      "step 50000 , training  accuracy 1\n",
      "step 50000 , loss : 0.463692\n",
      "step 50000 , validation  accuracy 0.815789\n",
      "step 50000 , validation loss : 0.61375\n",
      "step 50000 , test  accuracy 0.769231\n",
      "step 50000 , test loss : 0.619989\n",
      "step 50100 , training  accuracy 1\n",
      "step 50100 , loss : 0.464197\n",
      "step 50100 , validation  accuracy 0.815789\n",
      "step 50100 , validation loss : 0.614832\n",
      "step 50100 , test  accuracy 0.769231\n",
      "step 50100 , test loss : 0.6199\n",
      "step 50200 , training  accuracy 1\n",
      "step 50200 , loss : 0.463475\n",
      "step 50200 , validation  accuracy 0.815789\n",
      "step 50200 , validation loss : 0.616077\n",
      "step 50200 , test  accuracy 0.769231\n",
      "step 50200 , test loss : 0.620089\n",
      "step 50300 , training  accuracy 1\n",
      "step 50300 , loss : 0.464065\n",
      "step 50300 , validation  accuracy 0.815789\n",
      "step 50300 , validation loss : 0.617275\n",
      "step 50300 , test  accuracy 0.769231\n",
      "step 50300 , test loss : 0.620379\n",
      "step 50400 , training  accuracy 1\n",
      "step 50400 , loss : 0.464073\n",
      "step 50400 , validation  accuracy 0.815789\n",
      "step 50400 , validation loss : 0.616082\n",
      "step 50400 , test  accuracy 0.769231\n",
      "step 50400 , test loss : 0.621161\n",
      "step 50500 , training  accuracy 1\n",
      "step 50500 , loss : 0.464341\n",
      "step 50500 , validation  accuracy 0.815789\n",
      "step 50500 , validation loss : 0.614194\n",
      "step 50500 , test  accuracy 0.794872\n",
      "step 50500 , test loss : 0.621265\n",
      "step 50600 , training  accuracy 1\n",
      "step 50600 , loss : 0.463519\n",
      "step 50600 , validation  accuracy 0.789474\n",
      "step 50600 , validation loss : 0.613023\n",
      "step 50600 , test  accuracy 0.820513\n",
      "step 50600 , test loss : 0.622833\n",
      "step 50700 , training  accuracy 1\n",
      "step 50700 , loss : 0.463642\n",
      "step 50700 , validation  accuracy 0.789474\n",
      "step 50700 , validation loss : 0.612215\n",
      "step 50700 , test  accuracy 0.794872\n",
      "step 50700 , test loss : 0.623989\n",
      "step 50800 , training  accuracy 1\n",
      "step 50800 , loss : 0.464198\n",
      "step 50800 , validation  accuracy 0.789474\n",
      "step 50800 , validation loss : 0.611458\n",
      "step 50800 , test  accuracy 0.769231\n",
      "step 50800 , test loss : 0.625255\n",
      "step 50900 , training  accuracy 1\n",
      "step 50900 , loss : 0.464016\n",
      "step 50900 , validation  accuracy 0.789474\n",
      "step 50900 , validation loss : 0.610603\n",
      "step 50900 , test  accuracy 0.794872\n",
      "step 50900 , test loss : 0.62436\n",
      "step 51000 , training  accuracy 1\n",
      "step 51000 , loss : 0.464111\n",
      "step 51000 , validation  accuracy 0.815789\n",
      "step 51000 , validation loss : 0.610154\n",
      "step 51000 , test  accuracy 0.820513\n",
      "step 51000 , test loss : 0.622328\n",
      "step 51100 , training  accuracy 1\n",
      "step 51100 , loss : 0.464588\n",
      "step 51100 , validation  accuracy 0.815789\n",
      "step 51100 , validation loss : 0.61163\n",
      "step 51100 , test  accuracy 0.820513\n",
      "step 51100 , test loss : 0.621644\n",
      "step 51200 , training  accuracy 1\n",
      "step 51200 , loss : 0.466313\n",
      "step 51200 , validation  accuracy 0.815789\n",
      "step 51200 , validation loss : 0.613116\n",
      "step 51200 , test  accuracy 0.769231\n",
      "step 51200 , test loss : 0.621637\n",
      "step 51300 , training  accuracy 1\n",
      "step 51300 , loss : 0.46471\n",
      "step 51300 , validation  accuracy 0.815789\n",
      "step 51300 , validation loss : 0.612137\n",
      "step 51300 , test  accuracy 0.794872\n",
      "step 51300 , test loss : 0.622152\n",
      "step 51400 , training  accuracy 1\n",
      "step 51400 , loss : 0.463351\n",
      "step 51400 , validation  accuracy 0.815789\n",
      "step 51400 , validation loss : 0.610509\n",
      "step 51400 , test  accuracy 0.794872\n",
      "step 51400 , test loss : 0.622507\n",
      "step 51500 , training  accuracy 1\n",
      "step 51500 , loss : 0.463924\n",
      "step 51500 , validation  accuracy 0.789474\n",
      "step 51500 , validation loss : 0.610674\n",
      "step 51500 , test  accuracy 0.74359\n",
      "step 51500 , test loss : 0.625143\n",
      "step 51600 , training  accuracy 1\n",
      "step 51600 , loss : 0.464156\n",
      "step 51600 , validation  accuracy 0.815789\n",
      "step 51600 , validation loss : 0.612\n",
      "step 51600 , test  accuracy 0.74359\n",
      "step 51600 , test loss : 0.628235\n",
      "step 51700 , training  accuracy 1\n",
      "step 51700 , loss : 0.464032\n",
      "step 51700 , validation  accuracy 0.842105\n",
      "step 51700 , validation loss : 0.61085\n",
      "step 51700 , test  accuracy 0.74359\n",
      "step 51700 , test loss : 0.628556\n",
      "step 51800 , training  accuracy 1\n",
      "step 51800 , loss : 0.463631\n",
      "step 51800 , validation  accuracy 0.815789\n",
      "step 51800 , validation loss : 0.609241\n",
      "step 51800 , test  accuracy 0.717949\n",
      "step 51800 , test loss : 0.628156\n",
      "step 51900 , training  accuracy 1\n",
      "step 51900 , loss : 0.46432\n",
      "step 51900 , validation  accuracy 0.842105\n",
      "step 51900 , validation loss : 0.607997\n",
      "step 51900 , test  accuracy 0.769231\n",
      "step 51900 , test loss : 0.626362\n",
      "step 52000 , training  accuracy 1\n",
      "step 52000 , loss : 0.464335\n",
      "step 52000 , validation  accuracy 0.842105\n",
      "step 52000 , validation loss : 0.60916\n",
      "step 52000 , test  accuracy 0.769231\n",
      "step 52000 , test loss : 0.625855\n",
      "step 52100 , training  accuracy 1\n",
      "step 52100 , loss : 0.46447\n",
      "step 52100 , validation  accuracy 0.842105\n",
      "step 52100 , validation loss : 0.610495\n",
      "step 52100 , test  accuracy 0.769231\n",
      "step 52100 , test loss : 0.625866\n",
      "step 52200 , training  accuracy 1\n",
      "step 52200 , loss : 0.463703\n",
      "step 52200 , validation  accuracy 0.842105\n",
      "step 52200 , validation loss : 0.612066\n",
      "step 52200 , test  accuracy 0.769231\n",
      "step 52200 , test loss : 0.627585\n",
      "step 52300 , training  accuracy 1\n",
      "step 52300 , loss : 0.464346\n",
      "step 52300 , validation  accuracy 0.842105\n",
      "step 52300 , validation loss : 0.61269\n",
      "step 52300 , test  accuracy 0.769231\n",
      "step 52300 , test loss : 0.630329\n",
      "step 52400 , training  accuracy 1\n",
      "step 52400 , loss : 0.463996\n",
      "step 52400 , validation  accuracy 0.842105\n",
      "step 52400 , validation loss : 0.613779\n",
      "step 52400 , test  accuracy 0.74359\n",
      "step 52400 , test loss : 0.633433\n",
      "step 52500 , training  accuracy 1\n",
      "step 52500 , loss : 0.463694\n",
      "step 52500 , validation  accuracy 0.842105\n",
      "step 52500 , validation loss : 0.615371\n",
      "step 52500 , test  accuracy 0.717949\n",
      "step 52500 , test loss : 0.636402\n",
      "step 52600 , training  accuracy 1\n",
      "step 52600 , loss : 0.46359\n",
      "step 52600 , validation  accuracy 0.842105\n",
      "step 52600 , validation loss : 0.617017\n",
      "step 52600 , test  accuracy 0.717949\n",
      "step 52600 , test loss : 0.638959\n",
      "step 52700 , training  accuracy 1\n",
      "step 52700 , loss : 0.463308\n",
      "step 52700 , validation  accuracy 0.815789\n",
      "step 52700 , validation loss : 0.619064\n",
      "step 52700 , test  accuracy 0.717949\n",
      "step 52700 , test loss : 0.640328\n",
      "step 52800 , training  accuracy 1\n",
      "step 52800 , loss : 0.463246\n",
      "step 52800 , validation  accuracy 0.815789\n",
      "step 52800 , validation loss : 0.62136\n",
      "step 52800 , test  accuracy 0.717949\n",
      "step 52800 , test loss : 0.640218\n",
      "step 52900 , training  accuracy 1\n",
      "step 52900 , loss : 0.463457\n",
      "step 52900 , validation  accuracy 0.789474\n",
      "step 52900 , validation loss : 0.623426\n",
      "step 52900 , test  accuracy 0.717949\n",
      "step 52900 , test loss : 0.639749\n",
      "step 53000 , training  accuracy 1\n",
      "step 53000 , loss : 0.463525\n",
      "step 53000 , validation  accuracy 0.789474\n",
      "step 53000 , validation loss : 0.625016\n",
      "step 53000 , test  accuracy 0.769231\n",
      "step 53000 , test loss : 0.638663\n",
      "step 53100 , training  accuracy 1\n",
      "step 53100 , loss : 0.465184\n",
      "step 53100 , validation  accuracy 0.789474\n",
      "step 53100 , validation loss : 0.62724\n",
      "step 53100 , test  accuracy 0.794872\n",
      "step 53100 , test loss : 0.638123\n",
      "step 53200 , training  accuracy 1\n",
      "step 53200 , loss : 0.463466\n",
      "step 53200 , validation  accuracy 0.789474\n",
      "step 53200 , validation loss : 0.628576\n",
      "step 53200 , test  accuracy 0.794872\n",
      "step 53200 , test loss : 0.63887\n",
      "step 53300 , training  accuracy 1\n",
      "step 53300 , loss : 0.463411\n",
      "step 53300 , validation  accuracy 0.789474\n",
      "step 53300 , validation loss : 0.629439\n",
      "step 53300 , test  accuracy 0.769231\n",
      "step 53300 , test loss : 0.639458\n",
      "step 53400 , training  accuracy 1\n",
      "step 53400 , loss : 0.463715\n",
      "step 53400 , validation  accuracy 0.789474\n",
      "step 53400 , validation loss : 0.629314\n",
      "step 53400 , test  accuracy 0.769231\n",
      "step 53400 , test loss : 0.639596\n",
      "step 53500 , training  accuracy 1\n",
      "step 53500 , loss : 0.463968\n",
      "step 53500 , validation  accuracy 0.789474\n",
      "step 53500 , validation loss : 0.628657\n",
      "step 53500 , test  accuracy 0.769231\n",
      "step 53500 , test loss : 0.639637\n",
      "step 53600 , training  accuracy 1\n",
      "step 53600 , loss : 0.463267\n",
      "step 53600 , validation  accuracy 0.815789\n",
      "step 53600 , validation loss : 0.626615\n",
      "step 53600 , test  accuracy 0.820513\n",
      "step 53600 , test loss : 0.63906\n",
      "step 53700 , training  accuracy 1\n",
      "step 53700 , loss : 0.463298\n",
      "step 53700 , validation  accuracy 0.815789\n",
      "step 53700 , validation loss : 0.624745\n",
      "step 53700 , test  accuracy 0.794872\n",
      "step 53700 , test loss : 0.637818\n",
      "step 53800 , training  accuracy 1\n",
      "step 53800 , loss : 0.463115\n",
      "step 53800 , validation  accuracy 0.815789\n",
      "step 53800 , validation loss : 0.62356\n",
      "step 53800 , test  accuracy 0.769231\n",
      "step 53800 , test loss : 0.637392\n",
      "step 53900 , training  accuracy 1\n",
      "step 53900 , loss : 0.463999\n",
      "step 53900 , validation  accuracy 0.789474\n",
      "step 53900 , validation loss : 0.623394\n",
      "step 53900 , test  accuracy 0.769231\n",
      "step 53900 , test loss : 0.636165\n",
      "step 54000 , training  accuracy 1\n",
      "step 54000 , loss : 0.463978\n",
      "step 54000 , validation  accuracy 0.789474\n",
      "step 54000 , validation loss : 0.623144\n",
      "step 54000 , test  accuracy 0.794872\n",
      "step 54000 , test loss : 0.633385\n",
      "step 54100 , training  accuracy 1\n",
      "step 54100 , loss : 0.464243\n",
      "step 54100 , validation  accuracy 0.789474\n",
      "step 54100 , validation loss : 0.623428\n",
      "step 54100 , test  accuracy 0.794872\n",
      "step 54100 , test loss : 0.63115\n",
      "step 54200 , training  accuracy 1\n",
      "step 54200 , loss : 0.4671\n",
      "step 54200 , validation  accuracy 0.789474\n",
      "step 54200 , validation loss : 0.624621\n",
      "step 54200 , test  accuracy 0.794872\n",
      "step 54200 , test loss : 0.629401\n",
      "step 54300 , training  accuracy 1\n",
      "step 54300 , loss : 0.464646\n",
      "step 54300 , validation  accuracy 0.789474\n",
      "step 54300 , validation loss : 0.624884\n",
      "step 54300 , test  accuracy 0.769231\n",
      "step 54300 , test loss : 0.628254\n",
      "step 54400 , training  accuracy 1\n",
      "step 54400 , loss : 0.464227\n",
      "step 54400 , validation  accuracy 0.789474\n",
      "step 54400 , validation loss : 0.624568\n",
      "step 54400 , test  accuracy 0.769231\n",
      "step 54400 , test loss : 0.626594\n",
      "step 54500 , training  accuracy 1\n",
      "step 54500 , loss : 0.464708\n",
      "step 54500 , validation  accuracy 0.789474\n",
      "step 54500 , validation loss : 0.621966\n",
      "step 54500 , test  accuracy 0.769231\n",
      "step 54500 , test loss : 0.62441\n",
      "step 54600 , training  accuracy 1\n",
      "step 54600 , loss : 0.463328\n",
      "step 54600 , validation  accuracy 0.789474\n",
      "step 54600 , validation loss : 0.617312\n",
      "step 54600 , test  accuracy 0.769231\n",
      "step 54600 , test loss : 0.622512\n",
      "step 54700 , training  accuracy 1\n",
      "step 54700 , loss : 0.4644\n",
      "step 54700 , validation  accuracy 0.789474\n",
      "step 54700 , validation loss : 0.614032\n",
      "step 54700 , test  accuracy 0.794872\n",
      "step 54700 , test loss : 0.622924\n",
      "step 54800 , training  accuracy 1\n",
      "step 54800 , loss : 0.463308\n",
      "step 54800 , validation  accuracy 0.789474\n",
      "step 54800 , validation loss : 0.612907\n",
      "step 54800 , test  accuracy 0.794872\n",
      "step 54800 , test loss : 0.624715\n",
      "step 54900 , training  accuracy 1\n",
      "step 54900 , loss : 0.463912\n",
      "step 54900 , validation  accuracy 0.789474\n",
      "step 54900 , validation loss : 0.612406\n",
      "step 54900 , test  accuracy 0.794872\n",
      "step 54900 , test loss : 0.625556\n",
      "step 55000 , training  accuracy 1\n",
      "step 55000 , loss : 0.463486\n",
      "step 55000 , validation  accuracy 0.789474\n",
      "step 55000 , validation loss : 0.61265\n",
      "step 55000 , test  accuracy 0.794872\n",
      "step 55000 , test loss : 0.625972\n",
      "step 55100 , training  accuracy 1\n",
      "step 55100 , loss : 0.464404\n",
      "step 55100 , validation  accuracy 0.789474\n",
      "step 55100 , validation loss : 0.61384\n",
      "step 55100 , test  accuracy 0.769231\n",
      "step 55100 , test loss : 0.625706\n",
      "step 55200 , training  accuracy 1\n",
      "step 55200 , loss : 0.464609\n",
      "step 55200 , validation  accuracy 0.789474\n",
      "step 55200 , validation loss : 0.617489\n",
      "step 55200 , test  accuracy 0.769231\n",
      "step 55200 , test loss : 0.62549\n",
      "step 55300 , training  accuracy 1\n",
      "step 55300 , loss : 0.463987\n",
      "step 55300 , validation  accuracy 0.789474\n",
      "step 55300 , validation loss : 0.620476\n",
      "step 55300 , test  accuracy 0.769231\n",
      "step 55300 , test loss : 0.626657\n",
      "step 55400 , training  accuracy 1\n",
      "step 55400 , loss : 0.463623\n",
      "step 55400 , validation  accuracy 0.789474\n",
      "step 55400 , validation loss : 0.62159\n",
      "step 55400 , test  accuracy 0.74359\n",
      "step 55400 , test loss : 0.628822\n",
      "step 55500 , training  accuracy 1\n",
      "step 55500 , loss : 0.463789\n",
      "step 55500 , validation  accuracy 0.789474\n",
      "step 55500 , validation loss : 0.620999\n",
      "step 55500 , test  accuracy 0.74359\n",
      "step 55500 , test loss : 0.630687\n",
      "step 55600 , training  accuracy 1\n",
      "step 55600 , loss : 0.46448\n",
      "step 55600 , validation  accuracy 0.789474\n",
      "step 55600 , validation loss : 0.618419\n",
      "step 55600 , test  accuracy 0.74359\n",
      "step 55600 , test loss : 0.632874\n",
      "step 55700 , training  accuracy 1\n",
      "step 55700 , loss : 0.463468\n",
      "step 55700 , validation  accuracy 0.815789\n",
      "step 55700 , validation loss : 0.616766\n",
      "step 55700 , test  accuracy 0.769231\n",
      "step 55700 , test loss : 0.634893\n",
      "step 55800 , training  accuracy 1\n",
      "step 55800 , loss : 0.463737\n",
      "step 55800 , validation  accuracy 0.815789\n",
      "step 55800 , validation loss : 0.616307\n",
      "step 55800 , test  accuracy 0.794872\n",
      "step 55800 , test loss : 0.637144\n",
      "step 55900 , training  accuracy 1\n",
      "step 55900 , loss : 0.463876\n",
      "step 55900 , validation  accuracy 0.815789\n",
      "step 55900 , validation loss : 0.616413\n",
      "step 55900 , test  accuracy 0.794872\n",
      "step 55900 , test loss : 0.638388\n",
      "step 56000 , training  accuracy 1\n",
      "step 56000 , loss : 0.463319\n",
      "step 56000 , validation  accuracy 0.815789\n",
      "step 56000 , validation loss : 0.61658\n",
      "step 56000 , test  accuracy 0.769231\n",
      "step 56000 , test loss : 0.639719\n",
      "step 56100 , training  accuracy 1\n",
      "step 56100 , loss : 0.463643\n",
      "step 56100 , validation  accuracy 0.789474\n",
      "step 56100 , validation loss : 0.617076\n",
      "step 56100 , test  accuracy 0.769231\n",
      "step 56100 , test loss : 0.640898\n",
      "step 56200 , training  accuracy 1\n",
      "step 56200 , loss : 0.463441\n",
      "step 56200 , validation  accuracy 0.763158\n",
      "step 56200 , validation loss : 0.618504\n",
      "step 56200 , test  accuracy 0.717949\n",
      "step 56200 , test loss : 0.642957\n",
      "step 56300 , training  accuracy 1\n",
      "step 56300 , loss : 0.463361\n",
      "step 56300 , validation  accuracy 0.736842\n",
      "step 56300 , validation loss : 0.620251\n",
      "step 56300 , test  accuracy 0.692308\n",
      "step 56300 , test loss : 0.644231\n",
      "step 56400 , training  accuracy 1\n",
      "step 56400 , loss : 0.46338\n",
      "step 56400 , validation  accuracy 0.763158\n",
      "step 56400 , validation loss : 0.62046\n",
      "step 56400 , test  accuracy 0.692308\n",
      "step 56400 , test loss : 0.641059\n",
      "step 56500 , training  accuracy 1\n",
      "step 56500 , loss : 0.463601\n",
      "step 56500 , validation  accuracy 0.789474\n",
      "step 56500 , validation loss : 0.620287\n",
      "step 56500 , test  accuracy 0.692308\n",
      "step 56500 , test loss : 0.637967\n",
      "step 56600 , training  accuracy 1\n",
      "step 56600 , loss : 0.463349\n",
      "step 56600 , validation  accuracy 0.789474\n",
      "step 56600 , validation loss : 0.61995\n",
      "step 56600 , test  accuracy 0.74359\n",
      "step 56600 , test loss : 0.632852\n",
      "step 56700 , training  accuracy 1\n",
      "step 56700 , loss : 0.463843\n",
      "step 56700 , validation  accuracy 0.789474\n",
      "step 56700 , validation loss : 0.619567\n",
      "step 56700 , test  accuracy 0.769231\n",
      "step 56700 , test loss : 0.629199\n",
      "step 56800 , training  accuracy 1\n",
      "step 56800 , loss : 0.463368\n",
      "step 56800 , validation  accuracy 0.842105\n",
      "step 56800 , validation loss : 0.619945\n",
      "step 56800 , test  accuracy 0.769231\n",
      "step 56800 , test loss : 0.62749\n",
      "step 56900 , training  accuracy 1\n",
      "step 56900 , loss : 0.463646\n",
      "step 56900 , validation  accuracy 0.842105\n",
      "step 56900 , validation loss : 0.620758\n",
      "step 56900 , test  accuracy 0.794872\n",
      "step 56900 , test loss : 0.626762\n",
      "step 57000 , training  accuracy 1\n",
      "step 57000 , loss : 0.463648\n",
      "step 57000 , validation  accuracy 0.842105\n",
      "step 57000 , validation loss : 0.621032\n",
      "step 57000 , test  accuracy 0.794872\n",
      "step 57000 , test loss : 0.626521\n",
      "step 57100 , training  accuracy 1\n",
      "step 57100 , loss : 0.46359\n",
      "step 57100 , validation  accuracy 0.842105\n",
      "step 57100 , validation loss : 0.620978\n",
      "step 57100 , test  accuracy 0.794872\n",
      "step 57100 , test loss : 0.626701\n",
      "step 57200 , training  accuracy 1\n",
      "step 57200 , loss : 0.463421\n",
      "step 57200 , validation  accuracy 0.842105\n",
      "step 57200 , validation loss : 0.619523\n",
      "step 57200 , test  accuracy 0.794872\n",
      "step 57200 , test loss : 0.625528\n",
      "step 57300 , training  accuracy 1\n",
      "step 57300 , loss : 0.463416\n",
      "step 57300 , validation  accuracy 0.842105\n",
      "step 57300 , validation loss : 0.618627\n",
      "step 57300 , test  accuracy 0.794872\n",
      "step 57300 , test loss : 0.62462\n",
      "step 57400 , training  accuracy 1\n",
      "step 57400 , loss : 0.463665\n",
      "step 57400 , validation  accuracy 0.815789\n",
      "step 57400 , validation loss : 0.618065\n",
      "step 57400 , test  accuracy 0.820513\n",
      "step 57400 , test loss : 0.625529\n",
      "step 57500 , training  accuracy 1\n",
      "step 57500 , loss : 0.463785\n",
      "step 57500 , validation  accuracy 0.815789\n",
      "step 57500 , validation loss : 0.617847\n",
      "step 57500 , test  accuracy 0.794872\n",
      "step 57500 , test loss : 0.624734\n",
      "step 57600 , training  accuracy 1\n",
      "step 57600 , loss : 0.463854\n",
      "step 57600 , validation  accuracy 0.815789\n",
      "step 57600 , validation loss : 0.617295\n",
      "step 57600 , test  accuracy 0.794872\n",
      "step 57600 , test loss : 0.625515\n",
      "step 57700 , training  accuracy 1\n",
      "step 57700 , loss : 0.4635\n",
      "step 57700 , validation  accuracy 0.815789\n",
      "step 57700 , validation loss : 0.615677\n",
      "step 57700 , test  accuracy 0.794872\n",
      "step 57700 , test loss : 0.626379\n",
      "step 57800 , training  accuracy 1\n",
      "step 57800 , loss : 0.464265\n",
      "step 57800 , validation  accuracy 0.789474\n",
      "step 57800 , validation loss : 0.613807\n",
      "step 57800 , test  accuracy 0.820513\n",
      "step 57800 , test loss : 0.62741\n",
      "step 57900 , training  accuracy 1\n",
      "step 57900 , loss : 0.463671\n",
      "step 57900 , validation  accuracy 0.789474\n",
      "step 57900 , validation loss : 0.611843\n",
      "step 57900 , test  accuracy 0.769231\n",
      "step 57900 , test loss : 0.627759\n",
      "step 58000 , training  accuracy 1\n",
      "step 58000 , loss : 0.463547\n",
      "step 58000 , validation  accuracy 0.815789\n",
      "step 58000 , validation loss : 0.610068\n",
      "step 58000 , test  accuracy 0.794872\n",
      "step 58000 , test loss : 0.629041\n",
      "step 58100 , training  accuracy 1\n",
      "step 58100 , loss : 0.463881\n",
      "step 58100 , validation  accuracy 0.815789\n",
      "step 58100 , validation loss : 0.608787\n",
      "step 58100 , test  accuracy 0.794872\n",
      "step 58100 , test loss : 0.629231\n",
      "step 58200 , training  accuracy 1\n",
      "step 58200 , loss : 0.463473\n",
      "step 58200 , validation  accuracy 0.789474\n",
      "step 58200 , validation loss : 0.609188\n",
      "step 58200 , test  accuracy 0.769231\n",
      "step 58200 , test loss : 0.628558\n",
      "step 58300 , training  accuracy 1\n",
      "step 58300 , loss : 0.463875\n",
      "step 58300 , validation  accuracy 0.789474\n",
      "step 58300 , validation loss : 0.609832\n",
      "step 58300 , test  accuracy 0.769231\n",
      "step 58300 , test loss : 0.628442\n",
      "step 58400 , training  accuracy 1\n",
      "step 58400 , loss : 0.463849\n",
      "step 58400 , validation  accuracy 0.789474\n",
      "step 58400 , validation loss : 0.609226\n",
      "step 58400 , test  accuracy 0.769231\n",
      "step 58400 , test loss : 0.628711\n",
      "step 58500 , training  accuracy 1\n",
      "step 58500 , loss : 0.463602\n",
      "step 58500 , validation  accuracy 0.789474\n",
      "step 58500 , validation loss : 0.609181\n",
      "step 58500 , test  accuracy 0.794872\n",
      "step 58500 , test loss : 0.629738\n",
      "step 58600 , training  accuracy 1\n",
      "step 58600 , loss : 0.463636\n",
      "step 58600 , validation  accuracy 0.789474\n",
      "step 58600 , validation loss : 0.609848\n",
      "step 58600 , test  accuracy 0.794872\n",
      "step 58600 , test loss : 0.630982\n",
      "step 58700 , training  accuracy 1\n",
      "step 58700 , loss : 0.463441\n",
      "step 58700 , validation  accuracy 0.789474\n",
      "step 58700 , validation loss : 0.610154\n",
      "step 58700 , test  accuracy 0.769231\n",
      "step 58700 , test loss : 0.631772\n",
      "step 58800 , training  accuracy 1\n",
      "step 58800 , loss : 0.464566\n",
      "step 58800 , validation  accuracy 0.789474\n",
      "step 58800 , validation loss : 0.611305\n",
      "step 58800 , test  accuracy 0.794872\n",
      "step 58800 , test loss : 0.632309\n",
      "step 58900 , training  accuracy 1\n",
      "step 58900 , loss : 0.463552\n",
      "step 58900 , validation  accuracy 0.789474\n",
      "step 58900 , validation loss : 0.612581\n",
      "step 58900 , test  accuracy 0.769231\n",
      "step 58900 , test loss : 0.633013\n",
      "step 59000 , training  accuracy 1\n",
      "step 59000 , loss : 0.464152\n",
      "step 59000 , validation  accuracy 0.789474\n",
      "step 59000 , validation loss : 0.613826\n",
      "step 59000 , test  accuracy 0.769231\n",
      "step 59000 , test loss : 0.633725\n",
      "step 59100 , training  accuracy 1\n",
      "step 59100 , loss : 0.464114\n",
      "step 59100 , validation  accuracy 0.789474\n",
      "step 59100 , validation loss : 0.61597\n",
      "step 59100 , test  accuracy 0.769231\n",
      "step 59100 , test loss : 0.634177\n",
      "step 59200 , training  accuracy 1\n",
      "step 59200 , loss : 0.464397\n",
      "step 59200 , validation  accuracy 0.789474\n",
      "step 59200 , validation loss : 0.617353\n",
      "step 59200 , test  accuracy 0.769231\n",
      "step 59200 , test loss : 0.634592\n",
      "step 59300 , training  accuracy 1\n",
      "step 59300 , loss : 0.463722\n",
      "step 59300 , validation  accuracy 0.815789\n",
      "step 59300 , validation loss : 0.618344\n",
      "step 59300 , test  accuracy 0.769231\n",
      "step 59300 , test loss : 0.634687\n",
      "step 59400 , training  accuracy 1\n",
      "step 59400 , loss : 0.464292\n",
      "step 59400 , validation  accuracy 0.815789\n",
      "step 59400 , validation loss : 0.619215\n",
      "step 59400 , test  accuracy 0.769231\n",
      "step 59400 , test loss : 0.634544\n",
      "step 59500 , training  accuracy 1\n",
      "step 59500 , loss : 0.464264\n",
      "step 59500 , validation  accuracy 0.815789\n",
      "step 59500 , validation loss : 0.618096\n",
      "step 59500 , test  accuracy 0.769231\n",
      "step 59500 , test loss : 0.633923\n",
      "step 59600 , training  accuracy 1\n",
      "step 59600 , loss : 0.463315\n",
      "step 59600 , validation  accuracy 0.815789\n",
      "step 59600 , validation loss : 0.615947\n",
      "step 59600 , test  accuracy 0.769231\n",
      "step 59600 , test loss : 0.633591\n",
      "step 59700 , training  accuracy 1\n",
      "step 59700 , loss : 0.464124\n",
      "step 59700 , validation  accuracy 0.842105\n",
      "step 59700 , validation loss : 0.614666\n",
      "step 59700 , test  accuracy 0.769231\n",
      "step 59700 , test loss : 0.632761\n",
      "step 59800 , training  accuracy 1\n",
      "step 59800 , loss : 0.463545\n",
      "step 59800 , validation  accuracy 0.868421\n",
      "step 59800 , validation loss : 0.614579\n",
      "step 59800 , test  accuracy 0.74359\n",
      "step 59800 , test loss : 0.632914\n",
      "step 59900 , training  accuracy 1\n",
      "step 59900 , loss : 0.463314\n",
      "step 59900 , validation  accuracy 0.842105\n",
      "step 59900 , validation loss : 0.615288\n",
      "step 59900 , test  accuracy 0.769231\n",
      "step 59900 , test loss : 0.632617\n",
      "step 60000 , training  accuracy 1\n",
      "step 60000 , loss : 0.463287\n",
      "step 60000 , validation  accuracy 0.842105\n",
      "step 60000 , validation loss : 0.616321\n",
      "step 60000 , test  accuracy 0.794872\n",
      "step 60000 , test loss : 0.632539\n",
      "step 60100 , training  accuracy 1\n",
      "step 60100 , loss : 0.463698\n",
      "step 60100 , validation  accuracy 0.842105\n",
      "step 60100 , validation loss : 0.617202\n",
      "step 60100 , test  accuracy 0.820513\n",
      "step 60100 , test loss : 0.631981\n",
      "step 60200 , training  accuracy 1\n",
      "step 60200 , loss : 0.463329\n",
      "step 60200 , validation  accuracy 0.815789\n",
      "step 60200 , validation loss : 0.617863\n",
      "step 60200 , test  accuracy 0.820513\n",
      "step 60200 , test loss : 0.631878\n",
      "step 60300 , training  accuracy 1\n",
      "step 60300 , loss : 0.463713\n",
      "step 60300 , validation  accuracy 0.789474\n",
      "step 60300 , validation loss : 0.619611\n",
      "step 60300 , test  accuracy 0.820513\n",
      "step 60300 , test loss : 0.633615\n",
      "step 60400 , training  accuracy 1\n",
      "step 60400 , loss : 0.464939\n",
      "step 60400 , validation  accuracy 0.789474\n",
      "step 60400 , validation loss : 0.620652\n",
      "step 60400 , test  accuracy 0.794872\n",
      "step 60400 , test loss : 0.634843\n",
      "step 60500 , training  accuracy 1\n",
      "step 60500 , loss : 0.464273\n",
      "step 60500 , validation  accuracy 0.842105\n",
      "step 60500 , validation loss : 0.616754\n",
      "step 60500 , test  accuracy 0.820513\n",
      "step 60500 , test loss : 0.630475\n",
      "step 60600 , training  accuracy 1\n",
      "step 60600 , loss : 0.463375\n",
      "step 60600 , validation  accuracy 0.842105\n",
      "step 60600 , validation loss : 0.614471\n",
      "step 60600 , test  accuracy 0.794872\n",
      "step 60600 , test loss : 0.626552\n",
      "step 60700 , training  accuracy 1\n",
      "step 60700 , loss : 0.463668\n",
      "step 60700 , validation  accuracy 0.842105\n",
      "step 60700 , validation loss : 0.614799\n",
      "step 60700 , test  accuracy 0.794872\n",
      "step 60700 , test loss : 0.624014\n",
      "step 60800 , training  accuracy 1\n",
      "step 60800 , loss : 0.463383\n",
      "step 60800 , validation  accuracy 0.815789\n",
      "step 60800 , validation loss : 0.615529\n",
      "step 60800 , test  accuracy 0.820513\n",
      "step 60800 , test loss : 0.622087\n",
      "step 60900 , training  accuracy 1\n",
      "step 60900 , loss : 0.463513\n",
      "step 60900 , validation  accuracy 0.842105\n",
      "step 60900 , validation loss : 0.617614\n",
      "step 60900 , test  accuracy 0.820513\n",
      "step 60900 , test loss : 0.620149\n",
      "step 61000 , training  accuracy 1\n",
      "step 61000 , loss : 0.464009\n",
      "step 61000 , validation  accuracy 0.815789\n",
      "step 61000 , validation loss : 0.618785\n",
      "step 61000 , test  accuracy 0.820513\n",
      "step 61000 , test loss : 0.617753\n",
      "step 61100 , training  accuracy 1\n",
      "step 61100 , loss : 0.463717\n",
      "step 61100 , validation  accuracy 0.815789\n",
      "step 61100 , validation loss : 0.61639\n",
      "step 61100 , test  accuracy 0.820513\n",
      "step 61100 , test loss : 0.616129\n",
      "step 61200 , training  accuracy 1\n",
      "step 61200 , loss : 0.464509\n",
      "step 61200 , validation  accuracy 0.842105\n",
      "step 61200 , validation loss : 0.612893\n",
      "step 61200 , test  accuracy 0.820513\n",
      "step 61200 , test loss : 0.615251\n",
      "step 61300 , training  accuracy 1\n",
      "step 61300 , loss : 0.463634\n",
      "step 61300 , validation  accuracy 0.815789\n",
      "step 61300 , validation loss : 0.609753\n",
      "step 61300 , test  accuracy 0.820513\n",
      "step 61300 , test loss : 0.617434\n",
      "step 61400 , training  accuracy 1\n",
      "step 61400 , loss : 0.463745\n",
      "step 61400 , validation  accuracy 0.815789\n",
      "step 61400 , validation loss : 0.608721\n",
      "step 61400 , test  accuracy 0.794872\n",
      "step 61400 , test loss : 0.62062\n",
      "step 61500 , training  accuracy 1\n",
      "step 61500 , loss : 0.463699\n",
      "step 61500 , validation  accuracy 0.815789\n",
      "step 61500 , validation loss : 0.611655\n",
      "step 61500 , test  accuracy 0.794872\n",
      "step 61500 , test loss : 0.624636\n",
      "step 61600 , training  accuracy 1\n",
      "step 61600 , loss : 0.46355\n",
      "step 61600 , validation  accuracy 0.815789\n",
      "step 61600 , validation loss : 0.616385\n",
      "step 61600 , test  accuracy 0.769231\n",
      "step 61600 , test loss : 0.628166\n",
      "step 61700 , training  accuracy 1\n",
      "step 61700 , loss : 0.463549\n",
      "step 61700 , validation  accuracy 0.815789\n",
      "step 61700 , validation loss : 0.620398\n",
      "step 61700 , test  accuracy 0.769231\n",
      "step 61700 , test loss : 0.63351\n",
      "step 61800 , training  accuracy 1\n",
      "step 61800 , loss : 0.463084\n",
      "step 61800 , validation  accuracy 0.763158\n",
      "step 61800 , validation loss : 0.625105\n",
      "step 61800 , test  accuracy 0.692308\n",
      "step 61800 , test loss : 0.6387\n",
      "step 61900 , training  accuracy 1\n",
      "step 61900 , loss : 0.463836\n",
      "step 61900 , validation  accuracy 0.736842\n",
      "step 61900 , validation loss : 0.627428\n",
      "step 61900 , test  accuracy 0.692308\n",
      "step 61900 , test loss : 0.64308\n",
      "step 62000 , training  accuracy 1\n",
      "step 62000 , loss : 0.463922\n",
      "step 62000 , validation  accuracy 0.736842\n",
      "step 62000 , validation loss : 0.627981\n",
      "step 62000 , test  accuracy 0.666667\n",
      "step 62000 , test loss : 0.644144\n",
      "step 62100 , training  accuracy 1\n",
      "step 62100 , loss : 0.465121\n",
      "step 62100 , validation  accuracy 0.763158\n",
      "step 62100 , validation loss : 0.626478\n",
      "step 62100 , test  accuracy 0.641026\n",
      "step 62100 , test loss : 0.642189\n",
      "step 62200 , training  accuracy 1\n",
      "step 62200 , loss : 0.463458\n",
      "step 62200 , validation  accuracy 0.815789\n",
      "step 62200 , validation loss : 0.622445\n",
      "step 62200 , test  accuracy 0.74359\n",
      "step 62200 , test loss : 0.634493\n",
      "step 62300 , training  accuracy 1\n",
      "step 62300 , loss : 0.463767\n",
      "step 62300 , validation  accuracy 0.815789\n",
      "step 62300 , validation loss : 0.618979\n",
      "step 62300 , test  accuracy 0.74359\n",
      "step 62300 , test loss : 0.629998\n",
      "step 62400 , training  accuracy 1\n",
      "step 62400 , loss : 0.463034\n",
      "step 62400 , validation  accuracy 0.815789\n",
      "step 62400 , validation loss : 0.616019\n",
      "step 62400 , test  accuracy 0.794872\n",
      "step 62400 , test loss : 0.626797\n",
      "step 62500 , training  accuracy 1\n",
      "step 62500 , loss : 0.4634\n",
      "step 62500 , validation  accuracy 0.815789\n",
      "step 62500 , validation loss : 0.614349\n",
      "step 62500 , test  accuracy 0.820513\n",
      "step 62500 , test loss : 0.624993\n",
      "step 62600 , training  accuracy 1\n",
      "step 62600 , loss : 0.463353\n",
      "step 62600 , validation  accuracy 0.815789\n",
      "step 62600 , validation loss : 0.61317\n",
      "step 62600 , test  accuracy 0.820513\n",
      "step 62600 , test loss : 0.623002\n",
      "step 62700 , training  accuracy 1\n",
      "step 62700 , loss : 0.4632\n",
      "step 62700 , validation  accuracy 0.815789\n",
      "step 62700 , validation loss : 0.61119\n",
      "step 62700 , test  accuracy 0.820513\n",
      "step 62700 , test loss : 0.621852\n",
      "step 62800 , training  accuracy 1\n",
      "step 62800 , loss : 0.463524\n",
      "step 62800 , validation  accuracy 0.815789\n",
      "step 62800 , validation loss : 0.609906\n",
      "step 62800 , test  accuracy 0.820513\n",
      "step 62800 , test loss : 0.621824\n",
      "step 62900 , training  accuracy 1\n",
      "step 62900 , loss : 0.463211\n",
      "step 62900 , validation  accuracy 0.815789\n",
      "step 62900 , validation loss : 0.608873\n",
      "step 62900 , test  accuracy 0.820513\n",
      "step 62900 , test loss : 0.62213\n",
      "step 63000 , training  accuracy 1\n",
      "step 63000 , loss : 0.463846\n",
      "step 63000 , validation  accuracy 0.815789\n",
      "step 63000 , validation loss : 0.606541\n",
      "step 63000 , test  accuracy 0.820513\n",
      "step 63000 , test loss : 0.623088\n",
      "step 63100 , training  accuracy 1\n",
      "step 63100 , loss : 0.463038\n",
      "step 63100 , validation  accuracy 0.815789\n",
      "step 63100 , validation loss : 0.605597\n",
      "step 63100 , test  accuracy 0.820513\n",
      "step 63100 , test loss : 0.623676\n",
      "step 63200 , training  accuracy 1\n",
      "step 63200 , loss : 0.463324\n",
      "step 63200 , validation  accuracy 0.815789\n",
      "step 63200 , validation loss : 0.60563\n",
      "step 63200 , test  accuracy 0.820513\n",
      "step 63200 , test loss : 0.624083\n",
      "step 63300 , training  accuracy 1\n",
      "step 63300 , loss : 0.463205\n",
      "step 63300 , validation  accuracy 0.815789\n",
      "step 63300 , validation loss : 0.604139\n",
      "step 63300 , test  accuracy 0.820513\n",
      "step 63300 , test loss : 0.625666\n",
      "step 63400 , training  accuracy 1\n",
      "step 63400 , loss : 0.462968\n",
      "step 63400 , validation  accuracy 0.815789\n",
      "step 63400 , validation loss : 0.602965\n",
      "step 63400 , test  accuracy 0.820513\n",
      "step 63400 , test loss : 0.627416\n",
      "step 63500 , training  accuracy 1\n",
      "step 63500 , loss : 0.463382\n",
      "step 63500 , validation  accuracy 0.815789\n",
      "step 63500 , validation loss : 0.602834\n",
      "step 63500 , test  accuracy 0.820513\n",
      "step 63500 , test loss : 0.628504\n",
      "step 63600 , training  accuracy 1\n",
      "step 63600 , loss : 0.463964\n",
      "step 63600 , validation  accuracy 0.815789\n",
      "step 63600 , validation loss : 0.605316\n",
      "step 63600 , test  accuracy 0.820513\n",
      "step 63600 , test loss : 0.630092\n",
      "step 63700 , training  accuracy 1\n",
      "step 63700 , loss : 0.463427\n",
      "step 63700 , validation  accuracy 0.815789\n",
      "step 63700 , validation loss : 0.607739\n",
      "step 63700 , test  accuracy 0.794872\n",
      "step 63700 , test loss : 0.631026\n",
      "step 63800 , training  accuracy 1\n",
      "step 63800 , loss : 0.464061\n",
      "step 63800 , validation  accuracy 0.842105\n",
      "step 63800 , validation loss : 0.609235\n",
      "step 63800 , test  accuracy 0.794872\n",
      "step 63800 , test loss : 0.630456\n",
      "step 63900 , training  accuracy 1\n",
      "step 63900 , loss : 0.463709\n",
      "step 63900 , validation  accuracy 0.815789\n",
      "step 63900 , validation loss : 0.610136\n",
      "step 63900 , test  accuracy 0.820513\n",
      "step 63900 , test loss : 0.629299\n",
      "step 64000 , training  accuracy 1\n",
      "step 64000 , loss : 0.464241\n",
      "step 64000 , validation  accuracy 0.789474\n",
      "step 64000 , validation loss : 0.611667\n",
      "step 64000 , test  accuracy 0.769231\n",
      "step 64000 , test loss : 0.628627\n",
      "step 64100 , training  accuracy 1\n",
      "step 64100 , loss : 0.463608\n",
      "step 64100 , validation  accuracy 0.789474\n",
      "step 64100 , validation loss : 0.614044\n",
      "step 64100 , test  accuracy 0.769231\n",
      "step 64100 , test loss : 0.629488\n",
      "step 64200 , training  accuracy 1\n",
      "step 64200 , loss : 0.463553\n",
      "step 64200 , validation  accuracy 0.789474\n",
      "step 64200 , validation loss : 0.615942\n",
      "step 64200 , test  accuracy 0.769231\n",
      "step 64200 , test loss : 0.630988\n",
      "step 64300 , training  accuracy 1\n",
      "step 64300 , loss : 0.463683\n",
      "step 64300 , validation  accuracy 0.789474\n",
      "step 64300 , validation loss : 0.616866\n",
      "step 64300 , test  accuracy 0.769231\n",
      "step 64300 , test loss : 0.630954\n",
      "step 64400 , training  accuracy 1\n",
      "step 64400 , loss : 0.463545\n",
      "step 64400 , validation  accuracy 0.789474\n",
      "step 64400 , validation loss : 0.61653\n",
      "step 64400 , test  accuracy 0.769231\n",
      "step 64400 , test loss : 0.630167\n",
      "step 64500 , training  accuracy 1\n",
      "step 64500 , loss : 0.463292\n",
      "step 64500 , validation  accuracy 0.789474\n",
      "step 64500 , validation loss : 0.614241\n",
      "step 64500 , test  accuracy 0.769231\n",
      "step 64500 , test loss : 0.628243\n",
      "step 64600 , training  accuracy 1\n",
      "step 64600 , loss : 0.463235\n",
      "step 64600 , validation  accuracy 0.815789\n",
      "step 64600 , validation loss : 0.612551\n",
      "step 64600 , test  accuracy 0.820513\n",
      "step 64600 , test loss : 0.627407\n",
      "step 64700 , training  accuracy 1\n",
      "step 64700 , loss : 0.462886\n",
      "step 64700 , validation  accuracy 0.815789\n",
      "step 64700 , validation loss : 0.612233\n",
      "step 64700 , test  accuracy 0.820513\n",
      "step 64700 , test loss : 0.626928\n",
      "step 64800 , training  accuracy 1\n",
      "step 64800 , loss : 0.463092\n",
      "step 64800 , validation  accuracy 0.815789\n",
      "step 64800 , validation loss : 0.612248\n",
      "step 64800 , test  accuracy 0.820513\n",
      "step 64800 , test loss : 0.626764\n",
      "step 64900 , training  accuracy 1\n",
      "step 64900 , loss : 0.463021\n",
      "step 64900 , validation  accuracy 0.815789\n",
      "step 64900 , validation loss : 0.61207\n",
      "step 64900 , test  accuracy 0.820513\n",
      "step 64900 , test loss : 0.62667\n",
      "step 65000 , training  accuracy 1\n",
      "step 65000 , loss : 0.463324\n",
      "step 65000 , validation  accuracy 0.815789\n",
      "step 65000 , validation loss : 0.611645\n",
      "step 65000 , test  accuracy 0.820513\n",
      "step 65000 , test loss : 0.626718\n",
      "step 65100 , training  accuracy 1\n",
      "step 65100 , loss : 0.463234\n",
      "step 65100 , validation  accuracy 0.815789\n",
      "step 65100 , validation loss : 0.611321\n",
      "step 65100 , test  accuracy 0.820513\n",
      "step 65100 , test loss : 0.626573\n",
      "step 65200 , training  accuracy 1\n",
      "step 65200 , loss : 0.463665\n",
      "step 65200 , validation  accuracy 0.815789\n",
      "step 65200 , validation loss : 0.611709\n",
      "step 65200 , test  accuracy 0.820513\n",
      "step 65200 , test loss : 0.625975\n",
      "step 65300 , training  accuracy 1\n",
      "step 65300 , loss : 0.463193\n",
      "step 65300 , validation  accuracy 0.789474\n",
      "step 65300 , validation loss : 0.612786\n",
      "step 65300 , test  accuracy 0.820513\n",
      "step 65300 , test loss : 0.625408\n",
      "step 65400 , training  accuracy 1\n",
      "step 65400 , loss : 0.464087\n",
      "step 65400 , validation  accuracy 0.789474\n",
      "step 65400 , validation loss : 0.613591\n",
      "step 65400 , test  accuracy 0.820513\n",
      "step 65400 , test loss : 0.625329\n",
      "step 65500 , training  accuracy 1\n",
      "step 65500 , loss : 0.463399\n",
      "step 65500 , validation  accuracy 0.789474\n",
      "step 65500 , validation loss : 0.614161\n",
      "step 65500 , test  accuracy 0.820513\n",
      "step 65500 , test loss : 0.625573\n",
      "step 65600 , training  accuracy 1\n",
      "step 65600 , loss : 0.463669\n",
      "step 65600 , validation  accuracy 0.763158\n",
      "step 65600 , validation loss : 0.614778\n",
      "step 65600 , test  accuracy 0.820513\n",
      "step 65600 , test loss : 0.625781\n",
      "step 65700 , training  accuracy 1\n",
      "step 65700 , loss : 0.463708\n",
      "step 65700 , validation  accuracy 0.763158\n",
      "step 65700 , validation loss : 0.614803\n",
      "step 65700 , test  accuracy 0.794872\n",
      "step 65700 , test loss : 0.62608\n",
      "step 65800 , training  accuracy 1\n",
      "step 65800 , loss : 0.463529\n",
      "step 65800 , validation  accuracy 0.789474\n",
      "step 65800 , validation loss : 0.614551\n",
      "step 65800 , test  accuracy 0.794872\n",
      "step 65800 , test loss : 0.626751\n",
      "step 65900 , training  accuracy 1\n",
      "step 65900 , loss : 0.464363\n",
      "step 65900 , validation  accuracy 0.789474\n",
      "step 65900 , validation loss : 0.614928\n",
      "step 65900 , test  accuracy 0.794872\n",
      "step 65900 , test loss : 0.627706\n",
      "step 66000 , training  accuracy 1\n",
      "step 66000 , loss : 0.463506\n",
      "step 66000 , validation  accuracy 0.815789\n",
      "step 66000 , validation loss : 0.614959\n",
      "step 66000 , test  accuracy 0.794872\n",
      "step 66000 , test loss : 0.628973\n",
      "step 66100 , training  accuracy 1\n",
      "step 66100 , loss : 0.463438\n",
      "step 66100 , validation  accuracy 0.815789\n",
      "step 66100 , validation loss : 0.61443\n",
      "step 66100 , test  accuracy 0.794872\n",
      "step 66100 , test loss : 0.629771\n",
      "step 66200 , training  accuracy 1\n",
      "step 66200 , loss : 0.463698\n",
      "step 66200 , validation  accuracy 0.815789\n",
      "step 66200 , validation loss : 0.614218\n",
      "step 66200 , test  accuracy 0.794872\n",
      "step 66200 , test loss : 0.630646\n",
      "step 66300 , training  accuracy 1\n",
      "step 66300 , loss : 0.463584\n",
      "step 66300 , validation  accuracy 0.815789\n",
      "step 66300 , validation loss : 0.614429\n",
      "step 66300 , test  accuracy 0.794872\n",
      "step 66300 , test loss : 0.631352\n",
      "step 66400 , training  accuracy 1\n",
      "step 66400 , loss : 0.46359\n",
      "step 66400 , validation  accuracy 0.815789\n",
      "step 66400 , validation loss : 0.615303\n",
      "step 66400 , test  accuracy 0.794872\n",
      "step 66400 , test loss : 0.631791\n",
      "step 66500 , training  accuracy 1\n",
      "step 66500 , loss : 0.463062\n",
      "step 66500 , validation  accuracy 0.815789\n",
      "step 66500 , validation loss : 0.615708\n",
      "step 66500 , test  accuracy 0.794872\n",
      "step 66500 , test loss : 0.632203\n",
      "step 66600 , training  accuracy 1\n",
      "step 66600 , loss : 0.463413\n",
      "step 66600 , validation  accuracy 0.815789\n",
      "step 66600 , validation loss : 0.616487\n",
      "step 66600 , test  accuracy 0.794872\n",
      "step 66600 , test loss : 0.632836\n",
      "step 66700 , training  accuracy 1\n",
      "step 66700 , loss : 0.463295\n",
      "step 66700 , validation  accuracy 0.815789\n",
      "step 66700 , validation loss : 0.616546\n",
      "step 66700 , test  accuracy 0.794872\n",
      "step 66700 , test loss : 0.633118\n",
      "step 66800 , training  accuracy 1\n",
      "step 66800 , loss : 0.462956\n",
      "step 66800 , validation  accuracy 0.815789\n",
      "step 66800 , validation loss : 0.616396\n",
      "step 66800 , test  accuracy 0.794872\n",
      "step 66800 , test loss : 0.633596\n",
      "step 66900 , training  accuracy 1\n",
      "step 66900 , loss : 0.462965\n",
      "step 66900 , validation  accuracy 0.815789\n",
      "step 66900 , validation loss : 0.616633\n",
      "step 66900 , test  accuracy 0.794872\n",
      "step 66900 , test loss : 0.634351\n",
      "step 67000 , training  accuracy 1\n",
      "step 67000 , loss : 0.463112\n",
      "step 67000 , validation  accuracy 0.815789\n",
      "step 67000 , validation loss : 0.616153\n",
      "step 67000 , test  accuracy 0.820513\n",
      "step 67000 , test loss : 0.635032\n",
      "step 67100 , training  accuracy 1\n",
      "step 67100 , loss : 0.4631\n",
      "step 67100 , validation  accuracy 0.815789\n",
      "step 67100 , validation loss : 0.615422\n",
      "step 67100 , test  accuracy 0.820513\n",
      "step 67100 , test loss : 0.63579\n",
      "step 67200 , training  accuracy 1\n",
      "step 67200 , loss : 0.463165\n",
      "step 67200 , validation  accuracy 0.815789\n",
      "step 67200 , validation loss : 0.614183\n",
      "step 67200 , test  accuracy 0.820513\n",
      "step 67200 , test loss : 0.6351\n",
      "step 67300 , training  accuracy 1\n",
      "step 67300 , loss : 0.463211\n",
      "step 67300 , validation  accuracy 0.815789\n",
      "step 67300 , validation loss : 0.613509\n",
      "step 67300 , test  accuracy 0.820513\n",
      "step 67300 , test loss : 0.634297\n",
      "step 67400 , training  accuracy 1\n",
      "step 67400 , loss : 0.463291\n",
      "step 67400 , validation  accuracy 0.789474\n",
      "step 67400 , validation loss : 0.613216\n",
      "step 67400 , test  accuracy 0.820513\n",
      "step 67400 , test loss : 0.634429\n",
      "step 67500 , training  accuracy 1\n",
      "step 67500 , loss : 0.463202\n",
      "step 67500 , validation  accuracy 0.789474\n",
      "step 67500 , validation loss : 0.612651\n",
      "step 67500 , test  accuracy 0.820513\n",
      "step 67500 , test loss : 0.634188\n",
      "step 67600 , training  accuracy 1\n",
      "step 67600 , loss : 0.462874\n",
      "step 67600 , validation  accuracy 0.789474\n",
      "step 67600 , validation loss : 0.612421\n",
      "step 67600 , test  accuracy 0.820513\n",
      "step 67600 , test loss : 0.633983\n",
      "step 67700 , training  accuracy 1\n",
      "step 67700 , loss : 0.463674\n",
      "step 67700 , validation  accuracy 0.789474\n",
      "step 67700 , validation loss : 0.61219\n",
      "step 67700 , test  accuracy 0.820513\n",
      "step 67700 , test loss : 0.633601\n",
      "step 67800 , training  accuracy 1\n",
      "step 67800 , loss : 0.463203\n",
      "step 67800 , validation  accuracy 0.789474\n",
      "step 67800 , validation loss : 0.612276\n",
      "step 67800 , test  accuracy 0.794872\n",
      "step 67800 , test loss : 0.634192\n",
      "step 67900 , training  accuracy 1\n",
      "step 67900 , loss : 0.464669\n",
      "step 67900 , validation  accuracy 0.789474\n",
      "step 67900 , validation loss : 0.613096\n",
      "step 67900 , test  accuracy 0.794872\n",
      "step 67900 , test loss : 0.634609\n",
      "step 68000 , training  accuracy 1\n",
      "step 68000 , loss : 0.463419\n",
      "step 68000 , validation  accuracy 0.789474\n",
      "step 68000 , validation loss : 0.612941\n",
      "step 68000 , test  accuracy 0.769231\n",
      "step 68000 , test loss : 0.634946\n",
      "step 68100 , training  accuracy 1\n",
      "step 68100 , loss : 0.463129\n",
      "step 68100 , validation  accuracy 0.789474\n",
      "step 68100 , validation loss : 0.612805\n",
      "step 68100 , test  accuracy 0.769231\n",
      "step 68100 , test loss : 0.635671\n",
      "step 68200 , training  accuracy 1\n",
      "step 68200 , loss : 0.463279\n",
      "step 68200 , validation  accuracy 0.815789\n",
      "step 68200 , validation loss : 0.611841\n",
      "step 68200 , test  accuracy 0.769231\n",
      "step 68200 , test loss : 0.636112\n",
      "step 68300 , training  accuracy 1\n",
      "step 68300 , loss : 0.463319\n",
      "step 68300 , validation  accuracy 0.815789\n",
      "step 68300 , validation loss : 0.610545\n",
      "step 68300 , test  accuracy 0.769231\n",
      "step 68300 , test loss : 0.635317\n",
      "step 68400 , training  accuracy 1\n",
      "step 68400 , loss : 0.463233\n",
      "step 68400 , validation  accuracy 0.815789\n",
      "step 68400 , validation loss : 0.608913\n",
      "step 68400 , test  accuracy 0.769231\n",
      "step 68400 , test loss : 0.63344\n",
      "step 68500 , training  accuracy 1\n",
      "step 68500 , loss : 0.463347\n",
      "step 68500 , validation  accuracy 0.815789\n",
      "step 68500 , validation loss : 0.607912\n",
      "step 68500 , test  accuracy 0.769231\n",
      "step 68500 , test loss : 0.631575\n",
      "step 68600 , training  accuracy 1\n",
      "step 68600 , loss : 0.463346\n",
      "step 68600 , validation  accuracy 0.815789\n",
      "step 68600 , validation loss : 0.608367\n",
      "step 68600 , test  accuracy 0.769231\n",
      "step 68600 , test loss : 0.629931\n",
      "step 68700 , training  accuracy 1\n",
      "step 68700 , loss : 0.463087\n",
      "step 68700 , validation  accuracy 0.815789\n",
      "step 68700 , validation loss : 0.608294\n",
      "step 68700 , test  accuracy 0.769231\n",
      "step 68700 , test loss : 0.6285\n",
      "step 68800 , training  accuracy 1\n",
      "step 68800 , loss : 0.463673\n",
      "step 68800 , validation  accuracy 0.789474\n",
      "step 68800 , validation loss : 0.608902\n",
      "step 68800 , test  accuracy 0.794872\n",
      "step 68800 , test loss : 0.627385\n",
      "step 68900 , training  accuracy 1\n",
      "step 68900 , loss : 0.464127\n",
      "step 68900 , validation  accuracy 0.789474\n",
      "step 68900 , validation loss : 0.608275\n",
      "step 68900 , test  accuracy 0.794872\n",
      "step 68900 , test loss : 0.625284\n",
      "step 69000 , training  accuracy 1\n",
      "step 69000 , loss : 0.463469\n",
      "step 69000 , validation  accuracy 0.789474\n",
      "step 69000 , validation loss : 0.607013\n",
      "step 69000 , test  accuracy 0.794872\n",
      "step 69000 , test loss : 0.623127\n",
      "step 69100 , training  accuracy 1\n",
      "step 69100 , loss : 0.46331\n",
      "step 69100 , validation  accuracy 0.789474\n",
      "step 69100 , validation loss : 0.605518\n",
      "step 69100 , test  accuracy 0.794872\n",
      "step 69100 , test loss : 0.621001\n",
      "step 69200 , training  accuracy 1\n",
      "step 69200 , loss : 0.463296\n",
      "step 69200 , validation  accuracy 0.815789\n",
      "step 69200 , validation loss : 0.604279\n",
      "step 69200 , test  accuracy 0.820513\n",
      "step 69200 , test loss : 0.619293\n",
      "a\n",
      "step 69300 , training  accuracy 1\n",
      "step 69300 , loss : 0.463463\n",
      "step 69300 , validation  accuracy 0.868421\n",
      "step 69300 , validation loss : 0.603103\n",
      "step 69300 , test  accuracy 0.820513\n",
      "step 69300 , test loss : 0.617692\n",
      "step 69400 , training  accuracy 1\n",
      "step 69400 , loss : 0.463756\n",
      "step 69400 , validation  accuracy 0.868421\n",
      "step 69400 , validation loss : 0.602366\n",
      "step 69400 , test  accuracy 0.820513\n",
      "step 69400 , test loss : 0.616562\n",
      "step 69500 , training  accuracy 1\n",
      "step 69500 , loss : 0.46363\n",
      "step 69500 , validation  accuracy 0.842105\n",
      "step 69500 , validation loss : 0.602542\n",
      "step 69500 , test  accuracy 0.820513\n",
      "step 69500 , test loss : 0.615413\n",
      "step 69600 , training  accuracy 1\n",
      "step 69600 , loss : 0.463655\n",
      "step 69600 , validation  accuracy 0.842105\n",
      "step 69600 , validation loss : 0.602768\n",
      "step 69600 , test  accuracy 0.820513\n",
      "step 69600 , test loss : 0.614418\n",
      "step 69700 , training  accuracy 1\n",
      "step 69700 , loss : 0.463795\n",
      "step 69700 , validation  accuracy 0.842105\n",
      "step 69700 , validation loss : 0.602622\n",
      "step 69700 , test  accuracy 0.820513\n",
      "step 69700 , test loss : 0.61406\n",
      "step 69800 , training  accuracy 1\n",
      "step 69800 , loss : 0.463753\n",
      "step 69800 , validation  accuracy 0.842105\n",
      "step 69800 , validation loss : 0.602939\n",
      "step 69800 , test  accuracy 0.820513\n",
      "step 69800 , test loss : 0.613833\n",
      "step 69900 , training  accuracy 1\n",
      "step 69900 , loss : 0.463778\n",
      "step 69900 , validation  accuracy 0.842105\n",
      "step 69900 , validation loss : 0.603432\n",
      "step 69900 , test  accuracy 0.820513\n",
      "step 69900 , test loss : 0.613843\n",
      "step 70000 , training  accuracy 1\n",
      "step 70000 , loss : 0.464337\n",
      "step 70000 , validation  accuracy 0.815789\n",
      "step 70000 , validation loss : 0.604966\n",
      "step 70000 , test  accuracy 0.820513\n",
      "step 70000 , test loss : 0.614016\n",
      "step 70100 , training  accuracy 1\n",
      "step 70100 , loss : 0.464252\n",
      "step 70100 , validation  accuracy 0.789474\n",
      "step 70100 , validation loss : 0.607\n",
      "step 70100 , test  accuracy 0.820513\n",
      "step 70100 , test loss : 0.614771\n",
      "step 70200 , training  accuracy 1\n",
      "step 70200 , loss : 0.463918\n",
      "step 70200 , validation  accuracy 0.789474\n",
      "step 70200 , validation loss : 0.608187\n",
      "step 70200 , test  accuracy 0.820513\n",
      "step 70200 , test loss : 0.614702\n",
      "step 70300 , training  accuracy 1\n",
      "step 70300 , loss : 0.463859\n",
      "step 70300 , validation  accuracy 0.789474\n",
      "step 70300 , validation loss : 0.608698\n",
      "step 70300 , test  accuracy 0.820513\n",
      "step 70300 , test loss : 0.614864\n",
      "step 70400 , training  accuracy 1\n",
      "step 70400 , loss : 0.463767\n",
      "step 70400 , validation  accuracy 0.789474\n",
      "step 70400 , validation loss : 0.608524\n",
      "step 70400 , test  accuracy 0.820513\n",
      "step 70400 , test loss : 0.615985\n",
      "step 70500 , training  accuracy 1\n",
      "step 70500 , loss : 0.463289\n",
      "step 70500 , validation  accuracy 0.789474\n",
      "step 70500 , validation loss : 0.607783\n",
      "step 70500 , test  accuracy 0.820513\n",
      "step 70500 , test loss : 0.616666\n",
      "step 70600 , training  accuracy 1\n",
      "step 70600 , loss : 0.463115\n",
      "step 70600 , validation  accuracy 0.815789\n",
      "step 70600 , validation loss : 0.606947\n",
      "step 70600 , test  accuracy 0.820513\n",
      "step 70600 , test loss : 0.617116\n",
      "step 70700 , training  accuracy 1\n",
      "step 70700 , loss : 0.462817\n",
      "step 70700 , validation  accuracy 0.815789\n",
      "step 70700 , validation loss : 0.607224\n",
      "step 70700 , test  accuracy 0.820513\n",
      "step 70700 , test loss : 0.61844\n",
      "step 70800 , training  accuracy 1\n",
      "step 70800 , loss : 0.462903\n",
      "step 70800 , validation  accuracy 0.815789\n",
      "step 70800 , validation loss : 0.607614\n",
      "step 70800 , test  accuracy 0.820513\n",
      "step 70800 , test loss : 0.62034\n",
      "step 70900 , training  accuracy 1\n",
      "step 70900 , loss : 0.463095\n",
      "step 70900 , validation  accuracy 0.815789\n",
      "step 70900 , validation loss : 0.607699\n",
      "step 70900 , test  accuracy 0.794872\n",
      "step 70900 , test loss : 0.621306\n",
      "step 71000 , training  accuracy 1\n",
      "step 71000 , loss : 0.463539\n",
      "step 71000 , validation  accuracy 0.789474\n",
      "step 71000 , validation loss : 0.608341\n",
      "step 71000 , test  accuracy 0.794872\n",
      "step 71000 , test loss : 0.622762\n",
      "step 71100 , training  accuracy 1\n",
      "step 71100 , loss : 0.463019\n",
      "step 71100 , validation  accuracy 0.789474\n",
      "step 71100 , validation loss : 0.608917\n",
      "step 71100 , test  accuracy 0.794872\n",
      "step 71100 , test loss : 0.62395\n",
      "step 71200 , training  accuracy 1\n",
      "step 71200 , loss : 0.463144\n",
      "step 71200 , validation  accuracy 0.789474\n",
      "step 71200 , validation loss : 0.608813\n",
      "step 71200 , test  accuracy 0.794872\n",
      "step 71200 , test loss : 0.624685\n",
      "step 71300 , training  accuracy 1\n",
      "step 71300 , loss : 0.463114\n",
      "step 71300 , validation  accuracy 0.789474\n",
      "step 71300 , validation loss : 0.608351\n",
      "step 71300 , test  accuracy 0.794872\n",
      "step 71300 , test loss : 0.625709\n",
      "step 71400 , training  accuracy 1\n",
      "step 71400 , loss : 0.463077\n",
      "step 71400 , validation  accuracy 0.789474\n",
      "step 71400 , validation loss : 0.608351\n",
      "step 71400 , test  accuracy 0.794872\n",
      "step 71400 , test loss : 0.627759\n",
      "step 71500 , training  accuracy 1\n",
      "step 71500 , loss : 0.462988\n",
      "step 71500 , validation  accuracy 0.789474\n",
      "step 71500 , validation loss : 0.608395\n",
      "step 71500 , test  accuracy 0.769231\n",
      "step 71500 , test loss : 0.629346\n",
      "step 71600 , training  accuracy 1\n",
      "step 71600 , loss : 0.463152\n",
      "step 71600 , validation  accuracy 0.815789\n",
      "step 71600 , validation loss : 0.608721\n",
      "step 71600 , test  accuracy 0.769231\n",
      "step 71600 , test loss : 0.631438\n",
      "step 71700 , training  accuracy 1\n",
      "step 71700 , loss : 0.46315\n",
      "step 71700 , validation  accuracy 0.789474\n",
      "step 71700 , validation loss : 0.607672\n",
      "step 71700 , test  accuracy 0.794872\n",
      "step 71700 , test loss : 0.630406\n",
      "step 71800 , training  accuracy 1\n",
      "step 71800 , loss : 0.463209\n",
      "step 71800 , validation  accuracy 0.789474\n",
      "step 71800 , validation loss : 0.606664\n",
      "step 71800 , test  accuracy 0.794872\n",
      "step 71800 , test loss : 0.628404\n",
      "step 71900 , training  accuracy 1\n",
      "step 71900 , loss : 0.463226\n",
      "step 71900 , validation  accuracy 0.789474\n",
      "step 71900 , validation loss : 0.605332\n",
      "step 71900 , test  accuracy 0.794872\n",
      "step 71900 , test loss : 0.62615\n",
      "step 72000 , training  accuracy 1\n",
      "step 72000 , loss : 0.46321\n",
      "step 72000 , validation  accuracy 0.789474\n",
      "step 72000 , validation loss : 0.604409\n",
      "step 72000 , test  accuracy 0.794872\n",
      "step 72000 , test loss : 0.623563\n",
      "step 72100 , training  accuracy 1\n",
      "step 72100 , loss : 0.463779\n",
      "step 72100 , validation  accuracy 0.789474\n",
      "step 72100 , validation loss : 0.603693\n",
      "step 72100 , test  accuracy 0.820513\n",
      "step 72100 , test loss : 0.621685\n",
      "step 72200 , training  accuracy 1\n",
      "step 72200 , loss : 0.463818\n",
      "step 72200 , validation  accuracy 0.815789\n",
      "step 72200 , validation loss : 0.602166\n",
      "step 72200 , test  accuracy 0.820513\n",
      "step 72200 , test loss : 0.621045\n",
      "step 72300 , training  accuracy 1\n",
      "step 72300 , loss : 0.464051\n",
      "step 72300 , validation  accuracy 0.842105\n",
      "step 72300 , validation loss : 0.601294\n",
      "step 72300 , test  accuracy 0.820513\n",
      "step 72300 , test loss : 0.619593\n",
      "step 72400 , training  accuracy 1\n",
      "step 72400 , loss : 0.463895\n",
      "step 72400 , validation  accuracy 0.815789\n",
      "step 72400 , validation loss : 0.601816\n",
      "step 72400 , test  accuracy 0.820513\n",
      "step 72400 , test loss : 0.617447\n",
      "step 72500 , training  accuracy 1\n",
      "step 72500 , loss : 0.463556\n",
      "step 72500 , validation  accuracy 0.815789\n",
      "step 72500 , validation loss : 0.601887\n",
      "step 72500 , test  accuracy 0.820513\n",
      "step 72500 , test loss : 0.61655\n",
      "step 72600 , training  accuracy 1\n",
      "step 72600 , loss : 0.463676\n",
      "step 72600 , validation  accuracy 0.815789\n",
      "step 72600 , validation loss : 0.601503\n",
      "step 72600 , test  accuracy 0.820513\n",
      "step 72600 , test loss : 0.616318\n",
      "step 72700 , training  accuracy 1\n",
      "step 72700 , loss : 0.463713\n",
      "step 72700 , validation  accuracy 0.815789\n",
      "step 72700 , validation loss : 0.601114\n",
      "step 72700 , test  accuracy 0.820513\n",
      "step 72700 , test loss : 0.616465\n",
      "step 72800 , training  accuracy 1\n",
      "step 72800 , loss : 0.463534\n",
      "step 72800 , validation  accuracy 0.815789\n",
      "step 72800 , validation loss : 0.60117\n",
      "step 72800 , test  accuracy 0.820513\n",
      "step 72800 , test loss : 0.616449\n",
      "step 72900 , training  accuracy 1\n",
      "step 72900 , loss : 0.463612\n",
      "step 72900 , validation  accuracy 0.842105\n",
      "step 72900 , validation loss : 0.601081\n",
      "step 72900 , test  accuracy 0.820513\n",
      "step 72900 , test loss : 0.617228\n",
      "step 73000 , training  accuracy 1\n",
      "step 73000 , loss : 0.463385\n",
      "step 73000 , validation  accuracy 0.815789\n",
      "step 73000 , validation loss : 0.60133\n",
      "step 73000 , test  accuracy 0.820513\n",
      "step 73000 , test loss : 0.617984\n",
      "step 73100 , training  accuracy 1\n",
      "step 73100 , loss : 0.4633\n",
      "step 73100 , validation  accuracy 0.815789\n",
      "step 73100 , validation loss : 0.602196\n",
      "step 73100 , test  accuracy 0.820513\n",
      "step 73100 , test loss : 0.617969\n",
      "step 73200 , training  accuracy 1\n",
      "step 73200 , loss : 0.463425\n",
      "step 73200 , validation  accuracy 0.815789\n",
      "step 73200 , validation loss : 0.603028\n",
      "step 73200 , test  accuracy 0.820513\n",
      "step 73200 , test loss : 0.618195\n",
      "step 73300 , training  accuracy 1\n",
      "step 73300 , loss : 0.463578\n",
      "step 73300 , validation  accuracy 0.815789\n",
      "step 73300 , validation loss : 0.604506\n",
      "step 73300 , test  accuracy 0.820513\n",
      "step 73300 , test loss : 0.618175\n",
      "step 73400 , training  accuracy 1\n",
      "step 73400 , loss : 0.463125\n",
      "step 73400 , validation  accuracy 0.815789\n",
      "step 73400 , validation loss : 0.604998\n",
      "step 73400 , test  accuracy 0.820513\n",
      "step 73400 , test loss : 0.619201\n",
      "step 73500 , training  accuracy 1\n",
      "step 73500 , loss : 0.463073\n",
      "step 73500 , validation  accuracy 0.815789\n",
      "step 73500 , validation loss : 0.60509\n",
      "step 73500 , test  accuracy 0.794872\n",
      "step 73500 , test loss : 0.619955\n",
      "step 73600 , training  accuracy 1\n",
      "step 73600 , loss : 0.462928\n",
      "step 73600 , validation  accuracy 0.815789\n",
      "step 73600 , validation loss : 0.605163\n",
      "step 73600 , test  accuracy 0.794872\n",
      "step 73600 , test loss : 0.620414\n",
      "step 73700 , training  accuracy 1\n",
      "step 73700 , loss : 0.463007\n",
      "step 73700 , validation  accuracy 0.815789\n",
      "step 73700 , validation loss : 0.605106\n",
      "step 73700 , test  accuracy 0.794872\n",
      "step 73700 , test loss : 0.621391\n",
      "step 73800 , training  accuracy 1\n",
      "step 73800 , loss : 0.463177\n",
      "step 73800 , validation  accuracy 0.815789\n",
      "step 73800 , validation loss : 0.605045\n",
      "step 73800 , test  accuracy 0.794872\n",
      "step 73800 , test loss : 0.622492\n",
      "step 73900 , training  accuracy 1\n",
      "step 73900 , loss : 0.463049\n",
      "step 73900 , validation  accuracy 0.815789\n",
      "step 73900 , validation loss : 0.605388\n",
      "step 73900 , test  accuracy 0.794872\n",
      "step 73900 , test loss : 0.623727\n",
      "step 74000 , training  accuracy 1\n",
      "step 74000 , loss : 0.463246\n",
      "step 74000 , validation  accuracy 0.789474\n",
      "step 74000 , validation loss : 0.606553\n",
      "step 74000 , test  accuracy 0.794872\n",
      "step 74000 , test loss : 0.624633\n",
      "step 74100 , training  accuracy 1\n",
      "step 74100 , loss : 0.46321\n",
      "step 74100 , validation  accuracy 0.789474\n",
      "step 74100 , validation loss : 0.60779\n",
      "step 74100 , test  accuracy 0.794872\n",
      "step 74100 , test loss : 0.625962\n",
      "step 74200 , training  accuracy 1\n",
      "step 74200 , loss : 0.46324\n",
      "step 74200 , validation  accuracy 0.789474\n",
      "step 74200 , validation loss : 0.608992\n",
      "step 74200 , test  accuracy 0.794872\n",
      "step 74200 , test loss : 0.626454\n",
      "step 74300 , training  accuracy 1\n",
      "step 74300 , loss : 0.463512\n",
      "step 74300 , validation  accuracy 0.789474\n",
      "step 74300 , validation loss : 0.610017\n",
      "step 74300 , test  accuracy 0.794872\n",
      "step 74300 , test loss : 0.627236\n",
      "step 74400 , training  accuracy 1\n",
      "step 74400 , loss : 0.463528\n",
      "step 74400 , validation  accuracy 0.789474\n",
      "step 74400 , validation loss : 0.610409\n",
      "step 74400 , test  accuracy 0.820513\n",
      "step 74400 , test loss : 0.62807\n",
      "step 74500 , training  accuracy 1\n",
      "step 74500 , loss : 0.463909\n",
      "step 74500 , validation  accuracy 0.789474\n",
      "step 74500 , validation loss : 0.611162\n",
      "step 74500 , test  accuracy 0.820513\n",
      "step 74500 , test loss : 0.628524\n",
      "step 74600 , training  accuracy 1\n",
      "step 74600 , loss : 0.463883\n",
      "step 74600 , validation  accuracy 0.789474\n",
      "step 74600 , validation loss : 0.610934\n",
      "step 74600 , test  accuracy 0.794872\n",
      "step 74600 , test loss : 0.62965\n",
      "step 74700 , training  accuracy 1\n",
      "step 74700 , loss : 0.464108\n",
      "step 74700 , validation  accuracy 0.789474\n",
      "step 74700 , validation loss : 0.61051\n",
      "step 74700 , test  accuracy 0.820513\n",
      "step 74700 , test loss : 0.630509\n",
      "step 74800 , training  accuracy 1\n",
      "step 74800 , loss : 0.464515\n",
      "step 74800 , validation  accuracy 0.789474\n",
      "step 74800 , validation loss : 0.609845\n",
      "step 74800 , test  accuracy 0.820513\n",
      "step 74800 , test loss : 0.632448\n",
      "step 74900 , training  accuracy 1\n",
      "step 74900 , loss : 0.463949\n",
      "step 74900 , validation  accuracy 0.789474\n",
      "step 74900 , validation loss : 0.609091\n",
      "step 74900 , test  accuracy 0.820513\n",
      "step 74900 , test loss : 0.633354\n",
      "step 75000 , training  accuracy 1\n",
      "step 75000 , loss : 0.463852\n",
      "step 75000 , validation  accuracy 0.789474\n",
      "step 75000 , validation loss : 0.608584\n",
      "step 75000 , test  accuracy 0.820513\n",
      "step 75000 , test loss : 0.630759\n",
      "step 75100 , training  accuracy 1\n",
      "step 75100 , loss : 0.463557\n",
      "step 75100 , validation  accuracy 0.789474\n",
      "step 75100 , validation loss : 0.607699\n",
      "step 75100 , test  accuracy 0.820513\n",
      "step 75100 , test loss : 0.628357\n",
      "step 75200 , training  accuracy 1\n",
      "step 75200 , loss : 0.463206\n",
      "step 75200 , validation  accuracy 0.789474\n",
      "step 75200 , validation loss : 0.6072\n",
      "step 75200 , test  accuracy 0.820513\n",
      "step 75200 , test loss : 0.626695\n",
      "step 75300 , training  accuracy 1\n",
      "step 75300 , loss : 0.463217\n",
      "step 75300 , validation  accuracy 0.789474\n",
      "step 75300 , validation loss : 0.606477\n",
      "step 75300 , test  accuracy 0.820513\n",
      "step 75300 , test loss : 0.625381\n",
      "step 75400 , training  accuracy 1\n",
      "step 75400 , loss : 0.463268\n",
      "step 75400 , validation  accuracy 0.789474\n",
      "step 75400 , validation loss : 0.605892\n",
      "step 75400 , test  accuracy 0.820513\n",
      "step 75400 , test loss : 0.624125\n",
      "step 75500 , training  accuracy 1\n",
      "step 75500 , loss : 0.462992\n",
      "step 75500 , validation  accuracy 0.789474\n",
      "step 75500 , validation loss : 0.605373\n",
      "step 75500 , test  accuracy 0.820513\n",
      "step 75500 , test loss : 0.622934\n",
      "step 75600 , training  accuracy 1\n",
      "step 75600 , loss : 0.463377\n",
      "step 75600 , validation  accuracy 0.789474\n",
      "step 75600 , validation loss : 0.605015\n",
      "step 75600 , test  accuracy 0.820513\n",
      "step 75600 , test loss : 0.62163\n",
      "step 75700 , training  accuracy 1\n",
      "step 75700 , loss : 0.463222\n",
      "step 75700 , validation  accuracy 0.789474\n",
      "step 75700 , validation loss : 0.604695\n",
      "step 75700 , test  accuracy 0.820513\n",
      "step 75700 , test loss : 0.620788\n",
      "step 75800 , training  accuracy 1\n",
      "step 75800 , loss : 0.463285\n",
      "step 75800 , validation  accuracy 0.789474\n",
      "step 75800 , validation loss : 0.60299\n",
      "step 75800 , test  accuracy 0.794872\n",
      "step 75800 , test loss : 0.623559\n",
      "step 75900 , training  accuracy 1\n",
      "step 75900 , loss : 0.463147\n",
      "step 75900 , validation  accuracy 0.815789\n",
      "step 75900 , validation loss : 0.602367\n",
      "step 75900 , test  accuracy 0.794872\n",
      "step 75900 , test loss : 0.625983\n",
      "step 76000 , training  accuracy 1\n",
      "step 76000 , loss : 0.463278\n",
      "step 76000 , validation  accuracy 0.815789\n",
      "step 76000 , validation loss : 0.602676\n",
      "step 76000 , test  accuracy 0.794872\n",
      "step 76000 , test loss : 0.626313\n",
      "step 76100 , training  accuracy 1\n",
      "step 76100 , loss : 0.462717\n",
      "step 76100 , validation  accuracy 0.789474\n",
      "step 76100 , validation loss : 0.602909\n",
      "step 76100 , test  accuracy 0.794872\n",
      "step 76100 , test loss : 0.62402\n",
      "step 76200 , training  accuracy 1\n",
      "step 76200 , loss : 0.462876\n",
      "step 76200 , validation  accuracy 0.789474\n",
      "step 76200 , validation loss : 0.603966\n",
      "step 76200 , test  accuracy 0.794872\n",
      "step 76200 , test loss : 0.622193\n",
      "step 76300 , training  accuracy 1\n",
      "step 76300 , loss : 0.463239\n",
      "step 76300 , validation  accuracy 0.789474\n",
      "step 76300 , validation loss : 0.605824\n",
      "step 76300 , test  accuracy 0.794872\n",
      "step 76300 , test loss : 0.620689\n",
      "step 76400 , training  accuracy 1\n",
      "step 76400 , loss : 0.463428\n",
      "step 76400 , validation  accuracy 0.789474\n",
      "step 76400 , validation loss : 0.607701\n",
      "step 76400 , test  accuracy 0.794872\n",
      "step 76400 , test loss : 0.620055\n",
      "step 76500 , training  accuracy 1\n",
      "step 76500 , loss : 0.463541\n",
      "step 76500 , validation  accuracy 0.789474\n",
      "step 76500 , validation loss : 0.6086\n",
      "step 76500 , test  accuracy 0.794872\n",
      "step 76500 , test loss : 0.619722\n",
      "step 76600 , training  accuracy 1\n",
      "step 76600 , loss : 0.463561\n",
      "step 76600 , validation  accuracy 0.789474\n",
      "step 76600 , validation loss : 0.609728\n",
      "step 76600 , test  accuracy 0.794872\n",
      "step 76600 , test loss : 0.620478\n",
      "step 76700 , training  accuracy 1\n",
      "step 76700 , loss : 0.463847\n",
      "step 76700 , validation  accuracy 0.789474\n",
      "step 76700 , validation loss : 0.609412\n",
      "step 76700 , test  accuracy 0.794872\n",
      "step 76700 , test loss : 0.621792\n",
      "step 76800 , training  accuracy 1\n",
      "step 76800 , loss : 0.463453\n",
      "step 76800 , validation  accuracy 0.789474\n",
      "step 76800 , validation loss : 0.609371\n",
      "step 76800 , test  accuracy 0.794872\n",
      "step 76800 , test loss : 0.622319\n",
      "step 76900 , training  accuracy 1\n",
      "step 76900 , loss : 0.463905\n",
      "step 76900 , validation  accuracy 0.789474\n",
      "step 76900 , validation loss : 0.609457\n",
      "step 76900 , test  accuracy 0.794872\n",
      "step 76900 , test loss : 0.622915\n",
      "step 77000 , training  accuracy 1\n",
      "step 77000 , loss : 0.463602\n",
      "step 77000 , validation  accuracy 0.789474\n",
      "step 77000 , validation loss : 0.609966\n",
      "step 77000 , test  accuracy 0.794872\n",
      "step 77000 , test loss : 0.623567\n",
      "step 77100 , training  accuracy 1\n",
      "step 77100 , loss : 0.463512\n",
      "step 77100 , validation  accuracy 0.789474\n",
      "step 77100 , validation loss : 0.610627\n",
      "step 77100 , test  accuracy 0.794872\n",
      "step 77100 , test loss : 0.62393\n",
      "step 77200 , training  accuracy 1\n",
      "step 77200 , loss : 0.463941\n",
      "step 77200 , validation  accuracy 0.789474\n",
      "step 77200 , validation loss : 0.610695\n",
      "step 77200 , test  accuracy 0.794872\n",
      "step 77200 , test loss : 0.624473\n",
      "step 77300 , training  accuracy 1\n",
      "step 77300 , loss : 0.463481\n",
      "step 77300 , validation  accuracy 0.789474\n",
      "step 77300 , validation loss : 0.610206\n",
      "step 77300 , test  accuracy 0.820513\n",
      "step 77300 , test loss : 0.62369\n",
      "step 77400 , training  accuracy 1\n",
      "step 77400 , loss : 0.463811\n",
      "step 77400 , validation  accuracy 0.789474\n",
      "step 77400 , validation loss : 0.609003\n",
      "step 77400 , test  accuracy 0.820513\n",
      "step 77400 , test loss : 0.622152\n",
      "step 77500 , training  accuracy 1\n",
      "step 77500 , loss : 0.463428\n",
      "step 77500 , validation  accuracy 0.815789\n",
      "step 77500 , validation loss : 0.60741\n",
      "step 77500 , test  accuracy 0.820513\n",
      "step 77500 , test loss : 0.620902\n",
      "step 77600 , training  accuracy 1\n",
      "step 77600 , loss : 0.463267\n",
      "step 77600 , validation  accuracy 0.815789\n",
      "step 77600 , validation loss : 0.605404\n",
      "step 77600 , test  accuracy 0.820513\n",
      "step 77600 , test loss : 0.619543\n",
      "step 77700 , training  accuracy 1\n",
      "step 77700 , loss : 0.463423\n",
      "step 77700 , validation  accuracy 0.815789\n",
      "step 77700 , validation loss : 0.603972\n",
      "step 77700 , test  accuracy 0.820513\n",
      "step 77700 , test loss : 0.618392\n",
      "step 77800 , training  accuracy 1\n",
      "step 77800 , loss : 0.463263\n",
      "step 77800 , validation  accuracy 0.815789\n",
      "step 77800 , validation loss : 0.603007\n",
      "step 77800 , test  accuracy 0.820513\n",
      "step 77800 , test loss : 0.618078\n",
      "step 77900 , training  accuracy 1\n",
      "step 77900 , loss : 0.463261\n",
      "step 77900 , validation  accuracy 0.815789\n",
      "step 77900 , validation loss : 0.601641\n",
      "step 77900 , test  accuracy 0.820513\n",
      "step 77900 , test loss : 0.61629\n",
      "step 78000 , training  accuracy 1\n",
      "step 78000 , loss : 0.463401\n",
      "step 78000 , validation  accuracy 0.815789\n",
      "step 78000 , validation loss : 0.600642\n",
      "step 78000 , test  accuracy 0.820513\n",
      "step 78000 , test loss : 0.614415\n",
      "step 78100 , training  accuracy 1\n",
      "step 78100 , loss : 0.4641\n",
      "step 78100 , validation  accuracy 0.815789\n",
      "step 78100 , validation loss : 0.599921\n",
      "step 78100 , test  accuracy 0.846154\n",
      "step 78100 , test loss : 0.613582\n",
      "step 78200 , training  accuracy 1\n",
      "step 78200 , loss : 0.46339\n",
      "step 78200 , validation  accuracy 0.815789\n",
      "step 78200 , validation loss : 0.600417\n",
      "step 78200 , test  accuracy 0.820513\n",
      "step 78200 , test loss : 0.613576\n",
      "step 78300 , training  accuracy 1\n",
      "step 78300 , loss : 0.463233\n",
      "step 78300 , validation  accuracy 0.815789\n",
      "step 78300 , validation loss : 0.603169\n",
      "step 78300 , test  accuracy 0.820513\n",
      "step 78300 , test loss : 0.614042\n",
      "step 78400 , training  accuracy 1\n",
      "step 78400 , loss : 0.463623\n",
      "step 78400 , validation  accuracy 0.789474\n",
      "step 78400 , validation loss : 0.60602\n",
      "step 78400 , test  accuracy 0.820513\n",
      "step 78400 , test loss : 0.614844\n",
      "step 78500 , training  accuracy 1\n",
      "step 78500 , loss : 0.463212\n",
      "step 78500 , validation  accuracy 0.789474\n",
      "step 78500 , validation loss : 0.607812\n",
      "step 78500 , test  accuracy 0.820513\n",
      "step 78500 , test loss : 0.61628\n",
      "step 78600 , training  accuracy 1\n",
      "step 78600 , loss : 0.462902\n",
      "step 78600 , validation  accuracy 0.789474\n",
      "step 78600 , validation loss : 0.608547\n",
      "step 78600 , test  accuracy 0.820513\n",
      "step 78600 , test loss : 0.618125\n",
      "step 78700 , training  accuracy 1\n",
      "step 78700 , loss : 0.462941\n",
      "step 78700 , validation  accuracy 0.789474\n",
      "step 78700 , validation loss : 0.607388\n",
      "step 78700 , test  accuracy 0.794872\n",
      "step 78700 , test loss : 0.620499\n",
      "step 78800 , training  accuracy 1\n",
      "step 78800 , loss : 0.462765\n",
      "step 78800 , validation  accuracy 0.789474\n",
      "step 78800 , validation loss : 0.60732\n",
      "step 78800 , test  accuracy 0.794872\n",
      "step 78800 , test loss : 0.622548\n",
      "step 78900 , training  accuracy 1\n",
      "step 78900 , loss : 0.463304\n",
      "step 78900 , validation  accuracy 0.789474\n",
      "step 78900 , validation loss : 0.607643\n",
      "step 78900 , test  accuracy 0.794872\n",
      "step 78900 , test loss : 0.624161\n",
      "step 79000 , training  accuracy 1\n",
      "step 79000 , loss : 0.462987\n",
      "step 79000 , validation  accuracy 0.815789\n",
      "step 79000 , validation loss : 0.608061\n",
      "step 79000 , test  accuracy 0.794872\n",
      "step 79000 , test loss : 0.627203\n",
      "step 79100 , training  accuracy 1\n",
      "step 79100 , loss : 0.46323\n",
      "step 79100 , validation  accuracy 0.815789\n",
      "step 79100 , validation loss : 0.60879\n",
      "step 79100 , test  accuracy 0.794872\n",
      "step 79100 , test loss : 0.62964\n",
      "step 79200 , training  accuracy 1\n",
      "step 79200 , loss : 0.463086\n",
      "step 79200 , validation  accuracy 0.815789\n",
      "step 79200 , validation loss : 0.610088\n",
      "step 79200 , test  accuracy 0.794872\n",
      "step 79200 , test loss : 0.630959\n",
      "step 79300 , training  accuracy 1\n",
      "step 79300 , loss : 0.462849\n",
      "step 79300 , validation  accuracy 0.842105\n",
      "step 79300 , validation loss : 0.611238\n",
      "step 79300 , test  accuracy 0.794872\n",
      "step 79300 , test loss : 0.63198\n",
      "step 79400 , training  accuracy 1\n",
      "step 79400 , loss : 0.462985\n",
      "step 79400 , validation  accuracy 0.842105\n",
      "step 79400 , validation loss : 0.612565\n",
      "step 79400 , test  accuracy 0.794872\n",
      "step 79400 , test loss : 0.632363\n",
      "step 79500 , training  accuracy 1\n",
      "step 79500 , loss : 0.463277\n",
      "step 79500 , validation  accuracy 0.842105\n",
      "step 79500 , validation loss : 0.612959\n",
      "step 79500 , test  accuracy 0.794872\n",
      "step 79500 , test loss : 0.631388\n",
      "step 79600 , training  accuracy 1\n",
      "step 79600 , loss : 0.463587\n",
      "step 79600 , validation  accuracy 0.842105\n",
      "step 79600 , validation loss : 0.613292\n",
      "step 79600 , test  accuracy 0.794872\n",
      "step 79600 , test loss : 0.630782\n",
      "step 79700 , training  accuracy 1\n",
      "step 79700 , loss : 0.463677\n",
      "step 79700 , validation  accuracy 0.815789\n",
      "step 79700 , validation loss : 0.613698\n",
      "step 79700 , test  accuracy 0.820513\n",
      "step 79700 , test loss : 0.629973\n",
      "step 79800 , training  accuracy 1\n",
      "step 79800 , loss : 0.463943\n",
      "step 79800 , validation  accuracy 0.815789\n",
      "step 79800 , validation loss : 0.614491\n",
      "step 79800 , test  accuracy 0.794872\n",
      "step 79800 , test loss : 0.629528\n",
      "step 79900 , training  accuracy 1\n",
      "step 79900 , loss : 0.463692\n",
      "step 79900 , validation  accuracy 0.842105\n",
      "step 79900 , validation loss : 0.613952\n",
      "step 79900 , test  accuracy 0.820513\n",
      "step 79900 , test loss : 0.627888\n",
      "step 80000 , training  accuracy 1\n",
      "step 80000 , loss : 0.4633\n",
      "step 80000 , validation  accuracy 0.842105\n",
      "step 80000 , validation loss : 0.613236\n",
      "step 80000 , test  accuracy 0.820513\n",
      "step 80000 , test loss : 0.626355\n",
      "step 80100 , training  accuracy 1\n",
      "step 80100 , loss : 0.4636\n",
      "step 80100 , validation  accuracy 0.842105\n",
      "step 80100 , validation loss : 0.61226\n",
      "step 80100 , test  accuracy 0.820513\n",
      "step 80100 , test loss : 0.625125\n",
      "step 80200 , training  accuracy 1\n",
      "step 80200 , loss : 0.463395\n",
      "step 80200 , validation  accuracy 0.842105\n",
      "step 80200 , validation loss : 0.611558\n",
      "step 80200 , test  accuracy 0.820513\n",
      "step 80200 , test loss : 0.624474\n",
      "step 80300 , training  accuracy 1\n",
      "step 80300 , loss : 0.463468\n",
      "step 80300 , validation  accuracy 0.842105\n",
      "step 80300 , validation loss : 0.611049\n",
      "step 80300 , test  accuracy 0.820513\n",
      "step 80300 , test loss : 0.623829\n",
      "step 80400 , training  accuracy 1\n",
      "step 80400 , loss : 0.463029\n",
      "step 80400 , validation  accuracy 0.842105\n",
      "step 80400 , validation loss : 0.61062\n",
      "step 80400 , test  accuracy 0.820513\n",
      "step 80400 , test loss : 0.624054\n",
      "step 80500 , training  accuracy 1\n",
      "step 80500 , loss : 0.463104\n",
      "step 80500 , validation  accuracy 0.842105\n",
      "step 80500 , validation loss : 0.609782\n",
      "step 80500 , test  accuracy 0.820513\n",
      "step 80500 , test loss : 0.624371\n",
      "step 80600 , training  accuracy 1\n",
      "step 80600 , loss : 0.463373\n",
      "step 80600 , validation  accuracy 0.842105\n",
      "step 80600 , validation loss : 0.609032\n",
      "step 80600 , test  accuracy 0.820513\n",
      "step 80600 , test loss : 0.625275\n",
      "step 80700 , training  accuracy 1\n",
      "step 80700 , loss : 0.463132\n",
      "step 80700 , validation  accuracy 0.842105\n",
      "step 80700 , validation loss : 0.608869\n",
      "step 80700 , test  accuracy 0.820513\n",
      "step 80700 , test loss : 0.626302\n",
      "step 80800 , training  accuracy 1\n",
      "step 80800 , loss : 0.463099\n",
      "step 80800 , validation  accuracy 0.815789\n",
      "step 80800 , validation loss : 0.608569\n",
      "step 80800 , test  accuracy 0.820513\n",
      "step 80800 , test loss : 0.626906\n",
      "step 80900 , training  accuracy 1\n",
      "step 80900 , loss : 0.463082\n",
      "step 80900 , validation  accuracy 0.815789\n",
      "step 80900 , validation loss : 0.608888\n",
      "step 80900 , test  accuracy 0.820513\n",
      "step 80900 , test loss : 0.62768\n",
      "step 81000 , training  accuracy 1\n",
      "step 81000 , loss : 0.463305\n",
      "step 81000 , validation  accuracy 0.815789\n",
      "step 81000 , validation loss : 0.609702\n",
      "step 81000 , test  accuracy 0.820513\n",
      "step 81000 , test loss : 0.628154\n",
      "step 81100 , training  accuracy 1\n",
      "step 81100 , loss : 0.463235\n",
      "step 81100 , validation  accuracy 0.815789\n",
      "step 81100 , validation loss : 0.610334\n",
      "step 81100 , test  accuracy 0.820513\n",
      "step 81100 , test loss : 0.627872\n",
      "step 81200 , training  accuracy 1\n",
      "step 81200 , loss : 0.4632\n",
      "step 81200 , validation  accuracy 0.789474\n",
      "step 81200 , validation loss : 0.611008\n",
      "step 81200 , test  accuracy 0.820513\n",
      "step 81200 , test loss : 0.627795\n",
      "step 81300 , training  accuracy 1\n",
      "step 81300 , loss : 0.463049\n",
      "step 81300 , validation  accuracy 0.789474\n",
      "step 81300 , validation loss : 0.612604\n",
      "step 81300 , test  accuracy 0.820513\n",
      "step 81300 , test loss : 0.628777\n",
      "step 81400 , training  accuracy 1\n",
      "step 81400 , loss : 0.463235\n",
      "step 81400 , validation  accuracy 0.789474\n",
      "step 81400 , validation loss : 0.613473\n",
      "step 81400 , test  accuracy 0.820513\n",
      "step 81400 , test loss : 0.629489\n",
      "step 81500 , training  accuracy 1\n",
      "step 81500 , loss : 0.463349\n",
      "step 81500 , validation  accuracy 0.789474\n",
      "step 81500 , validation loss : 0.612852\n",
      "step 81500 , test  accuracy 0.820513\n",
      "step 81500 , test loss : 0.628159\n",
      "step 81600 , training  accuracy 1\n",
      "step 81600 , loss : 0.463062\n",
      "step 81600 , validation  accuracy 0.789474\n",
      "step 81600 , validation loss : 0.611933\n",
      "step 81600 , test  accuracy 0.820513\n",
      "step 81600 , test loss : 0.627935\n",
      "step 81700 , training  accuracy 1\n",
      "step 81700 , loss : 0.463324\n",
      "step 81700 , validation  accuracy 0.815789\n",
      "step 81700 , validation loss : 0.611379\n",
      "step 81700 , test  accuracy 0.820513\n",
      "step 81700 , test loss : 0.627423\n",
      "step 81800 , training  accuracy 1\n",
      "step 81800 , loss : 0.463867\n",
      "step 81800 , validation  accuracy 0.815789\n",
      "step 81800 , validation loss : 0.610936\n",
      "step 81800 , test  accuracy 0.820513\n",
      "step 81800 , test loss : 0.628217\n",
      "step 81900 , training  accuracy 1\n",
      "step 81900 , loss : 0.463148\n",
      "step 81900 , validation  accuracy 0.815789\n",
      "step 81900 , validation loss : 0.610088\n",
      "step 81900 , test  accuracy 0.820513\n",
      "step 81900 , test loss : 0.628087\n",
      "step 82000 , training  accuracy 1\n",
      "step 82000 , loss : 0.463592\n",
      "step 82000 , validation  accuracy 0.815789\n",
      "step 82000 , validation loss : 0.609164\n",
      "step 82000 , test  accuracy 0.820513\n",
      "step 82000 , test loss : 0.627828\n",
      "step 82100 , training  accuracy 1\n",
      "step 82100 , loss : 0.463115\n",
      "step 82100 , validation  accuracy 0.815789\n",
      "step 82100 , validation loss : 0.60788\n",
      "step 82100 , test  accuracy 0.820513\n",
      "step 82100 , test loss : 0.627382\n",
      "step 82200 , training  accuracy 1\n",
      "step 82200 , loss : 0.463068\n",
      "step 82200 , validation  accuracy 0.842105\n",
      "step 82200 , validation loss : 0.607113\n",
      "step 82200 , test  accuracy 0.820513\n",
      "step 82200 , test loss : 0.626711\n",
      "step 82300 , training  accuracy 1\n",
      "step 82300 , loss : 0.463412\n",
      "step 82300 , validation  accuracy 0.842105\n",
      "step 82300 , validation loss : 0.607101\n",
      "step 82300 , test  accuracy 0.794872\n",
      "step 82300 , test loss : 0.626025\n",
      "step 82400 , training  accuracy 1\n",
      "step 82400 , loss : 0.463464\n",
      "step 82400 , validation  accuracy 0.868421\n",
      "step 82400 , validation loss : 0.606283\n",
      "step 82400 , test  accuracy 0.820513\n",
      "step 82400 , test loss : 0.624444\n",
      "step 82500 , training  accuracy 1\n",
      "step 82500 , loss : 0.462932\n",
      "step 82500 , validation  accuracy 0.842105\n",
      "step 82500 , validation loss : 0.605291\n",
      "step 82500 , test  accuracy 0.820513\n",
      "step 82500 , test loss : 0.622545\n",
      "step 82600 , training  accuracy 1\n",
      "step 82600 , loss : 0.463033\n",
      "step 82600 , validation  accuracy 0.842105\n",
      "step 82600 , validation loss : 0.604519\n",
      "step 82600 , test  accuracy 0.820513\n",
      "step 82600 , test loss : 0.621083\n",
      "step 82700 , training  accuracy 1\n",
      "step 82700 , loss : 0.463165\n",
      "step 82700 , validation  accuracy 0.842105\n",
      "step 82700 , validation loss : 0.603937\n",
      "step 82700 , test  accuracy 0.820513\n",
      "step 82700 , test loss : 0.61963\n",
      "step 82800 , training  accuracy 1\n",
      "step 82800 , loss : 0.463027\n",
      "step 82800 , validation  accuracy 0.842105\n",
      "step 82800 , validation loss : 0.60317\n",
      "step 82800 , test  accuracy 0.820513\n",
      "step 82800 , test loss : 0.618215\n",
      "step 82900 , training  accuracy 1\n",
      "step 82900 , loss : 0.462957\n",
      "step 82900 , validation  accuracy 0.815789\n",
      "step 82900 , validation loss : 0.603156\n",
      "step 82900 , test  accuracy 0.820513\n",
      "step 82900 , test loss : 0.617364\n",
      "step 83000 , training  accuracy 1\n",
      "step 83000 , loss : 0.463257\n",
      "step 83000 , validation  accuracy 0.815789\n",
      "step 83000 , validation loss : 0.603945\n",
      "step 83000 , test  accuracy 0.820513\n",
      "step 83000 , test loss : 0.616989\n",
      "step 83100 , training  accuracy 1\n",
      "step 83100 , loss : 0.463317\n",
      "step 83100 , validation  accuracy 0.789474\n",
      "step 83100 , validation loss : 0.605822\n",
      "step 83100 , test  accuracy 0.820513\n",
      "step 83100 , test loss : 0.616162\n",
      "step 83200 , training  accuracy 1\n",
      "step 83200 , loss : 0.463569\n",
      "step 83200 , validation  accuracy 0.815789\n",
      "step 83200 , validation loss : 0.607445\n",
      "step 83200 , test  accuracy 0.820513\n",
      "step 83200 , test loss : 0.616032\n",
      "step 83300 , training  accuracy 1\n",
      "step 83300 , loss : 0.463318\n",
      "step 83300 , validation  accuracy 0.815789\n",
      "step 83300 , validation loss : 0.607397\n",
      "step 83300 , test  accuracy 0.820513\n",
      "step 83300 , test loss : 0.617641\n",
      "step 83400 , training  accuracy 1\n",
      "step 83400 , loss : 0.463253\n",
      "step 83400 , validation  accuracy 0.815789\n",
      "step 83400 , validation loss : 0.608297\n",
      "step 83400 , test  accuracy 0.820513\n",
      "step 83400 , test loss : 0.619003\n",
      "step 83500 , training  accuracy 1\n",
      "step 83500 , loss : 0.46321\n",
      "step 83500 , validation  accuracy 0.815789\n",
      "step 83500 , validation loss : 0.610488\n",
      "step 83500 , test  accuracy 0.820513\n",
      "step 83500 , test loss : 0.620212\n",
      "step 83600 , training  accuracy 1\n",
      "step 83600 , loss : 0.463241\n",
      "step 83600 , validation  accuracy 0.815789\n",
      "step 83600 , validation loss : 0.613374\n",
      "step 83600 , test  accuracy 0.794872\n",
      "step 83600 , test loss : 0.622828\n",
      "step 83700 , training  accuracy 1\n",
      "step 83700 , loss : 0.46326\n",
      "step 83700 , validation  accuracy 0.789474\n",
      "step 83700 , validation loss : 0.61528\n",
      "step 83700 , test  accuracy 0.794872\n",
      "step 83700 , test loss : 0.625757\n",
      "step 83800 , training  accuracy 1\n",
      "step 83800 , loss : 0.463638\n",
      "step 83800 , validation  accuracy 0.789474\n",
      "step 83800 , validation loss : 0.617088\n",
      "step 83800 , test  accuracy 0.74359\n",
      "step 83800 , test loss : 0.628289\n",
      "step 83900 , training  accuracy 1\n",
      "step 83900 , loss : 0.463889\n",
      "step 83900 , validation  accuracy 0.789474\n",
      "step 83900 , validation loss : 0.618056\n",
      "step 83900 , test  accuracy 0.717949\n",
      "step 83900 , test loss : 0.629538\n",
      "step 84000 , training  accuracy 1\n",
      "step 84000 , loss : 0.463265\n",
      "step 84000 , validation  accuracy 0.815789\n",
      "step 84000 , validation loss : 0.617483\n",
      "step 84000 , test  accuracy 0.74359\n",
      "step 84000 , test loss : 0.628943\n",
      "step 84100 , training  accuracy 1\n",
      "step 84100 , loss : 0.463313\n",
      "step 84100 , validation  accuracy 0.815789\n",
      "step 84100 , validation loss : 0.616644\n",
      "step 84100 , test  accuracy 0.74359\n",
      "step 84100 , test loss : 0.6279\n",
      "step 84200 , training  accuracy 1\n",
      "step 84200 , loss : 0.463401\n",
      "step 84200 , validation  accuracy 0.815789\n",
      "step 84200 , validation loss : 0.615409\n",
      "step 84200 , test  accuracy 0.794872\n",
      "step 84200 , test loss : 0.62573\n",
      "step 84300 , training  accuracy 1\n",
      "step 84300 , loss : 0.463169\n",
      "step 84300 , validation  accuracy 0.789474\n",
      "step 84300 , validation loss : 0.614743\n",
      "step 84300 , test  accuracy 0.820513\n",
      "step 84300 , test loss : 0.62395\n",
      "step 84400 , training  accuracy 1\n",
      "step 84400 , loss : 0.463232\n",
      "step 84400 , validation  accuracy 0.789474\n",
      "step 84400 , validation loss : 0.614294\n",
      "step 84400 , test  accuracy 0.820513\n",
      "step 84400 , test loss : 0.62287\n",
      "step 84500 , training  accuracy 1\n",
      "step 84500 , loss : 0.463254\n",
      "step 84500 , validation  accuracy 0.789474\n",
      "step 84500 , validation loss : 0.613886\n",
      "step 84500 , test  accuracy 0.820513\n",
      "step 84500 , test loss : 0.62156\n",
      "step 84600 , training  accuracy 1\n",
      "step 84600 , loss : 0.463264\n",
      "step 84600 , validation  accuracy 0.789474\n",
      "step 84600 , validation loss : 0.613059\n",
      "step 84600 , test  accuracy 0.820513\n",
      "step 84600 , test loss : 0.62102\n",
      "step 84700 , training  accuracy 1\n",
      "step 84700 , loss : 0.46323\n",
      "step 84700 , validation  accuracy 0.789474\n",
      "step 84700 , validation loss : 0.611755\n",
      "step 84700 , test  accuracy 0.820513\n",
      "step 84700 , test loss : 0.62071\n",
      "step 84800 , training  accuracy 1\n",
      "step 84800 , loss : 0.463337\n",
      "step 84800 , validation  accuracy 0.815789\n",
      "step 84800 , validation loss : 0.610931\n",
      "step 84800 , test  accuracy 0.820513\n",
      "step 84800 , test loss : 0.620309\n",
      "step 84900 , training  accuracy 1\n",
      "step 84900 , loss : 0.463627\n",
      "step 84900 , validation  accuracy 0.815789\n",
      "step 84900 , validation loss : 0.610205\n",
      "step 84900 , test  accuracy 0.794872\n",
      "step 84900 , test loss : 0.619626\n",
      "step 85000 , training  accuracy 1\n",
      "step 85000 , loss : 0.464015\n",
      "step 85000 , validation  accuracy 0.815789\n",
      "step 85000 , validation loss : 0.609141\n",
      "step 85000 , test  accuracy 0.794872\n",
      "step 85000 , test loss : 0.618701\n",
      "step 85100 , training  accuracy 1\n",
      "step 85100 , loss : 0.463688\n",
      "step 85100 , validation  accuracy 0.789474\n",
      "step 85100 , validation loss : 0.608354\n",
      "step 85100 , test  accuracy 0.794872\n",
      "step 85100 , test loss : 0.616734\n",
      "step 85200 , training  accuracy 1\n",
      "step 85200 , loss : 0.464335\n",
      "step 85200 , validation  accuracy 0.789474\n",
      "step 85200 , validation loss : 0.607703\n",
      "step 85200 , test  accuracy 0.794872\n",
      "step 85200 , test loss : 0.614752\n",
      "step 85300 , training  accuracy 1\n",
      "step 85300 , loss : 0.464332\n",
      "step 85300 , validation  accuracy 0.789474\n",
      "step 85300 , validation loss : 0.607415\n",
      "step 85300 , test  accuracy 0.820513\n",
      "step 85300 , test loss : 0.613325\n",
      "step 85400 , training  accuracy 1\n",
      "step 85400 , loss : 0.464127\n",
      "step 85400 , validation  accuracy 0.789474\n",
      "step 85400 , validation loss : 0.607689\n",
      "step 85400 , test  accuracy 0.820513\n",
      "step 85400 , test loss : 0.612269\n",
      "step 85500 , training  accuracy 1\n",
      "step 85500 , loss : 0.464058\n",
      "step 85500 , validation  accuracy 0.789474\n",
      "step 85500 , validation loss : 0.608712\n",
      "step 85500 , test  accuracy 0.820513\n",
      "step 85500 , test loss : 0.61101\n",
      "step 85600 , training  accuracy 1\n",
      "step 85600 , loss : 0.464251\n",
      "step 85600 , validation  accuracy 0.789474\n",
      "step 85600 , validation loss : 0.608106\n",
      "step 85600 , test  accuracy 0.820513\n",
      "step 85600 , test loss : 0.61064\n",
      "step 85700 , training  accuracy 1\n",
      "step 85700 , loss : 0.463659\n",
      "step 85700 , validation  accuracy 0.789474\n",
      "step 85700 , validation loss : 0.606945\n",
      "step 85700 , test  accuracy 0.820513\n",
      "step 85700 , test loss : 0.610789\n",
      "step 85800 , training  accuracy 1\n",
      "step 85800 , loss : 0.463532\n",
      "step 85800 , validation  accuracy 0.789474\n",
      "step 85800 , validation loss : 0.605798\n",
      "step 85800 , test  accuracy 0.820513\n",
      "step 85800 , test loss : 0.612635\n",
      "step 85900 , training  accuracy 1\n",
      "step 85900 , loss : 0.463444\n",
      "step 85900 , validation  accuracy 0.789474\n",
      "step 85900 , validation loss : 0.604391\n",
      "step 85900 , test  accuracy 0.820513\n",
      "step 85900 , test loss : 0.614697\n",
      "step 86000 , training  accuracy 1\n",
      "step 86000 , loss : 0.463469\n",
      "step 86000 , validation  accuracy 0.815789\n",
      "step 86000 , validation loss : 0.603771\n",
      "step 86000 , test  accuracy 0.820513\n",
      "step 86000 , test loss : 0.617614\n",
      "step 86100 , training  accuracy 1\n",
      "step 86100 , loss : 0.463284\n",
      "step 86100 , validation  accuracy 0.815789\n",
      "step 86100 , validation loss : 0.604414\n",
      "step 86100 , test  accuracy 0.820513\n",
      "step 86100 , test loss : 0.620794\n",
      "step 86200 , training  accuracy 1\n",
      "step 86200 , loss : 0.463385\n",
      "step 86200 , validation  accuracy 0.789474\n",
      "step 86200 , validation loss : 0.605521\n",
      "step 86200 , test  accuracy 0.820513\n",
      "step 86200 , test loss : 0.623994\n",
      "step 86300 , training  accuracy 1\n",
      "step 86300 , loss : 0.463139\n",
      "step 86300 , validation  accuracy 0.789474\n",
      "step 86300 , validation loss : 0.60631\n",
      "step 86300 , test  accuracy 0.794872\n",
      "step 86300 , test loss : 0.62586\n",
      "step 86400 , training  accuracy 1\n",
      "step 86400 , loss : 0.463188\n",
      "step 86400 , validation  accuracy 0.789474\n",
      "step 86400 , validation loss : 0.606962\n",
      "step 86400 , test  accuracy 0.794872\n",
      "step 86400 , test loss : 0.626655\n",
      "step 86500 , training  accuracy 1\n",
      "step 86500 , loss : 0.463251\n",
      "step 86500 , validation  accuracy 0.789474\n",
      "step 86500 , validation loss : 0.607742\n",
      "step 86500 , test  accuracy 0.794872\n",
      "step 86500 , test loss : 0.627565\n",
      "step 86600 , training  accuracy 1\n",
      "step 86600 , loss : 0.462818\n",
      "step 86600 , validation  accuracy 0.815789\n",
      "step 86600 , validation loss : 0.606857\n",
      "step 86600 , test  accuracy 0.794872\n",
      "step 86600 , test loss : 0.626891\n",
      "step 86700 , training  accuracy 1\n",
      "step 86700 , loss : 0.462827\n",
      "step 86700 , validation  accuracy 0.815789\n",
      "step 86700 , validation loss : 0.604921\n",
      "step 86700 , test  accuracy 0.820513\n",
      "step 86700 , test loss : 0.625482\n",
      "step 86800 , training  accuracy 1\n",
      "step 86800 , loss : 0.462779\n",
      "step 86800 , validation  accuracy 0.815789\n",
      "step 86800 , validation loss : 0.604583\n",
      "step 86800 , test  accuracy 0.820513\n",
      "step 86800 , test loss : 0.625704\n",
      "step 86900 , training  accuracy 1\n",
      "step 86900 , loss : 0.462981\n",
      "step 86900 , validation  accuracy 0.842105\n",
      "step 86900 , validation loss : 0.604387\n",
      "step 86900 , test  accuracy 0.820513\n",
      "step 86900 , test loss : 0.625993\n",
      "step 87000 , training  accuracy 1\n",
      "step 87000 , loss : 0.462994\n",
      "step 87000 , validation  accuracy 0.842105\n",
      "step 87000 , validation loss : 0.60384\n",
      "step 87000 , test  accuracy 0.820513\n",
      "step 87000 , test loss : 0.62585\n",
      "step 87100 , training  accuracy 1\n",
      "step 87100 , loss : 0.463098\n",
      "step 87100 , validation  accuracy 0.842105\n",
      "step 87100 , validation loss : 0.603222\n",
      "step 87100 , test  accuracy 0.820513\n",
      "step 87100 , test loss : 0.625669\n",
      "step 87200 , training  accuracy 1\n",
      "step 87200 , loss : 0.463216\n",
      "step 87200 , validation  accuracy 0.815789\n",
      "step 87200 , validation loss : 0.60237\n",
      "step 87200 , test  accuracy 0.820513\n",
      "step 87200 , test loss : 0.625165\n",
      "step 87300 , training  accuracy 1\n",
      "step 87300 , loss : 0.463267\n",
      "step 87300 , validation  accuracy 0.815789\n",
      "step 87300 , validation loss : 0.601768\n",
      "step 87300 , test  accuracy 0.820513\n",
      "step 87300 , test loss : 0.625042\n",
      "step 87400 , training  accuracy 1\n",
      "step 87400 , loss : 0.463772\n",
      "step 87400 , validation  accuracy 0.815789\n",
      "step 87400 , validation loss : 0.602292\n",
      "step 87400 , test  accuracy 0.820513\n",
      "step 87400 , test loss : 0.624156\n",
      "step 87500 , training  accuracy 1\n",
      "step 87500 , loss : 0.463556\n",
      "step 87500 , validation  accuracy 0.789474\n",
      "step 87500 , validation loss : 0.603003\n",
      "step 87500 , test  accuracy 0.820513\n",
      "step 87500 , test loss : 0.623317\n",
      "step 87600 , training  accuracy 1\n",
      "step 87600 , loss : 0.46382\n",
      "step 87600 , validation  accuracy 0.789474\n",
      "step 87600 , validation loss : 0.604038\n",
      "step 87600 , test  accuracy 0.820513\n",
      "step 87600 , test loss : 0.622934\n",
      "step 87700 , training  accuracy 1\n",
      "step 87700 , loss : 0.463588\n",
      "step 87700 , validation  accuracy 0.789474\n",
      "step 87700 , validation loss : 0.603823\n",
      "step 87700 , test  accuracy 0.820513\n",
      "step 87700 , test loss : 0.622157\n",
      "step 87800 , training  accuracy 1\n",
      "step 87800 , loss : 0.463656\n",
      "step 87800 , validation  accuracy 0.789474\n",
      "step 87800 , validation loss : 0.601467\n",
      "step 87800 , test  accuracy 0.820513\n",
      "step 87800 , test loss : 0.620894\n",
      "step 87900 , training  accuracy 1\n",
      "step 87900 , loss : 0.463487\n",
      "step 87900 , validation  accuracy 0.789474\n",
      "step 87900 , validation loss : 0.599664\n",
      "step 87900 , test  accuracy 0.820513\n",
      "step 87900 , test loss : 0.620697\n",
      "step 88000 , training  accuracy 1\n",
      "step 88000 , loss : 0.463495\n",
      "step 88000 , validation  accuracy 0.815789\n",
      "step 88000 , validation loss : 0.598963\n",
      "step 88000 , test  accuracy 0.820513\n",
      "step 88000 , test loss : 0.620595\n",
      "step 88100 , training  accuracy 1\n",
      "step 88100 , loss : 0.463574\n",
      "step 88100 , validation  accuracy 0.815789\n",
      "step 88100 , validation loss : 0.598294\n",
      "step 88100 , test  accuracy 0.820513\n",
      "step 88100 , test loss : 0.620067\n",
      "step 88200 , training  accuracy 1\n",
      "step 88200 , loss : 0.463616\n",
      "step 88200 , validation  accuracy 0.815789\n",
      "step 88200 , validation loss : 0.597453\n",
      "step 88200 , test  accuracy 0.820513\n",
      "step 88200 , test loss : 0.619672\n",
      "step 88300 , training  accuracy 1\n",
      "step 88300 , loss : 0.463516\n",
      "step 88300 , validation  accuracy 0.842105\n",
      "step 88300 , validation loss : 0.596838\n",
      "step 88300 , test  accuracy 0.820513\n",
      "step 88300 , test loss : 0.619299\n",
      "step 88400 , training  accuracy 1\n",
      "step 88400 , loss : 0.463589\n",
      "step 88400 , validation  accuracy 0.815789\n",
      "step 88400 , validation loss : 0.597197\n",
      "step 88400 , test  accuracy 0.820513\n",
      "step 88400 , test loss : 0.618486\n",
      "step 88500 , training  accuracy 1\n",
      "step 88500 , loss : 0.463604\n",
      "step 88500 , validation  accuracy 0.815789\n",
      "step 88500 , validation loss : 0.598046\n",
      "step 88500 , test  accuracy 0.820513\n",
      "step 88500 , test loss : 0.617761\n",
      "step 88600 , training  accuracy 1\n",
      "step 88600 , loss : 0.463817\n",
      "step 88600 , validation  accuracy 0.789474\n",
      "step 88600 , validation loss : 0.599392\n",
      "step 88600 , test  accuracy 0.820513\n",
      "step 88600 , test loss : 0.617118\n",
      "step 88700 , training  accuracy 1\n",
      "step 88700 , loss : 0.464406\n",
      "step 88700 , validation  accuracy 0.815789\n",
      "step 88700 , validation loss : 0.600302\n",
      "step 88700 , test  accuracy 0.820513\n",
      "step 88700 , test loss : 0.617069\n",
      "step 88800 , training  accuracy 1\n",
      "step 88800 , loss : 0.463976\n",
      "step 88800 , validation  accuracy 0.789474\n",
      "step 88800 , validation loss : 0.600494\n",
      "step 88800 , test  accuracy 0.820513\n",
      "step 88800 , test loss : 0.61765\n",
      "step 88900 , training  accuracy 1\n",
      "step 88900 , loss : 0.46377\n",
      "step 88900 , validation  accuracy 0.789474\n",
      "step 88900 , validation loss : 0.60057\n",
      "step 88900 , test  accuracy 0.820513\n",
      "step 88900 , test loss : 0.617176\n",
      "step 89000 , training  accuracy 1\n",
      "step 89000 , loss : 0.464016\n",
      "step 89000 , validation  accuracy 0.815789\n",
      "step 89000 , validation loss : 0.600516\n",
      "step 89000 , test  accuracy 0.820513\n",
      "step 89000 , test loss : 0.616361\n",
      "step 89100 , training  accuracy 1\n",
      "step 89100 , loss : 0.463875\n",
      "step 89100 , validation  accuracy 0.842105\n",
      "step 89100 , validation loss : 0.60076\n",
      "step 89100 , test  accuracy 0.820513\n",
      "step 89100 , test loss : 0.616055\n",
      "step 89200 , training  accuracy 1\n",
      "step 89200 , loss : 0.463823\n",
      "step 89200 , validation  accuracy 0.842105\n",
      "step 89200 , validation loss : 0.60086\n",
      "step 89200 , test  accuracy 0.820513\n",
      "step 89200 , test loss : 0.615791\n",
      "step 89300 , training  accuracy 1\n",
      "step 89300 , loss : 0.463589\n",
      "step 89300 , validation  accuracy 0.842105\n",
      "step 89300 , validation loss : 0.60157\n",
      "step 89300 , test  accuracy 0.820513\n",
      "step 89300 , test loss : 0.61619\n",
      "step 89400 , training  accuracy 1\n",
      "step 89400 , loss : 0.463224\n",
      "step 89400 , validation  accuracy 0.842105\n",
      "step 89400 , validation loss : 0.603055\n",
      "step 89400 , test  accuracy 0.820513\n",
      "step 89400 , test loss : 0.617064\n",
      "step 89500 , training  accuracy 1\n",
      "step 89500 , loss : 0.463341\n",
      "step 89500 , validation  accuracy 0.842105\n",
      "step 89500 , validation loss : 0.603278\n",
      "step 89500 , test  accuracy 0.846154\n",
      "step 89500 , test loss : 0.616602\n",
      "step 89600 , training  accuracy 1\n",
      "step 89600 , loss : 0.46308\n",
      "step 89600 , validation  accuracy 0.842105\n",
      "step 89600 , validation loss : 0.602758\n",
      "step 89600 , test  accuracy 0.846154\n",
      "step 89600 , test loss : 0.615095\n",
      "step 89700 , training  accuracy 1\n",
      "step 89700 , loss : 0.462966\n",
      "step 89700 , validation  accuracy 0.842105\n",
      "step 89700 , validation loss : 0.601556\n",
      "step 89700 , test  accuracy 0.846154\n",
      "step 89700 , test loss : 0.613015\n",
      "step 89800 , training  accuracy 1\n",
      "step 89800 , loss : 0.463035\n",
      "step 89800 , validation  accuracy 0.815789\n",
      "step 89800 , validation loss : 0.600464\n",
      "step 89800 , test  accuracy 0.820513\n",
      "step 89800 , test loss : 0.611467\n",
      "step 89900 , training  accuracy 1\n",
      "step 89900 , loss : 0.462973\n",
      "step 89900 , validation  accuracy 0.815789\n",
      "step 89900 , validation loss : 0.60006\n",
      "step 89900 , test  accuracy 0.820513\n",
      "step 89900 , test loss : 0.610084\n",
      "step 90000 , training  accuracy 1\n",
      "step 90000 , loss : 0.463256\n",
      "step 90000 , validation  accuracy 0.815789\n",
      "step 90000 , validation loss : 0.600114\n",
      "step 90000 , test  accuracy 0.820513\n",
      "step 90000 , test loss : 0.609169\n",
      "step 90100 , training  accuracy 1\n",
      "step 90100 , loss : 0.463206\n",
      "step 90100 , validation  accuracy 0.815789\n",
      "step 90100 , validation loss : 0.60004\n",
      "step 90100 , test  accuracy 0.820513\n",
      "step 90100 , test loss : 0.608376\n",
      "step 90200 , training  accuracy 1\n",
      "step 90200 , loss : 0.463293\n",
      "step 90200 , validation  accuracy 0.815789\n",
      "step 90200 , validation loss : 0.600249\n",
      "step 90200 , test  accuracy 0.820513\n",
      "step 90200 , test loss : 0.607919\n",
      "step 90300 , training  accuracy 1\n",
      "step 90300 , loss : 0.463028\n",
      "step 90300 , validation  accuracy 0.842105\n",
      "step 90300 , validation loss : 0.600404\n",
      "step 90300 , test  accuracy 0.820513\n",
      "step 90300 , test loss : 0.607714\n",
      "step 90400 , training  accuracy 1\n",
      "step 90400 , loss : 0.463115\n",
      "step 90400 , validation  accuracy 0.842105\n",
      "step 90400 , validation loss : 0.600732\n",
      "step 90400 , test  accuracy 0.820513\n",
      "step 90400 , test loss : 0.607986\n",
      "step 90500 , training  accuracy 1\n",
      "step 90500 , loss : 0.463476\n",
      "step 90500 , validation  accuracy 0.842105\n",
      "step 90500 , validation loss : 0.601326\n",
      "step 90500 , test  accuracy 0.820513\n",
      "step 90500 , test loss : 0.608336\n",
      "step 90600 , training  accuracy 1\n",
      "step 90600 , loss : 0.463885\n",
      "step 90600 , validation  accuracy 0.842105\n",
      "step 90600 , validation loss : 0.602203\n",
      "step 90600 , test  accuracy 0.820513\n",
      "step 90600 , test loss : 0.608014\n",
      "step 90700 , training  accuracy 1\n",
      "step 90700 , loss : 0.463392\n",
      "step 90700 , validation  accuracy 0.815789\n",
      "step 90700 , validation loss : 0.602699\n",
      "step 90700 , test  accuracy 0.820513\n",
      "step 90700 , test loss : 0.60811\n",
      "step 90800 , training  accuracy 1\n",
      "step 90800 , loss : 0.463226\n",
      "step 90800 , validation  accuracy 0.815789\n",
      "step 90800 , validation loss : 0.603321\n",
      "step 90800 , test  accuracy 0.820513\n",
      "step 90800 , test loss : 0.608528\n",
      "step 90900 , training  accuracy 1\n",
      "step 90900 , loss : 0.463408\n",
      "step 90900 , validation  accuracy 0.815789\n",
      "step 90900 , validation loss : 0.603461\n",
      "step 90900 , test  accuracy 0.820513\n",
      "step 90900 , test loss : 0.608758\n",
      "step 91000 , training  accuracy 1\n",
      "step 91000 , loss : 0.463102\n",
      "step 91000 , validation  accuracy 0.789474\n",
      "step 91000 , validation loss : 0.603607\n",
      "step 91000 , test  accuracy 0.820513\n",
      "step 91000 , test loss : 0.609422\n",
      "step 91100 , training  accuracy 1\n",
      "step 91100 , loss : 0.463231\n",
      "step 91100 , validation  accuracy 0.789474\n",
      "step 91100 , validation loss : 0.603833\n",
      "step 91100 , test  accuracy 0.820513\n",
      "step 91100 , test loss : 0.610064\n",
      "step 91200 , training  accuracy 1\n",
      "step 91200 , loss : 0.463237\n",
      "step 91200 , validation  accuracy 0.815789\n",
      "step 91200 , validation loss : 0.603522\n",
      "step 91200 , test  accuracy 0.820513\n",
      "step 91200 , test loss : 0.610519\n",
      "step 91300 , training  accuracy 1\n",
      "step 91300 , loss : 0.463411\n",
      "step 91300 , validation  accuracy 0.815789\n",
      "step 91300 , validation loss : 0.603995\n",
      "step 91300 , test  accuracy 0.820513\n",
      "step 91300 , test loss : 0.610711\n",
      "step 91400 , training  accuracy 1\n",
      "step 91400 , loss : 0.463843\n",
      "step 91400 , validation  accuracy 0.815789\n",
      "step 91400 , validation loss : 0.604161\n",
      "step 91400 , test  accuracy 0.820513\n",
      "step 91400 , test loss : 0.61003\n",
      "step 91500 , training  accuracy 1\n",
      "step 91500 , loss : 0.464146\n",
      "step 91500 , validation  accuracy 0.815789\n",
      "step 91500 , validation loss : 0.60469\n",
      "step 91500 , test  accuracy 0.820513\n",
      "step 91500 , test loss : 0.609637\n",
      "step 91600 , training  accuracy 1\n",
      "step 91600 , loss : 0.463839\n",
      "step 91600 , validation  accuracy 0.815789\n",
      "step 91600 , validation loss : 0.605072\n",
      "step 91600 , test  accuracy 0.820513\n",
      "step 91600 , test loss : 0.609715\n",
      "step 91700 , training  accuracy 1\n",
      "step 91700 , loss : 0.463893\n",
      "step 91700 , validation  accuracy 0.815789\n",
      "step 91700 , validation loss : 0.605115\n",
      "step 91700 , test  accuracy 0.820513\n",
      "step 91700 , test loss : 0.610068\n",
      "step 91800 , training  accuracy 1\n",
      "step 91800 , loss : 0.464538\n",
      "step 91800 , validation  accuracy 0.789474\n",
      "step 91800 , validation loss : 0.604788\n",
      "step 91800 , test  accuracy 0.820513\n",
      "step 91800 , test loss : 0.610964\n",
      "step 91900 , training  accuracy 1\n",
      "step 91900 , loss : 0.464041\n",
      "step 91900 , validation  accuracy 0.789474\n",
      "step 91900 , validation loss : 0.604264\n",
      "step 91900 , test  accuracy 0.820513\n",
      "step 91900 , test loss : 0.61176\n",
      "step 92000 , training  accuracy 1\n",
      "step 92000 , loss : 0.463688\n",
      "step 92000 , validation  accuracy 0.789474\n",
      "step 92000 , validation loss : 0.602966\n",
      "step 92000 , test  accuracy 0.846154\n",
      "step 92000 , test loss : 0.611987\n",
      "step 92100 , training  accuracy 1\n",
      "step 92100 , loss : 0.463612\n",
      "step 92100 , validation  accuracy 0.789474\n",
      "step 92100 , validation loss : 0.602284\n",
      "step 92100 , test  accuracy 0.846154\n",
      "step 92100 , test loss : 0.612584\n",
      "step 92200 , training  accuracy 1\n",
      "step 92200 , loss : 0.463811\n",
      "step 92200 , validation  accuracy 0.815789\n",
      "step 92200 , validation loss : 0.601748\n",
      "step 92200 , test  accuracy 0.846154\n",
      "step 92200 , test loss : 0.613473\n",
      "step 92300 , training  accuracy 1\n",
      "step 92300 , loss : 0.463571\n",
      "step 92300 , validation  accuracy 0.815789\n",
      "step 92300 , validation loss : 0.600932\n",
      "step 92300 , test  accuracy 0.846154\n",
      "step 92300 , test loss : 0.612472\n",
      "step 92400 , training  accuracy 1\n",
      "step 92400 , loss : 0.463471\n",
      "step 92400 , validation  accuracy 0.815789\n",
      "step 92400 , validation loss : 0.600704\n",
      "step 92400 , test  accuracy 0.820513\n",
      "step 92400 , test loss : 0.611349\n",
      "step 92500 , training  accuracy 1\n",
      "step 92500 , loss : 0.463465\n",
      "step 92500 , validation  accuracy 0.815789\n",
      "step 92500 , validation loss : 0.601359\n",
      "step 92500 , test  accuracy 0.820513\n",
      "step 92500 , test loss : 0.611528\n",
      "step 92600 , training  accuracy 1\n",
      "step 92600 , loss : 0.463599\n",
      "step 92600 , validation  accuracy 0.815789\n",
      "step 92600 , validation loss : 0.602231\n",
      "step 92600 , test  accuracy 0.820513\n",
      "step 92600 , test loss : 0.612227\n",
      "step 92700 , training  accuracy 1\n",
      "step 92700 , loss : 0.463498\n",
      "step 92700 , validation  accuracy 0.815789\n",
      "step 92700 , validation loss : 0.602667\n",
      "step 92700 , test  accuracy 0.820513\n",
      "step 92700 , test loss : 0.613199\n",
      "step 92800 , training  accuracy 1\n",
      "step 92800 , loss : 0.46338\n",
      "step 92800 , validation  accuracy 0.815789\n",
      "step 92800 , validation loss : 0.602151\n",
      "step 92800 , test  accuracy 0.820513\n",
      "step 92800 , test loss : 0.614238\n",
      "step 92900 , training  accuracy 1\n",
      "step 92900 , loss : 0.464199\n",
      "step 92900 , validation  accuracy 0.842105\n",
      "step 92900 , validation loss : 0.601598\n",
      "step 92900 , test  accuracy 0.820513\n",
      "step 92900 , test loss : 0.615018\n",
      "step 93000 , training  accuracy 1\n",
      "step 93000 , loss : 0.463428\n",
      "step 93000 , validation  accuracy 0.815789\n",
      "step 93000 , validation loss : 0.601354\n",
      "step 93000 , test  accuracy 0.820513\n",
      "step 93000 , test loss : 0.615322\n",
      "step 93100 , training  accuracy 1\n",
      "step 93100 , loss : 0.463591\n",
      "step 93100 , validation  accuracy 0.815789\n",
      "step 93100 , validation loss : 0.600561\n",
      "step 93100 , test  accuracy 0.794872\n",
      "step 93100 , test loss : 0.615444\n",
      "step 93200 , training  accuracy 1\n",
      "step 93200 , loss : 0.463609\n",
      "step 93200 , validation  accuracy 0.815789\n",
      "step 93200 , validation loss : 0.599945\n",
      "step 93200 , test  accuracy 0.794872\n",
      "step 93200 , test loss : 0.616305\n",
      "step 93300 , training  accuracy 1\n",
      "step 93300 , loss : 0.46372\n",
      "step 93300 , validation  accuracy 0.815789\n",
      "step 93300 , validation loss : 0.599684\n",
      "step 93300 , test  accuracy 0.794872\n",
      "step 93300 , test loss : 0.61711\n",
      "step 93400 , training  accuracy 1\n",
      "step 93400 , loss : 0.463758\n",
      "step 93400 , validation  accuracy 0.815789\n",
      "step 93400 , validation loss : 0.600429\n",
      "step 93400 , test  accuracy 0.820513\n",
      "step 93400 , test loss : 0.618057\n",
      "step 93500 , training  accuracy 1\n",
      "step 93500 , loss : 0.463681\n",
      "step 93500 , validation  accuracy 0.842105\n",
      "step 93500 , validation loss : 0.601381\n",
      "step 93500 , test  accuracy 0.820513\n",
      "step 93500 , test loss : 0.618919\n",
      "step 93600 , training  accuracy 1\n",
      "step 93600 , loss : 0.463651\n",
      "step 93600 , validation  accuracy 0.842105\n",
      "step 93600 , validation loss : 0.601606\n",
      "step 93600 , test  accuracy 0.794872\n",
      "step 93600 , test loss : 0.619205\n",
      "step 93700 , training  accuracy 1\n",
      "step 93700 , loss : 0.463702\n",
      "step 93700 , validation  accuracy 0.842105\n",
      "step 93700 , validation loss : 0.60168\n",
      "step 93700 , test  accuracy 0.794872\n",
      "step 93700 , test loss : 0.619476\n",
      "step 93800 , training  accuracy 1\n",
      "step 93800 , loss : 0.463426\n",
      "step 93800 , validation  accuracy 0.842105\n",
      "step 93800 , validation loss : 0.602161\n",
      "step 93800 , test  accuracy 0.794872\n",
      "step 93800 , test loss : 0.620123\n",
      "step 93900 , training  accuracy 1\n",
      "step 93900 , loss : 0.463633\n",
      "step 93900 , validation  accuracy 0.842105\n",
      "step 93900 , validation loss : 0.602992\n",
      "step 93900 , test  accuracy 0.794872\n",
      "step 93900 , test loss : 0.620818\n",
      "step 94000 , training  accuracy 1\n",
      "step 94000 , loss : 0.463678\n",
      "step 94000 , validation  accuracy 0.815789\n",
      "step 94000 , validation loss : 0.603833\n",
      "step 94000 , test  accuracy 0.794872\n",
      "step 94000 , test loss : 0.621189\n",
      "step 94100 , training  accuracy 1\n",
      "step 94100 , loss : 0.463658\n",
      "step 94100 , validation  accuracy 0.815789\n",
      "step 94100 , validation loss : 0.604653\n",
      "step 94100 , test  accuracy 0.794872\n",
      "step 94100 , test loss : 0.62168\n",
      "step 94200 , training  accuracy 1\n",
      "step 94200 , loss : 0.463577\n",
      "step 94200 , validation  accuracy 0.815789\n",
      "step 94200 , validation loss : 0.605392\n",
      "step 94200 , test  accuracy 0.794872\n",
      "step 94200 , test loss : 0.622164\n",
      "step 94300 , training  accuracy 1\n",
      "step 94300 , loss : 0.4636\n",
      "step 94300 , validation  accuracy 0.789474\n",
      "step 94300 , validation loss : 0.606356\n",
      "step 94300 , test  accuracy 0.794872\n",
      "step 94300 , test loss : 0.622479\n",
      "step 94400 , training  accuracy 1\n",
      "step 94400 , loss : 0.463211\n",
      "step 94400 , validation  accuracy 0.789474\n",
      "step 94400 , validation loss : 0.607377\n",
      "step 94400 , test  accuracy 0.794872\n",
      "step 94400 , test loss : 0.622972\n",
      "step 94500 , training  accuracy 1\n",
      "step 94500 , loss : 0.463233\n",
      "step 94500 , validation  accuracy 0.789474\n",
      "step 94500 , validation loss : 0.607689\n",
      "step 94500 , test  accuracy 0.794872\n",
      "step 94500 , test loss : 0.623476\n",
      "step 94600 , training  accuracy 1\n",
      "step 94600 , loss : 0.463243\n",
      "step 94600 , validation  accuracy 0.789474\n",
      "step 94600 , validation loss : 0.608343\n",
      "step 94600 , test  accuracy 0.794872\n",
      "step 94600 , test loss : 0.623958\n",
      "step 94700 , training  accuracy 1\n",
      "step 94700 , loss : 0.463554\n",
      "step 94700 , validation  accuracy 0.789474\n",
      "step 94700 , validation loss : 0.608951\n",
      "step 94700 , test  accuracy 0.794872\n",
      "step 94700 , test loss : 0.624524\n",
      "step 94800 , training  accuracy 1\n",
      "step 94800 , loss : 0.462912\n",
      "step 94800 , validation  accuracy 0.789474\n",
      "step 94800 , validation loss : 0.609986\n",
      "step 94800 , test  accuracy 0.794872\n",
      "step 94800 , test loss : 0.625542\n",
      "step 94900 , training  accuracy 1\n",
      "step 94900 , loss : 0.463074\n",
      "step 94900 , validation  accuracy 0.789474\n",
      "step 94900 , validation loss : 0.610658\n",
      "step 94900 , test  accuracy 0.794872\n",
      "step 94900 , test loss : 0.625784\n",
      "step 95000 , training  accuracy 1\n",
      "step 95000 , loss : 0.463226\n",
      "step 95000 , validation  accuracy 0.815789\n",
      "step 95000 , validation loss : 0.609962\n",
      "step 95000 , test  accuracy 0.794872\n",
      "step 95000 , test loss : 0.62592\n",
      "step 95100 , training  accuracy 1\n",
      "step 95100 , loss : 0.46294\n",
      "step 95100 , validation  accuracy 0.815789\n",
      "step 95100 , validation loss : 0.608101\n",
      "step 95100 , test  accuracy 0.794872\n",
      "step 95100 , test loss : 0.626064\n",
      "step 95200 , training  accuracy 1\n",
      "step 95200 , loss : 0.463014\n",
      "step 95200 , validation  accuracy 0.842105\n",
      "step 95200 , validation loss : 0.60665\n",
      "step 95200 , test  accuracy 0.794872\n",
      "step 95200 , test loss : 0.62587\n",
      "step 95300 , training  accuracy 1\n",
      "step 95300 , loss : 0.46285\n",
      "step 95300 , validation  accuracy 0.842105\n",
      "step 95300 , validation loss : 0.606038\n",
      "step 95300 , test  accuracy 0.794872\n",
      "step 95300 , test loss : 0.626885\n",
      "step 95400 , training  accuracy 1\n",
      "step 95400 , loss : 0.46315\n",
      "step 95400 , validation  accuracy 0.842105\n",
      "step 95400 , validation loss : 0.605303\n",
      "step 95400 , test  accuracy 0.794872\n",
      "step 95400 , test loss : 0.627217\n",
      "step 95500 , training  accuracy 1\n",
      "step 95500 , loss : 0.463299\n",
      "step 95500 , validation  accuracy 0.842105\n",
      "step 95500 , validation loss : 0.604473\n",
      "step 95500 , test  accuracy 0.794872\n",
      "step 95500 , test loss : 0.626562\n",
      "step 95600 , training  accuracy 1\n",
      "step 95600 , loss : 0.463184\n",
      "step 95600 , validation  accuracy 0.842105\n",
      "step 95600 , validation loss : 0.604342\n",
      "step 95600 , test  accuracy 0.794872\n",
      "step 95600 , test loss : 0.626318\n",
      "step 95700 , training  accuracy 1\n",
      "step 95700 , loss : 0.463133\n",
      "step 95700 , validation  accuracy 0.842105\n",
      "step 95700 , validation loss : 0.604442\n",
      "step 95700 , test  accuracy 0.794872\n",
      "step 95700 , test loss : 0.626423\n",
      "step 95800 , training  accuracy 1\n",
      "step 95800 , loss : 0.463589\n",
      "step 95800 , validation  accuracy 0.842105\n",
      "step 95800 , validation loss : 0.604733\n",
      "step 95800 , test  accuracy 0.794872\n",
      "step 95800 , test loss : 0.626608\n",
      "step 95900 , training  accuracy 1\n",
      "step 95900 , loss : 0.463665\n",
      "step 95900 , validation  accuracy 0.842105\n",
      "step 95900 , validation loss : 0.605312\n",
      "step 95900 , test  accuracy 0.794872\n",
      "step 95900 , test loss : 0.627404\n",
      "step 96000 , training  accuracy 1\n",
      "step 96000 , loss : 0.463902\n",
      "step 96000 , validation  accuracy 0.842105\n",
      "step 96000 , validation loss : 0.605628\n",
      "step 96000 , test  accuracy 0.794872\n",
      "step 96000 , test loss : 0.62715\n",
      "step 96100 , training  accuracy 1\n",
      "step 96100 , loss : 0.463462\n",
      "step 96100 , validation  accuracy 0.842105\n",
      "step 96100 , validation loss : 0.605628\n",
      "step 96100 , test  accuracy 0.820513\n",
      "step 96100 , test loss : 0.625177\n",
      "step 96200 , training  accuracy 1\n",
      "step 96200 , loss : 0.46364\n",
      "step 96200 , validation  accuracy 0.815789\n",
      "step 96200 , validation loss : 0.605618\n",
      "step 96200 , test  accuracy 0.820513\n",
      "step 96200 , test loss : 0.621634\n",
      "step 96300 , training  accuracy 1\n",
      "step 96300 , loss : 0.463475\n",
      "step 96300 , validation  accuracy 0.815789\n",
      "step 96300 , validation loss : 0.606122\n",
      "step 96300 , test  accuracy 0.820513\n",
      "step 96300 , test loss : 0.619087\n",
      "step 96400 , training  accuracy 1\n",
      "step 96400 , loss : 0.463649\n",
      "step 96400 , validation  accuracy 0.815789\n",
      "step 96400 , validation loss : 0.60701\n",
      "step 96400 , test  accuracy 0.820513\n",
      "step 96400 , test loss : 0.617497\n",
      "step 96500 , training  accuracy 1\n",
      "step 96500 , loss : 0.464\n",
      "step 96500 , validation  accuracy 0.815789\n",
      "step 96500 , validation loss : 0.607944\n",
      "step 96500 , test  accuracy 0.820513\n",
      "step 96500 , test loss : 0.616082\n",
      "step 96600 , training  accuracy 1\n",
      "step 96600 , loss : 0.463898\n",
      "step 96600 , validation  accuracy 0.815789\n",
      "step 96600 , validation loss : 0.607571\n",
      "step 96600 , test  accuracy 0.820513\n",
      "step 96600 , test loss : 0.614143\n",
      "step 96700 , training  accuracy 1\n",
      "step 96700 , loss : 0.463449\n",
      "step 96700 , validation  accuracy 0.815789\n",
      "step 96700 , validation loss : 0.606863\n",
      "step 96700 , test  accuracy 0.820513\n",
      "step 96700 , test loss : 0.613248\n",
      "step 96800 , training  accuracy 1\n",
      "step 96800 , loss : 0.463828\n",
      "step 96800 , validation  accuracy 0.815789\n",
      "step 96800 , validation loss : 0.606964\n",
      "step 96800 , test  accuracy 0.820513\n",
      "step 96800 , test loss : 0.612653\n",
      "step 96900 , training  accuracy 1\n",
      "step 96900 , loss : 0.463886\n",
      "step 96900 , validation  accuracy 0.815789\n",
      "step 96900 , validation loss : 0.606078\n",
      "step 96900 , test  accuracy 0.820513\n",
      "step 96900 , test loss : 0.612142\n",
      "step 97000 , training  accuracy 1\n",
      "step 97000 , loss : 0.463702\n",
      "step 97000 , validation  accuracy 0.815789\n",
      "step 97000 , validation loss : 0.604982\n",
      "step 97000 , test  accuracy 0.820513\n",
      "step 97000 , test loss : 0.611886\n",
      "step 97100 , training  accuracy 1\n",
      "step 97100 , loss : 0.463359\n",
      "step 97100 , validation  accuracy 0.815789\n",
      "step 97100 , validation loss : 0.603488\n",
      "step 97100 , test  accuracy 0.820513\n",
      "step 97100 , test loss : 0.612495\n",
      "step 97200 , training  accuracy 1\n",
      "step 97200 , loss : 0.463517\n",
      "step 97200 , validation  accuracy 0.815789\n",
      "step 97200 , validation loss : 0.602617\n",
      "step 97200 , test  accuracy 0.820513\n",
      "step 97200 , test loss : 0.613634\n",
      "step 97300 , training  accuracy 1\n",
      "step 97300 , loss : 0.463474\n",
      "step 97300 , validation  accuracy 0.842105\n",
      "step 97300 , validation loss : 0.603127\n",
      "step 97300 , test  accuracy 0.820513\n",
      "step 97300 , test loss : 0.61444\n",
      "step 97400 , training  accuracy 1\n",
      "step 97400 , loss : 0.463403\n",
      "step 97400 , validation  accuracy 0.842105\n",
      "step 97400 , validation loss : 0.603827\n",
      "step 97400 , test  accuracy 0.820513\n",
      "step 97400 , test loss : 0.615172\n",
      "step 97500 , training  accuracy 1\n",
      "step 97500 , loss : 0.463257\n",
      "step 97500 , validation  accuracy 0.815789\n",
      "step 97500 , validation loss : 0.604595\n",
      "step 97500 , test  accuracy 0.820513\n",
      "step 97500 , test loss : 0.615632\n",
      "step 97600 , training  accuracy 1\n",
      "step 97600 , loss : 0.463431\n",
      "step 97600 , validation  accuracy 0.815789\n",
      "step 97600 , validation loss : 0.60581\n",
      "step 97600 , test  accuracy 0.820513\n",
      "step 97600 , test loss : 0.616213\n",
      "step 97700 , training  accuracy 1\n",
      "step 97700 , loss : 0.463769\n",
      "step 97700 , validation  accuracy 0.815789\n",
      "step 97700 , validation loss : 0.606413\n",
      "step 97700 , test  accuracy 0.820513\n",
      "step 97700 , test loss : 0.616402\n",
      "step 97800 , training  accuracy 1\n",
      "step 97800 , loss : 0.463507\n",
      "step 97800 , validation  accuracy 0.842105\n",
      "step 97800 , validation loss : 0.606611\n",
      "step 97800 , test  accuracy 0.820513\n",
      "step 97800 , test loss : 0.615421\n",
      "step 97900 , training  accuracy 1\n",
      "step 97900 , loss : 0.46364\n",
      "step 97900 , validation  accuracy 0.842105\n",
      "step 97900 , validation loss : 0.606524\n",
      "step 97900 , test  accuracy 0.820513\n",
      "step 97900 , test loss : 0.614816\n",
      "step 98000 , training  accuracy 1\n",
      "step 98000 , loss : 0.463854\n",
      "step 98000 , validation  accuracy 0.842105\n",
      "step 98000 , validation loss : 0.606207\n",
      "step 98000 , test  accuracy 0.820513\n",
      "step 98000 , test loss : 0.614194\n",
      "step 98100 , training  accuracy 1\n",
      "step 98100 , loss : 0.463853\n",
      "step 98100 , validation  accuracy 0.842105\n",
      "step 98100 , validation loss : 0.605941\n",
      "step 98100 , test  accuracy 0.820513\n",
      "step 98100 , test loss : 0.613011\n",
      "step 98200 , training  accuracy 1\n",
      "step 98200 , loss : 0.463484\n",
      "step 98200 , validation  accuracy 0.842105\n",
      "step 98200 , validation loss : 0.606174\n",
      "step 98200 , test  accuracy 0.820513\n",
      "step 98200 , test loss : 0.611604\n",
      "step 98300 , training  accuracy 1\n",
      "step 98300 , loss : 0.464448\n",
      "step 98300 , validation  accuracy 0.842105\n",
      "step 98300 , validation loss : 0.606282\n",
      "step 98300 , test  accuracy 0.820513\n",
      "step 98300 , test loss : 0.610961\n",
      "step 98400 , training  accuracy 1\n",
      "step 98400 , loss : 0.464033\n",
      "step 98400 , validation  accuracy 0.842105\n",
      "step 98400 , validation loss : 0.606041\n",
      "step 98400 , test  accuracy 0.820513\n",
      "step 98400 , test loss : 0.611029\n",
      "step 98500 , training  accuracy 1\n",
      "step 98500 , loss : 0.463848\n",
      "step 98500 , validation  accuracy 0.842105\n",
      "step 98500 , validation loss : 0.606051\n",
      "step 98500 , test  accuracy 0.820513\n",
      "step 98500 , test loss : 0.612055\n",
      "step 98600 , training  accuracy 1\n",
      "step 98600 , loss : 0.463846\n",
      "step 98600 , validation  accuracy 0.842105\n",
      "step 98600 , validation loss : 0.606374\n",
      "step 98600 , test  accuracy 0.846154\n",
      "step 98600 , test loss : 0.614418\n",
      "step 98700 , training  accuracy 1\n",
      "step 98700 , loss : 0.463676\n",
      "step 98700 , validation  accuracy 0.842105\n",
      "step 98700 , validation loss : 0.606276\n",
      "step 98700 , test  accuracy 0.846154\n",
      "step 98700 , test loss : 0.615166\n",
      "step 98800 , training  accuracy 1\n",
      "step 98800 , loss : 0.464156\n",
      "step 98800 , validation  accuracy 0.842105\n",
      "step 98800 , validation loss : 0.60606\n",
      "step 98800 , test  accuracy 0.820513\n",
      "step 98800 , test loss : 0.616044\n",
      "step 98900 , training  accuracy 1\n",
      "step 98900 , loss : 0.466006\n",
      "step 98900 , validation  accuracy 0.842105\n",
      "step 98900 , validation loss : 0.605069\n",
      "step 98900 , test  accuracy 0.846154\n",
      "step 98900 , test loss : 0.615504\n",
      "step 99000 , training  accuracy 1\n",
      "step 99000 , loss : 0.464032\n",
      "step 99000 , validation  accuracy 0.842105\n",
      "step 99000 , validation loss : 0.602526\n",
      "step 99000 , test  accuracy 0.846154\n",
      "step 99000 , test loss : 0.608654\n",
      "step 99100 , training  accuracy 1\n",
      "step 99100 , loss : 0.46373\n",
      "step 99100 , validation  accuracy 0.815789\n",
      "step 99100 , validation loss : 0.60354\n",
      "step 99100 , test  accuracy 0.846154\n",
      "step 99100 , test loss : 0.604928\n",
      "step 99200 , training  accuracy 1\n",
      "step 99200 , loss : 0.463867\n",
      "step 99200 , validation  accuracy 0.789474\n",
      "step 99200 , validation loss : 0.605239\n",
      "step 99200 , test  accuracy 0.820513\n",
      "step 99200 , test loss : 0.602928\n",
      "step 99300 , training  accuracy 1\n",
      "step 99300 , loss : 0.463693\n",
      "step 99300 , validation  accuracy 0.789474\n",
      "step 99300 , validation loss : 0.606593\n",
      "step 99300 , test  accuracy 0.820513\n",
      "step 99300 , test loss : 0.602396\n",
      "step 99400 , training  accuracy 1\n",
      "step 99400 , loss : 0.463387\n",
      "step 99400 , validation  accuracy 0.815789\n",
      "step 99400 , validation loss : 0.607874\n",
      "step 99400 , test  accuracy 0.820513\n",
      "step 99400 , test loss : 0.602144\n",
      "step 99500 , training  accuracy 1\n",
      "step 99500 , loss : 0.463558\n",
      "step 99500 , validation  accuracy 0.815789\n",
      "step 99500 , validation loss : 0.608023\n",
      "step 99500 , test  accuracy 0.820513\n",
      "step 99500 , test loss : 0.602318\n",
      "step 99600 , training  accuracy 1\n",
      "step 99600 , loss : 0.4636\n",
      "step 99600 , validation  accuracy 0.815789\n",
      "step 99600 , validation loss : 0.605464\n",
      "step 99600 , test  accuracy 0.820513\n",
      "step 99600 , test loss : 0.602307\n",
      "step 99700 , training  accuracy 1\n",
      "step 99700 , loss : 0.463522\n",
      "step 99700 , validation  accuracy 0.815789\n",
      "step 99700 , validation loss : 0.601882\n",
      "step 99700 , test  accuracy 0.820513\n",
      "step 99700 , test loss : 0.602069\n",
      "step 99800 , training  accuracy 1\n",
      "step 99800 , loss : 0.463859\n",
      "step 99800 , validation  accuracy 0.789474\n",
      "step 99800 , validation loss : 0.598624\n",
      "step 99800 , test  accuracy 0.820513\n",
      "step 99800 , test loss : 0.601972\n",
      "step 99900 , training  accuracy 1\n",
      "step 99900 , loss : 0.463346\n",
      "step 99900 , validation  accuracy 0.789474\n",
      "step 99900 , validation loss : 0.59634\n",
      "step 99900 , test  accuracy 0.820513\n",
      "step 99900 , test loss : 0.601759\n",
      "--- Training Time : 630.453639984 ---\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#sm_conv= tf.nn.softmax(y_conv)\n",
    "    #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    start_time = time.time()\n",
    "\n",
    "    regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "    pred=tf.nn.softmax(y_conv)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "with tf.device('/gpu:0'):\n",
    "    cost = cost+regular\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "batch_count=0\n",
    "max_acc=0\n",
    "if divide_flag ==True:\n",
    "    n_batch =len(train_images)\n",
    "    batch_count=0\n",
    "show_Exception_flag=True\n",
    "val_acc_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "train_loss_list=[]\n",
    "for i in range(iterate):    \n",
    "    if divide_flag ==True:\n",
    "        if batch_count >= n_batch:\n",
    "            batch_count =0\n",
    "        train_img =np.load(file_locate+train_images[batch_count])\n",
    "        train_lab =np.load(file_locate+train_labels[batch_count])\n",
    "    batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)\n",
    "   # batch_val_xs  , batch_val_ys = next_batch(20 , val_img , val_lab)\n",
    "\n",
    "    if i%100 ==0: # in here add to validation \n",
    "        try:\n",
    "            val_accuracy = sess.run( accuracy , feed_dict={x:val_img , y_:val_lab , keep_prob: 1.0})        \n",
    "            val_loss = sess.run(cost , feed_dict = {x:val_img , y_: val_lab , keep_prob: 1.0})\n",
    "            train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "            train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "            test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})\n",
    "            \n",
    "            val_acc_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "            train_acc_list.append(train_accuracy)\n",
    "            train_loss_list.append(train_loss)\n",
    "            \n",
    "            if (val_accuracy+test_accuracy)/2 > max_acc:\n",
    "                print 'a'\n",
    "                if save_flag == True:\n",
    "                    save_numpy_weight(model_save_path)\n",
    "                max_acc=(val_accuracy+test_accuracy)/2\n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "            print(\"step %d , test  accuracy %g\" %(i,test_accuracy))\n",
    "            print(\"step %d , test loss : %g\" %(i,test_loss))\n",
    "            \n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            if divide_flag ==True:\n",
    "                batch_count+=1\n",
    "        except Exception as e:\n",
    "            if show_Exception_flag:\n",
    "                print str(e)\n",
    "                show_Exception_flag=False\n",
    "            \n",
    "            list_acc=[]\n",
    "            list_loss=[]\n",
    "            n_divide=len(val_img)/batch_size\n",
    "            j=0\n",
    "            for j in range(n_divide):\n",
    "                # j*batch_size :(j+1)*batch_size\n",
    "                val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :(j+1)*batch_size] , y_:val_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                list_acc.append(float(val_accuracy))\n",
    "                list_loss.append(float(val_loss))\n",
    "            val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "            list_acc=np.asarray(list_acc)\n",
    "            list_loss= np.asarray(list_loss)\n",
    "            val_accuracy=np.mean(list_acc)\n",
    "            val_loss = np.mean(list_loss)\n",
    "            \n",
    "            val_acc_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "\n",
    "                        \n",
    "            list_acc=[]\n",
    "            list_loss=[]                \n",
    "            for j in range(n_divide):    \n",
    "                # j*batch_size :(j+1)*batch_size\n",
    "                test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                list_acc.append(float(test_accuracy))\n",
    "                list_loss.append(float(test_loss))\n",
    "            #right above code have to modify\n",
    "            test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "            list_acc.append(test_accuracy)\n",
    "            list_loss.append(test_loss)\n",
    "            \n",
    "\n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            \n",
    "            train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "            train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "            train_acc_list.append(train_accuracy)\n",
    "            train_loss_list.append(train_loss)\n",
    "            \n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "            \n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "            print(\"step %d , test  accuracy %g\" %(i,test_accuracy))\n",
    "            print(\"step %d , test loss : %g\" %(i,test_loss))           \n",
    "            \n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            batch_count+=1\n",
    "            \n",
    "            val_acc_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "            train_acc_list.append(train_accuracy)\n",
    "            train_loss_list.append(train_loss)    \n",
    "\n",
    "        sess.run(train_step ,feed_dict={x:batch_xs , y_:batch_ys , keep_prob : 0.7})\n",
    "\n",
    "np.save(model_save_path+'val_acc',np.asarray(val_acc_list))\n",
    "np.save(model_save_path+'val_loss',np.asarray(val_loss_list))\n",
    "np.save(model_save_path+'train_acc',np.asarray(train_acc_list))\n",
    "np.save(model_save_path+'train_loss',np.asarray(train_loss_list))\n",
    "\n",
    "softmax_=sess.run( pred , feed_dict={x:test_img  ,y_:test_lab, keep_prob: 1.0})\n",
    "test_accuracy,test_loss= sess.run([accuracy,cost]  , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})\n",
    "print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "f.write(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35346532  0.64653468]\n",
      " [ 0.29977939  0.70022064]\n",
      " [ 0.69777179  0.30222821]\n",
      " [ 0.30079153  0.69920844]\n",
      " [ 0.59555101  0.40444893]\n",
      " [ 0.70426553  0.29573452]\n",
      " [ 0.3962577   0.6037423 ]\n",
      " [ 0.61589283  0.38410714]\n",
      " [ 0.47831243  0.52168751]\n",
      " [ 0.62959957  0.3704004 ]\n",
      " [ 0.57264978  0.42735019]\n",
      " [ 0.32129371  0.67870635]\n",
      " [ 0.65229702  0.34770301]\n",
      " [ 0.38721859  0.61278135]\n",
      " [ 0.5617069   0.43829307]\n",
      " [ 0.67327309  0.32672688]\n",
      " [ 0.42967385  0.57032615]\n",
      " [ 0.64947414  0.35052589]\n",
      " [ 0.53104889  0.46895105]\n",
      " [ 0.65667248  0.34332752]\n",
      " [ 0.6928764   0.30712363]\n",
      " [ 0.64309615  0.35690388]\n",
      " [ 0.30439886  0.69560117]\n",
      " [ 0.47541377  0.52458632]\n",
      " [ 0.58422464  0.41577536]\n",
      " [ 0.68990034  0.31009966]\n",
      " [ 0.65123695  0.34876299]\n",
      " [ 0.70350659  0.29649344]\n",
      " [ 0.70432109  0.29567894]\n",
      " [ 0.68694997  0.31304997]\n",
      " [ 0.33235833  0.6676417 ]\n",
      " [ 0.38513795  0.61486202]\n",
      " [ 0.30401945  0.69598061]\n",
      " [ 0.3797541   0.62024587]\n",
      " [ 0.30901688  0.69098318]\n",
      " [ 0.69455731  0.30544269]\n",
      " [ 0.71190238  0.28809756]\n",
      " [ 0.31927678  0.68072319]\n",
      " [ 0.32846776  0.67153227]]\n"
     ]
    }
   ],
   "source": [
    "print softmax_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "test_img=np.load('/home/seongjung/save_numpy/1.npy')\n",
    "print np.shape(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (30, 64, 64, 3) for Tensor u'x-input_4:0', which has shape '(?, 100, 100, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-7b3e373f7d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# j*batch_size :(j+1)*batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_lab\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlist_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlist_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seongjung/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seongjung/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (30, 64, 64, 3) for Tensor u'x-input_4:0', which has shape '(?, 100, 100, 3)'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    softmax_=sess.run( accuracy , feed_dict={x:test_img  , keep_prob: 1.0})\n",
    "    test_accuracy = sess.run( accuracy , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})        \n",
    "    test_loss = sess.run(cost , feed_dict = {x:test_img , y_: test_lab , keep_prob: 1.0})\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n",
    "except :\n",
    "    list_acc=[]\n",
    "    list_loss=[]\n",
    "    n_divide=len(test_img)/batch_size\n",
    "    for j in range(n_divide):\n",
    "\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "        list_acc.append(float(test_accuracy))\n",
    "        list_loss.append(float(test_loss))\n",
    "    test_accuracy , test_loss=sess.run([accuracy,cost] , feed_dict={x:test_img[(j+1)*batch_size : ] , y_:test_lab[(j+1)*(batch_size) : ] , keep_prob : 1.0})\n",
    "    #right above code have to modify\n",
    "\n",
    "    list_acc.append(test_accuracy)\n",
    "    list_loss.append(test_loss)\n",
    "    list_acc=np.asarray(list_acc)\n",
    "    list_loss= np.asarray(list_loss)\n",
    "\n",
    "    test_accuracy=np.mean(list_acc)\n",
    "    test_loss = np.mean(list_loss)\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_img[8])\n",
    "train_lab[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
